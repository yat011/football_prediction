{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "class FootballDataHelper:\n",
    "    def __init__ (self, recentNum=5):\n",
    "        self.win_mapping = {'D':0, 'H':1,'A':2}\n",
    "        self.recentNum = recentNum\n",
    "        self.df = None\n",
    "        #self.hiddensCount = 2\n",
    "       \n",
    "        \n",
    "    def readFootBallData(self,filename): \n",
    "        df = pd.read_csv(filename)\n",
    "        df = df.drop(df.columns[range(23,df.shape[1])], axis=1)\n",
    "        df = df.drop(\"Div\",axis=1)\n",
    "        df['Date'] = pd.to_datetime(df['Date'],dayfirst=True)\n",
    "        df['HTR'] = df['HTR'].map(self.win_mapping)\n",
    "        df['FTR'] = df['FTR'].map(self.win_mapping)\n",
    "        df= df.drop('Referee', 1)\n",
    "        print(df.shape)\n",
    "          #self.team = df['HomeTeam'].drop_duplicates()\n",
    "        if self.df is None:\n",
    "            self.df = df\n",
    "        else:\n",
    "            self.df = pd.concat([self.df,df])\n",
    "            \n",
    "        teams = self.df['HomeTeam'].drop_duplicates()\n",
    "        teamMap = {}\n",
    "        for index , v in enumerate(teams):\n",
    "            teamMap[v] = index\n",
    "        self.teamsMap = teamMap\n",
    " \n",
    "    def getTeam(self,dataFrame, teamName):       \n",
    "        return dataFrame[(dataFrame[\"HomeTeam\"] == teamName) | (dataFrame[\"AwayTeam\"] == teamName)]\n",
    "    def formatData(self, X_train ):\n",
    "        print(\"start format\")\n",
    "        X_train = X_train.sort_values(by=\"Date\")\n",
    "        X_train['Date'] = pd.to_numeric(X_train['Date'])/1e9/24/60/60\n",
    "        \n",
    "        sys.stdout.flush()\n",
    "        res = []\n",
    "        y =[]\n",
    "        for v in X_train['FTR']:\n",
    "            y.append(range(3)==v)\n",
    "        resy=[]\n",
    "        for i in range(X_train.shape[0]):\n",
    "            print(\"\\r progress {}\".format(i))\n",
    "            sys.stdout.flush()\n",
    "            x = X_train.iloc[i]\n",
    "            homeName = x['HomeTeam']\n",
    "            awayName = x['AwayTeam']\n",
    "            homeTeam = self.getTeam(X_train,homeName)\n",
    "            awayTeam = self.getTeam(X_train,awayName)\n",
    "            prevHome = self.previousRecords(homeTeam,x['Date'])\n",
    "            prevAway = self.previousRecords(awayTeam,x['Date'])\n",
    "            if prevHome is None or prevAway is None:\n",
    "               # print(\"{} skip\".format(i))\n",
    "                continue\n",
    "           # print(\"{} has enough sample\".format(i))  \n",
    "            prevHome=prevHome.copy()\n",
    "            prevAway = prevAway.copy()\n",
    "            prevHome['HomeTeam']=(prevHome['HomeTeam']==homeName)\n",
    "            prevHome['AwayTeam']=(prevHome['AwayTeam']==homeName)\n",
    "            prevAway['HomeTeam']=(prevAway['HomeTeam']==awayName)\n",
    "            prevAway['AwayTeam']=(prevAway['AwayTeam']==awayName)\n",
    "            homeDate = prevHome['Date'].values\n",
    "            awayDate = prevAway['Date'].values\n",
    "            #homeDate = homeDate.astype('uint64')/1e9/24/60/60\n",
    "            homeDate = x['Date'] - homeDate \n",
    "            #awayDate = awayDate.astype('uint64')/1e9/24/60/60\n",
    "            awayDate = x['Date'] - awayDate \n",
    "            #print(homeDate)\n",
    "            hv = prevHome.drop('Date',axis=1).values\n",
    "            av = prevAway.drop('Date',axis=1).values\n",
    "            hv = np.column_stack([hv, homeDate])\n",
    "            av = np.column_stack([av,awayDate])\n",
    "            \n",
    "            inData = np.ravel(np.array([hv,av]))\n",
    "            res.append(inData)\n",
    "            resy.append(y[i])\n",
    "        \n",
    "        Xres = np.array(res)\n",
    "        \n",
    "       \n",
    "        X_train_std = Xres\n",
    "        print(\"finish\")\n",
    "\n",
    "        return (X_train_std,np.array(resy))\n",
    "            \n",
    "    def fit(self,X=None,y=None):\n",
    "        teams = self.df['HomeTeam'].drop_duplicates()\n",
    "       \n",
    "        if X is None or y is None:\n",
    "            (X, y)=self.formatData(df)\n",
    "        X_train,X_test_val, y_train, y_test_val =    train_test_split(X,y, test_size=0.4)\n",
    "        X_val ,X_test,y_val,y_test = train_test_split(X_test_val,y_test_val, test_size=0.5)\n",
    "        print(X_val)\n",
    "        \n",
    "        \n",
    "     \n",
    "        print(\"Start Training\")\n",
    "        self.nn.fit(X_train,y_train)\n",
    "        print(\"fisish Training\")\n",
    "        return (X_val ,X_test,y_val,y_test)\n",
    "\n",
    "    def validate(self, X_val, y_val):\n",
    "            return self.nn.predict(X_val)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    def previousRecords(self,team, date , recentNum):\n",
    "        prev = team[( team[\"Date\"] < date)]\n",
    "        \n",
    "        if prev.shape[0] < recentNum :\n",
    "            #print(\"less than min Num\")\n",
    "            return None\n",
    "        else:\n",
    "            return prev.iloc[-recentNum:]\n",
    "    def readPredict (self, filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        df['Date'] = pd.to_datetime(df['Date'],dayfirst=True)\n",
    "        df['FTR'] = df['FTR'].map(self.win_mapping)\n",
    "        return df\n",
    "    \n",
    "    def getH1(self):\n",
    "        #recent matches (only win/loss/draw)\n",
    "       \n",
    "        \n",
    "       # print (self.df)      \n",
    "        X  = self.df.sort_values(by=\"Date\")\n",
    "        y = []\n",
    "        for v in X['FTR']:\n",
    "            y.append(range(3)==v)\n",
    "       # print(y)\n",
    "        resy=[]\n",
    "        resx=[]\n",
    "        print(\"h1:start format\")\n",
    "        for i in range(X.shape[0]):\n",
    "            \n",
    "            sys.stdout.write(\"\\r progress {}\".format(i))\n",
    "            sys.stdout.flush()\n",
    "            x = X.iloc[i]\n",
    "            homeName = x['HomeTeam']\n",
    "            awayName = x['AwayTeam']\n",
    "            homeTeam = self.getTeam(X,homeName)\n",
    "            awayTeam = self.getTeam(X,awayName)\n",
    "            prevHome = self.previousRecords(homeTeam,x['Date'])\n",
    "            prevAway = self.previousRecords(awayTeam,x['Date'])\n",
    "            if prevHome is None or prevAway is None:\n",
    "               # print(\"{} skip\".format(i))\n",
    "                continue\n",
    "            prevHomeWin = []\n",
    "            prevAwayWin = []\n",
    "            for v in prevHome['FTR']:\n",
    "                prevHomeWin.append(range(3) == v)\n",
    "            #print(prevHomeWin)\n",
    "            for v in prevAway['FTR']:\n",
    "                prevAwayWin.append(range(3) == v)\n",
    "            pHHT=(prevHome['HomeTeam']==homeName).values\n",
    "            pAHT=(prevAway['HomeTeam']==awayName).values\n",
    "            tempX=[]\n",
    "            for j in range(pHHT.shape[0]):\n",
    "                tempX.append(np.append(prevHomeWin[j],pHHT[j]))\n",
    "                \n",
    "            for j in range(pAHT.shape[0]):\n",
    "                tempX.append(np.append(prevAwayWin[j],pAHT[j]))\n",
    "            resx.append(np.ravel(tempX))\n",
    "            \n",
    "            resy.append(y[i])\n",
    "        print(\"finish\")\n",
    "        sys.stdout.flush()\n",
    "        return np.array(resx), np.array(resy)\n",
    "    def getH2(self):         \n",
    "       #team based      \n",
    "        X  = self.df.sort_values(by=\"Date\")\n",
    "        y = []\n",
    "        for v in X['FTR']:\n",
    "            y.append(range(3)==v)\n",
    "       # print(y)\n",
    "        resy=[]\n",
    "        resx=[]\n",
    "        print(\"h1:start format\")\n",
    "        X['HomeTeam'] = X['HomeTeam'].map(self.teamsMap)\n",
    "        X['AwayTeam'] = X['AwayTeam'].map(self.teamsMap)\n",
    "        nativeX = X[['HomeTeam','AwayTeam']].values\n",
    "        #print(X)\n",
    "        ohe = OneHotEncoder(categorical_features=[0,1])\n",
    "        res = ohe.fit_transform(nativeX).toarray()\n",
    "        #print(res)\n",
    "        return res, np.array(y)\n",
    "    def _getH3RecentMatches(self,x, X,teamName,recentNum):\n",
    "        team = self.getTeam(X,teamName)\n",
    "        prev = self.previousRecords(team,x['Date'],recentNum)\n",
    "        if prev is None:\n",
    "               return None\n",
    "        prevHt=  prev['HomeTeam'].values\n",
    "        prevAt=  prev['AwayTeam'].values   \n",
    "        prevIsHome = []\n",
    "        prevOther = []\n",
    "        for i in range(recentNum):\n",
    "            if prevHt[i] == teamName:\n",
    "                prevIsHome.append(1)\n",
    "                prevOther.append(prevAt[i])\n",
    "            else:\n",
    "                prevIsHome.append(0)\n",
    "                prevOther.append(prevHt[i])\n",
    "        wins = prev['FTR'].values       \n",
    "        temp = np.array([prevIsHome,prevOther,wins]).T\n",
    "\n",
    "        return np.ravel(temp)\n",
    "        \n",
    "    def getH3(self, recentNum):\n",
    "        X  = self.df.sort_values(by=\"Date\")\n",
    "        X['HomeTeam'] = X['HomeTeam'].map(self.teamsMap)\n",
    "        X['AwayTeam'] = X['AwayTeam'].map(self.teamsMap)\n",
    "        y = []\n",
    "        for v in X['FTR']:\n",
    "            y.append(range(3)==v)\n",
    "       # print(y)\n",
    "        resy=[]\n",
    "        resx=[]\n",
    "        print(\"h3:start format\")\n",
    "        recents = []\n",
    "        for i in range(X.shape[0]):\n",
    "            \n",
    "            sys.stdout.write(\"\\r progress {}\".format(i))\n",
    "            sys.stdout.flush()\n",
    "            x = X.iloc[i]\n",
    "            homeName = x['HomeTeam']\n",
    "            awayName = x['AwayTeam']\n",
    "            homeRecent = self._getH3RecentMatches(x,X,homeName, recentNum)\n",
    "            awayRecent =self._getH3RecentMatches(x,X,awayName, recentNum)\n",
    "            if homeRecent is None or awayRecent is None:\n",
    "                   continue \n",
    "        #    print(homeName)\n",
    "         #   print(homeRecent)\n",
    "        #    print(awayName)\n",
    "         #   print(awayRecent)\n",
    "         #   return\n",
    "            recents.append(np.hstack([homeName,awayName, homeRecent,awayRecent]))        \n",
    "            resy.append(y[i])\n",
    "        cols =np.hstack([[0,1],list(range(3,len(recents[0]),3))])\n",
    "        print(cols)\n",
    "        ohe = OneHotEncoder(categorical_features=cols)\n",
    "        res = ohe.fit_transform(recents).toarray()\n",
    "        print(\"finish\")\n",
    "        sys.stdout.flush()\n",
    "        return res, np.array(resy)\n",
    "   \n",
    "\n",
    "    def getH4(self, recentNum, target=None):\n",
    "        \n",
    "        X  = self.df.sort_values(by=\"Date\")\n",
    "        isInput = False\n",
    "        if target is None:\n",
    "            target =X      \n",
    "        else:\n",
    "            if self.ohe is None:\n",
    "                raise Exception(\"Not yet get train data\")\n",
    "            isInput = True\n",
    "            target['HomeTeam']=target['HomeTeam'].map(self.teamsMap)\n",
    "            target['AwayTeam']=target['AwayTeam'].map(self.teamsMap)\n",
    "            pass\n",
    "            \n",
    "        X['HomeTeam'] = X['HomeTeam'].map(self.teamsMap)\n",
    "        X['AwayTeam'] = X['AwayTeam'].map(self.teamsMap)\n",
    "        target_date = (pd.to_numeric(target['Date'])/1e9/24/60/60).values\n",
    "        y = []\n",
    "        for v in target['FTR']:\n",
    "            y.append(range(3)==v)\n",
    "       # print(y)\n",
    "        resy=[]\n",
    "        resx=[]\n",
    "        print(\"h4:start format\")\n",
    "        recents = []\n",
    "        for i in range(target.shape[0]):\n",
    "            \n",
    "            sys.stdout.write(\"\\r progress {}\".format(i))\n",
    "            sys.stdout.flush()\n",
    "            x = target.iloc[i]\n",
    "            homeName = x['HomeTeam']\n",
    "            awayName = x['AwayTeam']\n",
    "            homeRecent = self._getH3RecentMatches(x,X,homeName, recentNum)\n",
    "            awayRecent =self._getH3RecentMatches(x,X,awayName, recentNum)\n",
    "            if homeRecent is None or awayRecent is None:\n",
    "                   continue \n",
    "           # print(homeName)\n",
    "           # print(homeRecent)\n",
    "          #  print(awayName)\n",
    "            #print(awayRecent)\n",
    "            recents.append(np.hstack([homeName,awayName,target_date[i], homeRecent,awayRecent]))  \n",
    "         #   print(recents)            \n",
    "            resy.append(y[i])\n",
    "        \n",
    "        if isInput==False:\n",
    "            cols =np.hstack([[0,1],list(range(4,len(recents[0]),3))])\n",
    "            self.ohe = OneHotEncoder(categorical_features=cols)\n",
    "            self.ohe.fit(recents)\n",
    "\n",
    "        res = self.ohe.transform(recents).toarray()\n",
    "        print(\"finish\")\n",
    "        sys.stdout.flush()\n",
    "        return res, np.array(resy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from IPython.core.display import clear_output\n",
    "    have_ipython = True\n",
    "except ImportError:\n",
    "    have_ipython = False\n",
    "import sys\n",
    "def likehoodScore(proba,y):\n",
    "    return np.sum(proba * y)/proba.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 21)\n",
      "(380, 21)\n",
      "(288, 21)\n",
      "{'Sunderland': 3, 'Aston Villa': 10, 'Stoke': 16, 'Burnley': 22, 'Norwich': 2, 'Cardiff': 17, 'Chelsea': 7, 'Leicester': 20, 'Man United': 19, 'QPR': 21, 'Bournemouth': 23, 'Crystal Palace': 8, 'West Ham': 6, 'Hull': 13, 'Liverpool': 1, 'Everton': 11, 'Tottenham': 18, 'Newcastle': 14, 'Fulham': 12, 'Man City': 9, 'Swansea': 4, 'West Brom': 5, 'Arsenal': 0, 'Watford': 24, 'Southampton': 15}\n"
     ]
    }
   ],
   "source": [
    "c = FootballDataHelper(recentNum=4)\n",
    "c.readFootBallData(\"E0_1314.csv\")\n",
    "c.readFootBallData(\"E0_1415.csv\")\n",
    "c.readFootBallData(\"E0.csv\")\n",
    "print(c.teamsMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h4:start format\n",
      " progress 1047finish\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#alpha, hidden size, score, weighted Score\n",
    "\n",
    "#c.fit()\n",
    "#c.fit()\n",
    "#X, y = c.formatData(c.df)\n",
    "#print(X)\n",
    "X,y = c.getH4(5)\n",
    "#X, y =c.getH3(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date     HomeTeam     AwayTeam  FTR\n",
      "0 2016-03-12      Norwich     Man City    0\n",
      "1 2016-03-12  Bournemouth      Swansea    1\n",
      "2 2016-03-12        Stoke  Southampton    2\n",
      "3 2016-03-14  Aston Villa    Tottenham    2\n",
      "4 2016-03-15    Leicester    Newcastle    1\n",
      "h4:start format\n",
      " progress 4finish\n",
      "[[ True False False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False  True False]]\n"
     ]
    }
   ],
   "source": [
    "inData = c.readPredict(\"predict.csv\")\n",
    "print(inData)\n",
    "X_in, y_in = c.getH4(5,target=inData)\n",
    "print(y_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from custom import SoftMaxMLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "hiddenNodes = int(12)\n",
    "print(hiddenNodes)\n",
    "clf = SoftMaxMLPClassifier(hidden_layer_sizes=[hiddenNodes], activation='logistic', algorithm='l-bfgs', alpha=50, \n",
    "              learning_rate_init=0.01,learning_rate='adaptive' ,max_iter=500,early_stopping = True,verbose = 3)\n",
    "mlp = Pipeline([('scl', StandardScaler()),('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SoftMaxMLPClassifier(activation='logistic', algorithm='l-bfgs', alpha=50,\n",
       "           batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "           early_stopping=True, epsilon=1e-08, hidden_layer_sizes=[12],\n",
       "           learn...e=None, shuffle=True, tol=0.0001,\n",
       "           validation_fraction=0.1, verbose=3, warm_start=False))])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X,y)\n",
    "#res = mlp.predict(X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(973, 321)\n",
      "[[False False  True]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False  True False]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80000000000000004"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "res = mlp.predict(X_in)\n",
    "print(res)\n",
    "mlp.score(X_in,y_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434\n",
      "973\n"
     ]
    }
   ],
   "source": [
    "mlp.score(X,y)\n",
    "print(np.sum(np.argmax(res,axis=1) == np.argmax(y,axis=1)))\n",
    "print(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"start learning\")\n",
    "sys.stdout.flush()\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=mlp, \n",
    "                       X=X, \n",
    "                      y=y, \n",
    "                      train_sizes=np.linspace(0.1, 1.0, 4), \n",
    "                      cv=4,\n",
    "                     n_jobs=1,verbose=3)\n",
    "print(\"finishing\")   \n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def plotCurve(train_mean, train_std,test_mean,test_std,sizes):\n",
    "    plt.plot(sizes, train_mean, \n",
    "            color='blue', marker='o', \n",
    "            markersize=5, \n",
    "            label='training accuracy')\n",
    "    plt.fill_between(sizes, \n",
    "                  train_mean + train_std,\n",
    "                   train_mean - train_std, alpha=0.15, color='blue')\n",
    "\n",
    "    plt.plot(sizes, test_mean, \n",
    "              color='green', linestyle='--', \n",
    "              marker='s', markersize=5, \n",
    "             label='validation accuracy')\n",
    "    plt.fill_between(sizes, \n",
    "                      test_mean + test_std,\n",
    "                     test_mean - test_std, \n",
    "                    alpha=0.15, color='green')\n",
    "    plt.xlabel('x_range')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotCurve(train_mean,train_std,test_mean,test_std,train_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "def crossValidate(mlp, X,y, fold = 10):\n",
    "    y_label = np.argmax(y,axis=1)\n",
    "\n",
    "    kfold = StratifiedKFold(y=y_label, \n",
    "                             n_folds=fold,\n",
    "                            random_state=1)\n",
    "\n",
    "    scores = []\n",
    "    train_scores=[]\n",
    "    for k, (train, test) in enumerate(kfold):\n",
    "\n",
    "        mlp.fit(X[train], y[train])\n",
    "        score = mlp.score(X[test], y[test])\n",
    "        train_scores.append(mlp.score(X[train],y[train]))\n",
    "        scores.append(score)\n",
    "        print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1, \n",
    "                    np.bincount(y_label[train]), score))    \n",
    "    return train_scores,scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__warm_start': False, 'clf__beta_2': 0.999, 'clf__batch_size': 'auto', 'clf__early_stopping': True, 'clf__algorithm': 'l-bfgs', 'clf__nesterovs_momentum': True, 'clf': SoftMaxMLPClassifier(activation='logistic', algorithm='l-bfgs', alpha=10,\n",
      "           batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
      "           early_stopping=True, epsilon=1e-08, hidden_layer_sizes=[12],\n",
      "           learning_rate='adaptive', learning_rate_init=0.01, max_iter=500,\n",
      "           momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
      "           random_state=None, shuffle=True, tol=0.0001,\n",
      "           validation_fraction=0.1, verbose=3, warm_start=False), 'clf__shuffle': True, 'clf__learning_rate_init': 0.01, 'clf__activation': 'logistic', 'scl__with_std': True, 'clf__tol': 0.0001, 'clf__random_state': None, 'scl__copy': True, 'clf__epsilon': 1e-08, 'clf__hidden_layer_sizes': [12], 'scl__with_mean': True, 'clf__max_iter': 500, 'clf__momentum': 0.9, 'scl': StandardScaler(copy=True, with_mean=True, with_std=True), 'clf__learning_rate': 'adaptive', 'clf__alpha': 10, 'clf__validation_fraction': 0.1, 'clf__beta_1': 0.9, 'steps': [('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SoftMaxMLPClassifier(activation='logistic', algorithm='l-bfgs', alpha=10,\n",
      "           batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
      "           early_stopping=True, epsilon=1e-08, hidden_layer_sizes=[12],\n",
      "           learning_rate='adaptive', learning_rate_init=0.01, max_iter=500,\n",
      "           momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
      "           random_state=None, shuffle=True, tol=0.0001,\n",
      "           validation_fraction=0.1, verbose=3, warm_start=False))], 'clf__verbose': 3, 'clf__power_t': 0.5}\n",
      "Fold: 1, Class dist.: [183 347 248], Acc: 0.451\n",
      "Fold: 2, Class dist.: [183 347 248], Acc: 0.472\n",
      "Fold: 3, Class dist.: [183 347 248], Acc: 0.456\n",
      "Fold: 4, Class dist.: [183 347 248], Acc: 0.456\n",
      "Fold: 5, Class dist.: [184 348 248], Acc: 0.446\n",
      "lamda: 10, train: 0.9843260167424692, test: 0.4562986581639431\n",
      "{'clf__warm_start': False, 'clf__beta_2': 0.999, 'clf__batch_size': 'auto', 'clf__early_stopping': True, 'clf__algorithm': 'l-bfgs', 'clf__nesterovs_momentum': True, 'clf': SoftMaxMLPClassifier(activation='logistic', algorithm='l-bfgs', alpha=12,\n",
      "           batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
      "           early_stopping=True, epsilon=1e-08, hidden_layer_sizes=[12],\n",
      "           learning_rate='adaptive', learning_rate_init=0.01, max_iter=500,\n",
      "           momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
      "           random_state=None, shuffle=True, tol=0.0001,\n",
      "           validation_fraction=0.1, verbose=3, warm_start=False), 'clf__shuffle': True, 'clf__learning_rate_init': 0.01, 'clf__activation': 'logistic', 'scl__with_std': True, 'clf__tol': 0.0001, 'clf__random_state': None, 'scl__copy': True, 'clf__epsilon': 1e-08, 'clf__hidden_layer_sizes': [12], 'scl__with_mean': True, 'clf__max_iter': 500, 'clf__momentum': 0.9, 'scl': StandardScaler(copy=True, with_mean=True, with_std=True), 'clf__learning_rate': 'adaptive', 'clf__alpha': 12, 'clf__validation_fraction': 0.1, 'clf__beta_1': 0.9, 'steps': [('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SoftMaxMLPClassifier(activation='logistic', algorithm='l-bfgs', alpha=12,\n",
      "           batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
      "           early_stopping=True, epsilon=1e-08, hidden_layer_sizes=[12],\n",
      "           learning_rate='adaptive', learning_rate_init=0.01, max_iter=500,\n",
      "           momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
      "           random_state=None, shuffle=True, tol=0.0001,\n",
      "           validation_fraction=0.1, verbose=3, warm_start=False))], 'clf__verbose': 3, 'clf__power_t': 0.5}\n",
      "Fold: 1, Class dist.: [183 347 248], Acc: 0.415\n",
      "Fold: 2, Class dist.: [183 347 248], Acc: 0.477\n",
      "Fold: 3, Class dist.: [183 347 248], Acc: 0.451\n",
      "Fold: 4, Class dist.: [183 347 248], Acc: 0.436\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-1eebc3e16998>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0ml_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtrain_scores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlamda_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-62-1eebc3e16998>\u001b[0m in \u001b[0;36mlamda_test\u001b[1;34m(mlp, X, y, lamdas)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlamda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtrain_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrossValidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mtrain_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mtest_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-e7fa31a218ee>\u001b[0m in \u001b[0;36mcrossValidate\u001b[1;34m(mlp, X, y, fold)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mtrain_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/scikit-learn/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \"\"\"\n\u001b[0;32m    165\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/scikit-learn/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \"\"\"\n\u001b[1;32m--> 615\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/scikit-learn/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\u001b[1;32m--> 380\u001b[1;33m                             intercept_grads, layer_units)\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/scikit-learn/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[0;32m    463\u001b[0m             \u001b[0miprint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miprint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m             \u001b[0mpgtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m             args=(X, y, activations, deltas, coef_grads, intercept_grads))\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimal_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/anaconda3/lib/python3.5/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[1;32m--> 193\u001b[1;33m                            **opts)\n\u001b[0m\u001b[0;32m    194\u001b[0m     d = {'grad': res['jac'],\n\u001b[0;32m    195\u001b[0m          \u001b[1;34m'task'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/anaconda3/lib/python3.5/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    328\u001b[0m                 \u001b[1;31m# minimization routine wants f and g at the current x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/anaconda3/lib/python3.5/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/anaconda3/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/anaconda3/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/scikit-learn/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[1;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_coef_inter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         loss, coef_grads, intercept_grads = self._backprop(\n\u001b[1;32m--> 177\u001b[1;33m             X, y, activations, deltas, coef_grads, intercept_grads)\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoef_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/scikit-learn/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_backprop\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;31m# Iterate over the hidden layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m             \u001b[0mderivative\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDERIVATIVES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mderivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/scikit-learn/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def lamda_test(mlp, X, y, lamdas):\n",
    "    \n",
    "    train_scores=[]\n",
    "    test_scores=[]\n",
    "    for lamda in lamdas:\n",
    "        clf.set_params(alpha= lamda)\n",
    "        print(mlp.get_params())\n",
    "        train_s, test_s = crossValidate(mlp,X,y,fold=5)\n",
    "        train_scores.append(train_s)\n",
    "        test_scores.append(test_s)\n",
    "        print(\"lamda: {}, train: {}, test: {}\".format(lamda, \n",
    "                    np.mean(train_s), np.mean(test_s)) )\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    plotCurve(train_mean,train_std,test_mean,test_std,lamdas)\n",
    "    return np.array(train_scores),np.array(test_scores)\n",
    "\n",
    "l_range = np.array(range(10,100,2))\n",
    "train_scores,test_scores = lamda_test(mlp,X,y,l_range)\n",
    "#50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\n",
    "#plotCurve(train_mean,train_std,test_mean,test_std,l_range)\n",
    "plt.plot(l_range, train_mean, \n",
    "        color='blue', marker='o', \n",
    "        markersize=5, \n",
    "        label='training accuracy')\n",
    "plt.fill_between(l_range, \n",
    "              train_mean + train_std,\n",
    "               train_mean - train_std, alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(l_range, test_mean, \n",
    "          color='green', linestyle='--', \n",
    "          marker='s', markersize=5, \n",
    "         label='validation accuracy')\n",
    "plt.fill_between(l_range, \n",
    "                  test_mean + test_std,\n",
    "                 test_mean - test_std, \n",
    "                alpha=0.15, color='green')\n",
    "plt.xlabel('lamda')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y,test_size =0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = mlp.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = mlp.predict(X_test)\n",
    "print(mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likehoodScore(res,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "home_teams_test = np.argmax(X_test[:,0:len(c.teamsMap)],axis=1)\n",
    "away_teams_test = np.argmax(X_test[:,len(c.teamsMap):len(c.teamsMap)*2],axis=1)\n",
    "inverseMap ={}\n",
    "for name in c.teamsMap.keys():        \n",
    "    inverseMap[c.teamsMap[name]] = name\n",
    "\n",
    "home_name =[]\n",
    "away_name =[]\n",
    "for i in range(home_teams_test.shape[0]):         \n",
    "    home_name.append(inverseMap[home_teams_test[i]])\n",
    "    away_name.append(inverseMap[away_teams_test[i]])\n",
    "pre_y = np.argmax(predicted,axis=1)\n",
    "real_y = np.argmax(y_test,axis=1)\n",
    "for i in range(predicted.shape[0]):\n",
    "    if pre_y[i] != real_y[i]:\n",
    "        print('-------------')\n",
    "        print(\"{} vs {}\".format(home_name[i],away_name[i]))\n",
    "        print(\"{} vs {}\".format(res[i],y_test[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#c.df[(c.df['HomeTeam'] == 'West Brom') | (c.df['AwayTeam']=='West Brom')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from custom import SoftMaxMLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def testNodeSize(start ,end):\n",
    "    node_range = range(start,end,25)\n",
    "    train_means = []\n",
    "    train_std = []\n",
    "    test_means =[]\n",
    "    test_std=[]\n",
    "    for node in node_range:   \n",
    "        print(\"start node:{}\".format(node))\n",
    "        clf = SoftMaxMLPClassifier(hidden_layer_sizes=[node], activation='logistic', algorithm='l-bfgs', alpha=30, \n",
    "                  learning_rate_init=0.01,learning_rate='adaptive' ,max_iter=500,early_stopping = True,verbose = 3)\n",
    "        mlp = Pipeline([('scl', StandardScaler()),('clf', clf)])\n",
    "        train_scores,test_scores = crossValidate(mlp,X,y,fold=5)\n",
    "        train_means.append(np.mean(train_scores))\n",
    "        train_std.append(np.std(train_scores))\n",
    "        test_means.append(np.mean(test_scores))\n",
    "        test_std.append(np.std(test_scores))\n",
    "        print(\"Node {}: train_mean {}  v.s. test_mean {}\".format(node,np.mean(train_scores),np.mean(test_scores)))\n",
    "    plotCurve(train_means,train_std,test_means,test_std,node_range)\n",
    "    return train_means,train_std,test_means,test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_means,train_std,test_means,test_std=testNodeSize(10 , X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
