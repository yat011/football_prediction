{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "class FootballDataHelper:\n",
    "    def __init__ (self, recentNum=5):\n",
    "        self.win_mapping = {'H':0, 'D':1,'A':2}\n",
    "        self.recentNum = recentNum\n",
    "        self.df = None\n",
    "        #self.hiddensCount = 2\n",
    "       \n",
    "        \n",
    "    def readFootBallData(self,filename): \n",
    "        df = pd.read_csv(filename)\n",
    "        df = df.drop(df.columns[range(23,df.shape[1])], axis=1)\n",
    "        df = df.drop(\"Div\",axis=1)\n",
    "        df['Date'] = pd.to_datetime(df['Date'],dayfirst=True)\n",
    "        df['HTR'] = df['HTR'].map(self.win_mapping)\n",
    "        df['FTR'] = df['FTR'].map(self.win_mapping)\n",
    "        df= df.drop('Referee', 1)\n",
    "        print(df.shape)\n",
    "          #self.team = df['HomeTeam'].drop_duplicates()\n",
    "        if self.df is None:\n",
    "            self.df = df\n",
    "        else:\n",
    "            self.df = pd.concat([self.df,df])\n",
    "            \n",
    "        teams = self.df['HomeTeam'].drop_duplicates()\n",
    "        teamMap = {}\n",
    "        for index , v in enumerate(teams):\n",
    "            teamMap[v] = index\n",
    "        self.teamsMap = teamMap\n",
    " \n",
    "    def getTeam(self,dataFrame, teamName):       \n",
    "        return dataFrame[(dataFrame[\"HomeTeam\"] == teamName) | (dataFrame[\"AwayTeam\"] == teamName)]\n",
    "    def formatData(self, X_train ):\n",
    "        print(\"start format\")\n",
    "        X_train = X_train.sort_values(by=\"Date\")\n",
    "        X_train['Date'] = pd.to_numeric(X_train['Date'])/1e9/24/60/60\n",
    "        \n",
    "        sys.stdout.flush()\n",
    "        res = []\n",
    "        y =[]\n",
    "        for v in X_train['FTR']:\n",
    "            y.append(range(3)==v)\n",
    "        resy=[]\n",
    "        for i in range(X_train.shape[0]):\n",
    "            print(\"\\r progress {}\".format(i))\n",
    "            sys.stdout.flush()\n",
    "            x = X_train.iloc[i]\n",
    "            homeName = x['HomeTeam']\n",
    "            awayName = x['AwayTeam']\n",
    "            homeTeam = self.getTeam(X_train,homeName)\n",
    "            awayTeam = self.getTeam(X_train,awayName)\n",
    "            prevHome = self.previousRecords(homeTeam,x['Date'])\n",
    "            prevAway = self.previousRecords(awayTeam,x['Date'])\n",
    "            if prevHome is None or prevAway is None:\n",
    "               # print(\"{} skip\".format(i))\n",
    "                continue\n",
    "           # print(\"{} has enough sample\".format(i))  \n",
    "            prevHome=prevHome.copy()\n",
    "            prevAway = prevAway.copy()\n",
    "            prevHome['HomeTeam']=(prevHome['HomeTeam']==homeName)\n",
    "            prevHome['AwayTeam']=(prevHome['AwayTeam']==homeName)\n",
    "            prevAway['HomeTeam']=(prevAway['HomeTeam']==awayName)\n",
    "            prevAway['AwayTeam']=(prevAway['AwayTeam']==awayName)\n",
    "            homeDate = prevHome['Date'].values\n",
    "            awayDate = prevAway['Date'].values\n",
    "            #homeDate = homeDate.astype('uint64')/1e9/24/60/60\n",
    "            homeDate = x['Date'] - homeDate \n",
    "            #awayDate = awayDate.astype('uint64')/1e9/24/60/60\n",
    "            awayDate = x['Date'] - awayDate \n",
    "            #print(homeDate)\n",
    "            hv = prevHome.drop('Date',axis=1).values\n",
    "            av = prevAway.drop('Date',axis=1).values\n",
    "            hv = np.column_stack([hv, homeDate])\n",
    "            av = np.column_stack([av,awayDate])\n",
    "            \n",
    "            inData = np.ravel(np.array([hv,av]))\n",
    "            res.append(inData)\n",
    "            resy.append(y[i])\n",
    "        \n",
    "        Xres = np.array(res)\n",
    "        \n",
    "       \n",
    "        X_train_std = Xres\n",
    "        print(\"finish\")\n",
    "\n",
    "        return (X_train_std,np.array(resy))\n",
    "            \n",
    "    def fit(self,X=None,y=None):\n",
    "        teams = self.df['HomeTeam'].drop_duplicates()\n",
    "       \n",
    "        if X is None or y is None:\n",
    "            (X, y)=self.formatData(df)\n",
    "        X_train,X_test_val, y_train, y_test_val =    train_test_split(X,y, test_size=0.4)\n",
    "        X_val ,X_test,y_val,y_test = train_test_split(X_test_val,y_test_val, test_size=0.5)\n",
    "        print(X_val)\n",
    "        \n",
    "        \n",
    "     \n",
    "        print(\"Start Training\")\n",
    "        self.nn.fit(X_train,y_train)\n",
    "        print(\"fisish Training\")\n",
    "        return (X_val ,X_test,y_val,y_test)\n",
    "\n",
    "    def validate(self, X_val, y_val):\n",
    "            return self.nn.predict(X_val)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    def previousRecords(self,team, date , recentNum):\n",
    "        prev = team[( team[\"Date\"] < date)]\n",
    "        \n",
    "        if prev.shape[0] < recentNum :\n",
    "            #print(\"less than min Num\")\n",
    "            return None\n",
    "        else:\n",
    "            return prev.iloc[-recentNum:]\n",
    "    def readPredict (self, filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        df['Date'] = pd.to_datetime(df['Date'],dayfirst=True)\n",
    "        df['FTR'] = df['FTR'].map(self.win_mapping)\n",
    "        return df\n",
    "    \n",
    "    def getH1(self):\n",
    "        #recent matches (only win/loss/draw)\n",
    "       \n",
    "        \n",
    "       # print (self.df)      \n",
    "        X  = self.df.sort_values(by=\"Date\")\n",
    "        y = []\n",
    "        for v in X['FTR']:\n",
    "            y.append(range(3)==v)\n",
    "       # print(y)\n",
    "        resy=[]\n",
    "        resx=[]\n",
    "        print(\"h1:start format\")\n",
    "        for i in range(X.shape[0]):\n",
    "            \n",
    "            sys.stdout.write(\"\\r progress {}\".format(i))\n",
    "            sys.stdout.flush()\n",
    "            x = X.iloc[i]\n",
    "            homeName = x['HomeTeam']\n",
    "            awayName = x['AwayTeam']\n",
    "            homeTeam = self.getTeam(X,homeName)\n",
    "            awayTeam = self.getTeam(X,awayName)\n",
    "            prevHome = self.previousRecords(homeTeam,x['Date'])\n",
    "            prevAway = self.previousRecords(awayTeam,x['Date'])\n",
    "            if prevHome is None or prevAway is None:\n",
    "               # print(\"{} skip\".format(i))\n",
    "                continue\n",
    "            prevHomeWin = []\n",
    "            prevAwayWin = []\n",
    "            for v in prevHome['FTR']:\n",
    "                prevHomeWin.append(range(3) == v)\n",
    "            #print(prevHomeWin)\n",
    "            for v in prevAway['FTR']:\n",
    "                prevAwayWin.append(range(3) == v)\n",
    "            pHHT=(prevHome['HomeTeam']==homeName).values\n",
    "            pAHT=(prevAway['HomeTeam']==awayName).values\n",
    "            tempX=[]\n",
    "            for j in range(pHHT.shape[0]):\n",
    "                tempX.append(np.append(prevHomeWin[j],pHHT[j]))\n",
    "                \n",
    "            for j in range(pAHT.shape[0]):\n",
    "                tempX.append(np.append(prevAwayWin[j],pAHT[j]))\n",
    "            resx.append(np.ravel(tempX))\n",
    "            \n",
    "            resy.append(y[i])\n",
    "        print(\"finish\")\n",
    "        sys.stdout.flush()\n",
    "        return np.array(resx), np.array(resy)\n",
    "    def getH2(self):         \n",
    "       #team based      \n",
    "        X  = self.df.sort_values(by=\"Date\")\n",
    "        y = []\n",
    "        for v in X['FTR']:\n",
    "            y.append(range(3)==v)\n",
    "       # print(y)\n",
    "        resy=[]\n",
    "        resx=[]\n",
    "        print(\"h1:start format\")\n",
    "        X['HomeTeam'] = X['HomeTeam'].map(self.teamsMap)\n",
    "        X['AwayTeam'] = X['AwayTeam'].map(self.teamsMap)\n",
    "        nativeX = X[['HomeTeam','AwayTeam']].values\n",
    "        #print(X)\n",
    "        ohe = OneHotEncoder(categorical_features=[0,1])\n",
    "        res = ohe.fit_transform(nativeX).toarray()\n",
    "        #print(res)\n",
    "        return res, np.array(y)\n",
    "    def _getH3RecentMatches(self,x, X,teamName,recentNum):\n",
    "        team = self.getTeam(X,teamName)\n",
    "        prev = self.previousRecords(team,x['Date'],recentNum)\n",
    "        if prev is None:\n",
    "               return None\n",
    "        prevHt=  prev['HomeTeam'].values\n",
    "        prevAt=  prev['AwayTeam'].values   \n",
    "        prevIsHome = []\n",
    "        prevOther = []\n",
    "        for i in range(recentNum):\n",
    "            if prevHt[i] == teamName:\n",
    "                prevIsHome.append(1)\n",
    "                prevOther.append(prevAt[i])\n",
    "            else:\n",
    "                prevIsHome.append(0)\n",
    "                prevOther.append(prevHt[i])\n",
    "        wins = prev['FTR'].values       \n",
    "        temp = np.array([prevIsHome,prevOther,wins]).T\n",
    "\n",
    "        return np.ravel(temp)\n",
    "        \n",
    "    def getH3(self, recentNum):\n",
    "        X  = self.df.sort_values(by=\"Date\")\n",
    "        X['HomeTeam'] = X['HomeTeam'].map(self.teamsMap)\n",
    "        X['AwayTeam'] = X['AwayTeam'].map(self.teamsMap)\n",
    "        y = []\n",
    "        for v in X['FTR']:\n",
    "            y.append(range(3)==v)\n",
    "       # print(y)\n",
    "        resy=[]\n",
    "        resx=[]\n",
    "        print(\"h3:start format\")\n",
    "        recents = []\n",
    "        for i in range(X.shape[0]):\n",
    "            \n",
    "            sys.stdout.write(\"\\r progress {}\".format(i))\n",
    "            sys.stdout.flush()\n",
    "            x = X.iloc[i]\n",
    "            homeName = x['HomeTeam']\n",
    "            awayName = x['AwayTeam']\n",
    "            homeRecent = self._getH3RecentMatches(x,X,homeName, recentNum)\n",
    "            awayRecent =self._getH3RecentMatches(x,X,awayName, recentNum)\n",
    "            if homeRecent is None or awayRecent is None:\n",
    "                   continue \n",
    "        #    print(homeName)\n",
    "         #   print(homeRecent)\n",
    "        #    print(awayName)\n",
    "         #   print(awayRecent)\n",
    "         #   return\n",
    "            recents.append(np.hstack([homeName,awayName, homeRecent,awayRecent]))        \n",
    "            resy.append(y[i])\n",
    "        cols =np.hstack([[0,1],list(range(3,len(recents[0]),3))])\n",
    "        print(cols)\n",
    "        ohe = OneHotEncoder(categorical_features=cols)\n",
    "        res = ohe.fit_transform(recents).toarray()\n",
    "        print(\"finish\")\n",
    "        sys.stdout.flush()\n",
    "        return res, np.array(resy)\n",
    "   \n",
    "\n",
    "    def getH4(self, recentNum, target=None):\n",
    "        \n",
    "        X  = self.df.sort_values(by=\"Date\")\n",
    "        isInput = False\n",
    "        if target is None:\n",
    "            target =X      \n",
    "        else:\n",
    "            if self.ohe is None:\n",
    "                raise Exception(\"Not yet get train data\")\n",
    "            isInput = True\n",
    "            target['HomeTeam']=target['HomeTeam'].map(self.teamsMap)\n",
    "            target['AwayTeam']=target['AwayTeam'].map(self.teamsMap)\n",
    "            pass\n",
    "            \n",
    "        X['HomeTeam'] = X['HomeTeam'].map(self.teamsMap)\n",
    "        X['AwayTeam'] = X['AwayTeam'].map(self.teamsMap)\n",
    "        target_date = (pd.to_numeric(target['Date'])/1e9/24/60/60).values\n",
    "        y = []\n",
    "        for v in target['FTR']:\n",
    "            y.append(range(3)==v)\n",
    "       # print(y)\n",
    "        resy=[]\n",
    "        resx=[]\n",
    "        print(\"h4:start format\")\n",
    "        recents = []\n",
    "        for i in range(target.shape[0]):\n",
    "            \n",
    "            sys.stdout.write(\"\\r progress {}\".format(i))\n",
    "            sys.stdout.flush()\n",
    "            x = target.iloc[i]\n",
    "            homeName = x['HomeTeam']\n",
    "            awayName = x['AwayTeam']\n",
    "            homeRecent = self._getH3RecentMatches(x,X,homeName, recentNum)\n",
    "            awayRecent =self._getH3RecentMatches(x,X,awayName, recentNum)\n",
    "            if homeRecent is None or awayRecent is None:\n",
    "                   continue \n",
    "           # print(homeName)\n",
    "           # print(homeRecent)\n",
    "          #  print(awayName)\n",
    "            #print(awayRecent)\n",
    "            if recentNum == 0:\n",
    "                recents.append(np.hstack([homeName,awayName,target_date[i]]))\n",
    "            else:\n",
    "                recents.append(np.hstack([homeName,awayName,target_date[i], homeRecent,awayRecent]))            \n",
    "            resy.append(y[i])\n",
    "#        print(recents)\n",
    "        if isInput==False:\n",
    "            cols = None\n",
    "            if recentNum == 0 :\n",
    "                cols = np.array([0,1])\n",
    "            else:\n",
    "                cols =np.hstack([[0,1],list(range(4,len(recents[0]),3))])\n",
    "            self.ohe = OneHotEncoder(categorical_features=cols)\n",
    "            self.ohe.fit(recents)\n",
    "\n",
    "        res = self.ohe.transform(recents).toarray()\n",
    "        print(\"finish\")\n",
    "        sys.stdout.flush()\n",
    "        return res, np.array(resy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from IPython.core.display import clear_output\n",
    "    have_ipython = True\n",
    "except ImportError:\n",
    "    have_ipython = False\n",
    "import sys\n",
    "def likehoodScore(proba,y):\n",
    "    return np.sum(proba * y)/proba.shape[0]\n",
    "\n",
    "def firstNScore(n, pred, y):\n",
    "    for r in range(pred.shape[0]):\n",
    "        row = pred[r]\n",
    "        s = np.sort(row)\n",
    "        for c in range(pred.shape[1]):\n",
    "            temp = pred[r][c]\n",
    "            pred[r][c] = False\n",
    "            for j in range(1,n+1):\n",
    "                if temp == s[-j]:\n",
    "                    pred[r][c] = True\n",
    "                    break\n",
    "    res = np.sum(np.logical_and(pred,y))/pred.shape[0]\n",
    "    return res               \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 21)\n",
      "(380, 21)\n",
      "(293, 21)\n",
      "{'Newcastle': 14, 'Leicester': 20, 'Aston Villa': 10, 'QPR': 21, 'Watford': 24, 'Swansea': 4, 'Sunderland': 3, 'Stoke': 16, 'Tottenham': 18, 'Man City': 9, 'Everton': 11, 'Man United': 19, 'Chelsea': 7, 'West Ham': 6, 'Cardiff': 17, 'Southampton': 15, 'Fulham': 12, 'West Brom': 5, 'Crystal Palace': 8, 'Liverpool': 1, 'Bournemouth': 23, 'Burnley': 22, 'Norwich': 2, 'Arsenal': 0, 'Hull': 13}\n"
     ]
    }
   ],
   "source": [
    "c = FootballDataHelper(recentNum=4)\n",
    "c.readFootBallData(\"E0_1314.csv\")\n",
    "c.readFootBallData(\"E0_1415.csv\")\n",
    "c.readFootBallData(\"E0 (1).csv\")\n",
    "print(c.teamsMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h4:start format\n",
      " progress 1052finish\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#alpha, hidden size, score, weighted Score\n",
    "\n",
    "#c.fit()\n",
    "#c.fit()\n",
    "#X, y = c.formatData(c.df)\n",
    "#print(X)\n",
    "X,y = c.getH4(4)\n",
    "#X, y =c.getH3(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date     HomeTeam     AwayTeam  FTR\n",
      "0 2016-03-12      Norwich     Man City    1\n",
      "1 2016-03-12  Bournemouth      Swansea    0\n",
      "2 2016-03-12        Stoke  Southampton    2\n",
      "3 2016-03-14  Aston Villa    Tottenham    2\n",
      "4 2016-03-15    Leicester    Newcastle    0\n",
      "h4:start format\n",
      " progress 4finish\n",
      "[[False  True False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]]\n"
     ]
    }
   ],
   "source": [
    "inData = c.readPredict(\"predict.csv\")\n",
    "print(inData)\n",
    "X_in, y_in = c.getH4(4,target=inData)\n",
    "print(y_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from custom import SoftMaxMLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "hiddenNodes = int(12)\n",
    "print(hiddenNodes)\n",
    "clf = SoftMaxMLPClassifier(hidden_layer_sizes=[hiddenNodes], activation='logistic', algorithm='l-bfgs', alpha=50, \n",
    "              learning_rate_init=0.01,learning_rate='adaptive' ,max_iter=1000,early_stopping = True,verbose = 3)\n",
    "mlp = Pipeline([('scl', StandardScaler()),('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SoftMaxMLPClassifier(activation='logistic', algorithm='l-bfgs', alpha=50,\n",
       "           batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "           early_stopping=True, epsilon=1e-08, hidden_layer_sizes=[12],\n",
       "           learn...e=None, shuffle=True, tol=0.0001,\n",
       "           validation_fraction=0.1, verbose=3, warm_start=False))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X,y)\n",
    "#res = mlp.predict(X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(993, 267)\n",
      "(5, 267)\n",
      "[[False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]]\n",
      "[[False  True False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]]\n",
      "0.8\n",
      "[[ 0.18845696  0.21467054  0.5968725 ]\n",
      " [ 0.67735162  0.16321294  0.15943545]\n",
      " [ 0.25909715  0.20545068  0.53545217]\n",
      " [ 0.35779591  0.18831749  0.4538866 ]\n",
      " [ 0.66308908  0.16588589  0.17102503]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_in.shape)\n",
    "res = mlp.predict(X_in)\n",
    "print(res)\n",
    "proba= mlp.predict_proba(X_in)\n",
    "print(y_in)\n",
    "print(mlp.score(X_in,y_in))\n",
    "print(proba)\n",
    "print(firstNScore(2,proba,y_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date        HomeTeam     AwayTeam  FTR    HO    DO    AO\n",
      "0 2016-03-19         Everton      Arsenal    1  2.45  3.35  2.45\n",
      "1 2016-03-19         Chelsea     West Ham    1  1.57  3.65  4.90\n",
      "2 2016-03-19  Crystal Palace    Leicester    1  2.83  3.15  2.25\n",
      "3 2016-03-19         Watford        Stoke    1  2.10  3.00  3.30\n",
      "4 2016-03-19       West Brom      Norwich    1  2.15  3.00  3.15\n",
      "5 2016-03-19         Swansea  Aston Villa    1  1.54  3.60  5.35\n",
      "h4:start format\n",
      " progress 5finish\n",
      "[[False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [ True False False]]\n",
      "[[ 0.18762952  0.22318651  0.58918397]\n",
      " [ 0.8517382   0.09704269  0.05121911]\n",
      " [ 0.29825403  0.20268259  0.49906338]\n",
      " [ 0.42604514  0.19004408  0.38391078]\n",
      " [ 0.47116997  0.19474191  0.33408812]\n",
      " [ 0.60173609  0.18333453  0.21492937]]\n"
     ]
    }
   ],
   "source": [
    "#future\n",
    "inData = c.readPredict(\"future.csv\")\n",
    "print(inData)\n",
    "X_in, y_in = c.getH4(4,target=inData)\n",
    "res = mlp.predict(X_in)\n",
    "proba= mlp.predict_proba(X_in)\n",
    "print (\"{}\\n{}\".format(res,proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434\n",
      "973\n"
     ]
    }
   ],
   "source": [
    "mlp.score(X,y)\n",
    "print(np.sum(np.argmax(res,axis=1) == np.argmax(y,axis=1)))\n",
    "print(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"start learning\")\n",
    "sys.stdout.flush()\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=mlp, \n",
    "                       X=X, \n",
    "                      y=y, \n",
    "                      train_sizes=np.linspace(0.1, 1.0, 4), \n",
    "                      cv=4,\n",
    "                     n_jobs=1,verbose=3)\n",
    "print(\"finishing\")   \n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def plotCurve(train_mean, train_std,test_mean,test_std,sizes):\n",
    "    plt.plot(sizes, train_mean, \n",
    "            color='blue', marker='o', \n",
    "            markersize=5, \n",
    "            label='training accuracy')\n",
    "    plt.fill_between(sizes, \n",
    "                  train_mean + train_std,\n",
    "                   train_mean - train_std, alpha=0.15, color='blue')\n",
    "\n",
    "    plt.plot(sizes, test_mean, \n",
    "              color='green', linestyle='--', \n",
    "              marker='s', markersize=5, \n",
    "             label='validation accuracy')\n",
    "    plt.fill_between(sizes, \n",
    "                      test_mean + test_std,\n",
    "                     test_mean - test_std, \n",
    "                    alpha=0.15, color='green')\n",
    "    plt.xlabel('x_range')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotCurve(train_mean,train_std,test_mean,test_std,train_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "def crossValidate(mlp, X,y, fold = 10):\n",
    "    y_label = np.argmax(y,axis=1)\n",
    "\n",
    "    kfold = StratifiedKFold(y=y_label, \n",
    "                             n_folds=fold,\n",
    "                            random_state=1)\n",
    "\n",
    "    scores = []\n",
    "    train_scores=[]\n",
    "    firstNScores = []\n",
    "    for k, (train, test) in enumerate(kfold):\n",
    "\n",
    "        mlp.fit(X[train], y[train])\n",
    "        score = mlp.score(X[test], y[test])\n",
    "        firstNScores.append(firstNScore(2, mlp.predict_proba(X[test]), y[test]))\n",
    "        train_scores.append(mlp.score(X[train],y[train]))\n",
    "        scores.append(score)\n",
    "        print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1, \n",
    "                    np.bincount(y_label[train]), score))    \n",
    "    return train_scores,scores, firstNScores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__warm_start': False, 'clf__beta_2': 0.999, 'clf__batch_size': 'auto', 'clf__early_stopping': True, 'clf__algorithm': 'l-bfgs', 'clf__nesterovs_momentum': True, 'clf': SoftMaxMLPClassifier(activation='logistic', algorithm='l-bfgs', alpha=10,\n",
      "           batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
      "           early_stopping=True, epsilon=1e-08, hidden_layer_sizes=[12],\n",
      "           learning_rate='adaptive', learning_rate_init=0.01, max_iter=500,\n",
      "           momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
      "           random_state=None, shuffle=True, tol=0.0001,\n",
      "           validation_fraction=0.1, verbose=3, warm_start=False), 'clf__shuffle': True, 'clf__learning_rate_init': 0.01, 'clf__activation': 'logistic', 'scl__with_std': True, 'clf__tol': 0.0001, 'clf__random_state': None, 'scl__copy': True, 'clf__epsilon': 1e-08, 'clf__hidden_layer_sizes': [12], 'scl__with_mean': True, 'clf__max_iter': 500, 'clf__momentum': 0.9, 'scl': StandardScaler(copy=True, with_mean=True, with_std=True), 'clf__learning_rate': 'adaptive', 'clf__alpha': 10, 'clf__validation_fraction': 0.1, 'clf__beta_1': 0.9, 'steps': [('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SoftMaxMLPClassifier(activation='logistic', algorithm='l-bfgs', alpha=10,\n",
      "           batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
      "           early_stopping=True, epsilon=1e-08, hidden_layer_sizes=[12],\n",
      "           learning_rate='adaptive', learning_rate_init=0.01, max_iter=500,\n",
      "           momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
      "           random_state=None, shuffle=True, tol=0.0001,\n",
      "           validation_fraction=0.1, verbose=3, warm_start=False))], 'clf__verbose': 3, 'clf__power_t': 0.5}\n",
      "Fold: 1, Class dist.: [183 347 248], Acc: 0.451\n",
      "Fold: 2, Class dist.: [183 347 248], Acc: 0.472\n",
      "Fold: 3, Class dist.: [183 347 248], Acc: 0.456\n",
      "Fold: 4, Class dist.: [183 347 248], Acc: 0.456\n",
      "Fold: 5, Class dist.: [184 348 248], Acc: 0.446\n",
      "lamda: 10, train: 0.9843260167424692, test: 0.4562986581639431\n",
      "{'clf__warm_start': False, 'clf__beta_2': 0.999, 'clf__batch_size': 'auto', 'clf__early_stopping': True, 'clf__algorithm': 'l-bfgs', 'clf__nesterovs_momentum': True, 'clf': SoftMaxMLPClassifier(activation='logistic', algorithm='l-bfgs', alpha=12,\n",
      "           batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
      "           early_stopping=True, epsilon=1e-08, hidden_layer_sizes=[12],\n",
      "           learning_rate='adaptive', learning_rate_init=0.01, max_iter=500,\n",
      "           momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
      "           random_state=None, shuffle=True, tol=0.0001,\n",
      "           validation_fraction=0.1, verbose=3, warm_start=False), 'clf__shuffle': True, 'clf__learning_rate_init': 0.01, 'clf__activation': 'logistic', 'scl__with_std': True, 'clf__tol': 0.0001, 'clf__random_state': None, 'scl__copy': True, 'clf__epsilon': 1e-08, 'clf__hidden_layer_sizes': [12], 'scl__with_mean': True, 'clf__max_iter': 500, 'clf__momentum': 0.9, 'scl': StandardScaler(copy=True, with_mean=True, with_std=True), 'clf__learning_rate': 'adaptive', 'clf__alpha': 12, 'clf__validation_fraction': 0.1, 'clf__beta_1': 0.9, 'steps': [('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SoftMaxMLPClassifier(activation='logistic', algorithm='l-bfgs', alpha=12,\n",
      "           batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
      "           early_stopping=True, epsilon=1e-08, hidden_layer_sizes=[12],\n",
      "           learning_rate='adaptive', learning_rate_init=0.01, max_iter=500,\n",
      "           momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
      "           random_state=None, shuffle=True, tol=0.0001,\n",
      "           validation_fraction=0.1, verbose=3, warm_start=False))], 'clf__verbose': 3, 'clf__power_t': 0.5}\n",
      "Fold: 1, Class dist.: [183 347 248], Acc: 0.415\n",
      "Fold: 2, Class dist.: [183 347 248], Acc: 0.477\n",
      "Fold: 3, Class dist.: [183 347 248], Acc: 0.451\n",
      "Fold: 4, Class dist.: [183 347 248], Acc: 0.436\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-1eebc3e16998>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0ml_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtrain_scores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlamda_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-62-1eebc3e16998>\u001b[0m in \u001b[0;36mlamda_test\u001b[1;34m(mlp, X, y, lamdas)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlamda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtrain_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrossValidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mtrain_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mtest_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-e7fa31a218ee>\u001b[0m in \u001b[0;36mcrossValidate\u001b[1;34m(mlp, X, y, fold)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mtrain_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/scikit-learn/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \"\"\"\n\u001b[0;32m    165\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/scikit-learn/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \"\"\"\n\u001b[1;32m--> 615\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/scikit-learn/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\u001b[1;32m--> 380\u001b[1;33m                             intercept_grads, layer_units)\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/scikit-learn/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[0;32m    463\u001b[0m             \u001b[0miprint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miprint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m             \u001b[0mpgtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m             args=(X, y, activations, deltas, coef_grads, intercept_grads))\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimal_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/anaconda3/lib/python3.5/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[1;32m--> 193\u001b[1;33m                            **opts)\n\u001b[0m\u001b[0;32m    194\u001b[0m     d = {'grad': res['jac'],\n\u001b[0;32m    195\u001b[0m          \u001b[1;34m'task'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/anaconda3/lib/python3.5/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    328\u001b[0m                 \u001b[1;31m# minimization routine wants f and g at the current x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/anaconda3/lib/python3.5/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/anaconda3/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/anaconda3/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/scikit-learn/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[1;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_coef_inter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         loss, coef_grads, intercept_grads = self._backprop(\n\u001b[1;32m--> 177\u001b[1;33m             X, y, activations, deltas, coef_grads, intercept_grads)\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoef_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/scikit-learn/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_backprop\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;31m# Iterate over the hidden layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m             \u001b[0mderivative\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDERIVATIVES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mderivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/scikit-learn/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def lamda_test(mlp, X, y, lamdas):\n",
    "    \n",
    "    train_scores=[]\n",
    "    test_scores=[]\n",
    "    for lamda in lamdas:\n",
    "        clf.set_params(alpha= lamda)\n",
    "        print(mlp.get_params())\n",
    "        train_s, test_s = crossValidate(mlp,X,y,fold=5)\n",
    "        train_scores.append(train_s)\n",
    "        test_scores.append(test_s)\n",
    "        print(\"lamda: {}, train: {}, test: {}\".format(lamda, \n",
    "                    np.mean(train_s), np.mean(test_s)) )\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    plotCurve(train_mean,train_std,test_mean,test_std,lamdas)\n",
    "    return np.array(train_scores),np.array(test_scores)\n",
    "\n",
    "l_range = np.array(range(10,100,2))\n",
    "train_scores,test_scores = lamda_test(mlp,X,y,l_range)\n",
    "#50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\n",
    "#plotCurve(train_mean,train_std,test_mean,test_std,l_range)\n",
    "plt.plot(l_range, train_mean, \n",
    "        color='blue', marker='o', \n",
    "        markersize=5, \n",
    "        label='training accuracy')\n",
    "plt.fill_between(l_range, \n",
    "              train_mean + train_std,\n",
    "               train_mean - train_std, alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(l_range, test_mean, \n",
    "          color='green', linestyle='--', \n",
    "          marker='s', markersize=5, \n",
    "         label='validation accuracy')\n",
    "plt.fill_between(l_range, \n",
    "                  test_mean + test_std,\n",
    "                 test_mean - test_std, \n",
    "                alpha=0.15, color='green')\n",
    "plt.xlabel('lamda')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y,test_size =0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SoftMaxMLPClassifier(activation='logistic', algorithm='l-bfgs', alpha=50,\n",
       "           batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "           early_stopping=True, epsilon=1e-08, hidden_layer_sizes=[12],\n",
       "           learn...e=None, shuffle=True, tol=0.0001,\n",
       "           validation_fraction=0.1, verbose=3, warm_start=False))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = mlp.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47602739726\n",
      "0.770547945205\n"
     ]
    }
   ],
   "source": [
    "predicted = mlp.predict(X_test)\n",
    "print(mlp.score(X_test, y_test))\n",
    "proba = mlp.predict_proba(X_test)\n",
    "\n",
    "print(firstNScore(2,proba,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likehoodScore(res,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "home_teams_test = np.argmax(X_test[:,0:len(c.teamsMap)],axis=1)\n",
    "away_teams_test = np.argmax(X_test[:,len(c.teamsMap):len(c.teamsMap)*2],axis=1)\n",
    "inverseMap ={}\n",
    "for name in c.teamsMap.keys():        \n",
    "    inverseMap[c.teamsMap[name]] = name\n",
    "\n",
    "home_name =[]\n",
    "away_name =[]\n",
    "for i in range(home_teams_test.shape[0]):         \n",
    "    home_name.append(inverseMap[home_teams_test[i]])\n",
    "    away_name.append(inverseMap[away_teams_test[i]])\n",
    "pre_y = np.argmax(predicted,axis=1)\n",
    "real_y = np.argmax(y_test,axis=1)\n",
    "for i in range(predicted.shape[0]):\n",
    "    if pre_y[i] != real_y[i]:\n",
    "        print('-------------')\n",
    "        print(\"{} vs {}\".format(home_name[i],away_name[i]))\n",
    "        print(\"{} vs {}\".format(res[i],y_test[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#c.df[(c.df['HomeTeam'] == 'West Brom') | (c.df['AwayTeam']=='West Brom')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from custom import SoftMaxMLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def testNodeSize(start ,end):\n",
    "    node_range = range(start,end,25)\n",
    "    train_means = []\n",
    "    train_std = []\n",
    "    test_means =[]\n",
    "    test_std=[]\n",
    "    for node in node_range:   \n",
    "        print(\"start node:{}\".format(node))\n",
    "        clf = SoftMaxMLPClassifier(hidden_layer_sizes=[node], activation='logistic', algorithm='l-bfgs', alpha=30, \n",
    "                  learning_rate_init=0.01,learning_rate='adaptive' ,max_iter=500,early_stopping = True,verbose = 3)\n",
    "        mlp = Pipeline([('scl', StandardScaler()),('clf', clf)])\n",
    "        train_scores,test_scores = crossValidate(mlp,X,y,fold=5)\n",
    "        train_means.append(np.mean(train_scores))\n",
    "        train_std.append(np.std(train_scores))\n",
    "        test_means.append(np.mean(test_scores))\n",
    "        test_std.append(np.std(test_scores))\n",
    "        print(\"Node {}: train_mean {}  v.s. test_mean {}\".format(node,np.mean(train_scores),np.mean(test_scores)))\n",
    "    plotCurve(train_means,train_std,test_means,test_std,node_range)\n",
    "    return train_means,train_std,test_means,test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_means,train_std,test_means,test_std=testNodeSize(10 , X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from custom import SoftMaxMLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def testRecentNum(start, end):\n",
    "    recent_range = range(start,end)\n",
    "    train_means = []\n",
    "    train_std = []\n",
    "    test_means =[]\n",
    "    test_std=[]\n",
    "    first2_mean=[]\n",
    "    for recent in recent_range:\n",
    "        print(\"start recent:{}\".format(recent))\n",
    "        X,y = c.getH4(recent)\n",
    "        clf = SoftMaxMLPClassifier(hidden_layer_sizes=[12], activation='logistic', algorithm='l-bfgs', alpha=30, \n",
    "                  learning_rate_init=0.01,learning_rate='adaptive' ,max_iter=500,early_stopping = True,verbose = 3)\n",
    "        mlp = Pipeline([('scl', StandardScaler()),('clf', clf)])\n",
    "        train_scores,test_scores, first2 = crossValidate(mlp,X,y,fold=10)\n",
    "        train_means.append(np.mean(train_scores))\n",
    "        train_std.append(np.std(train_scores))\n",
    "        test_means.append(np.mean(test_scores))\n",
    "        test_std.append(np.std(test_scores))\n",
    "        first2_mean.append(np.mean(first2))\n",
    "        print(\"recent {}: train_mean {}  v.s. test_mean {} , first2_mean {}\".format(\n",
    "                recent,np.mean(train_scores),np.mean(test_scores),np.mean(first2)))\n",
    "    plotCurve(train_means,train_std,test_means,test_std,recent_range)\n",
    "    return train_means,train_std,test_means,test_std,first2_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start recent:0\n",
      "h4:start format\n",
      " progress 1047finish\n",
      "Fold: 1, Class dist.: [225 419 298], Acc: 0.528\n",
      "Fold: 2, Class dist.: [225 419 298], Acc: 0.566\n",
      "Fold: 3, Class dist.: [225 419 299], Acc: 0.562\n",
      "Fold: 4, Class dist.: [225 419 299], Acc: 0.533\n",
      "Fold: 5, Class dist.: [225 419 299], Acc: 0.467\n",
      "Fold: 6, Class dist.: [225 419 299], Acc: 0.533\n",
      "Fold: 7, Class dist.: [225 420 299], Acc: 0.548\n",
      "Fold: 8, Class dist.: [225 420 299], Acc: 0.490\n",
      "Fold: 9, Class dist.: [225 420 299], Acc: 0.423\n",
      "Fold: 10, Class dist.: [225 420 299], Acc: 0.481\n",
      "recent 0: train_mean 0.5462242046630976  v.s. test_mean 0.5131885410187297 , first2_mean 0.7547619047619047\n",
      "start recent:1\n",
      "h4:start format\n",
      " progress 1047finish\n",
      "Fold: 1, Class dist.: [222 415 291], Acc: 0.514\n",
      "Fold: 2, Class dist.: [222 415 291], Acc: 0.571\n",
      "Fold: 3, Class dist.: [222 416 291], Acc: 0.538\n",
      "Fold: 4, Class dist.: [222 416 291], Acc: 0.529\n",
      "Fold: 5, Class dist.: [222 416 292], Acc: 0.495\n",
      "Fold: 6, Class dist.: [222 416 292], Acc: 0.495\n",
      "Fold: 7, Class dist.: [222 416 292], Acc: 0.505\n",
      "Fold: 8, Class dist.: [223 416 292], Acc: 0.471\n",
      "Fold: 9, Class dist.: [223 416 292], Acc: 0.471\n",
      "Fold: 10, Class dist.: [223 416 292], Acc: 0.471\n",
      "recent 1: train_mean 0.5693191533640649  v.s. test_mean 0.5059932314972292 , first2_mean 0.7521882262987345\n",
      "start recent:2\n",
      "h4:start format\n",
      " progress 1047finish\n",
      "Fold: 1, Class dist.: [217 407 289], Acc: 0.471\n",
      "Fold: 2, Class dist.: [217 407 289], Acc: 0.615\n",
      "Fold: 3, Class dist.: [218 407 290], Acc: 0.471\n",
      "Fold: 4, Class dist.: [218 408 290], Acc: 0.485\n",
      "Fold: 5, Class dist.: [218 408 290], Acc: 0.505\n",
      "Fold: 6, Class dist.: [218 408 290], Acc: 0.485\n",
      "Fold: 7, Class dist.: [218 408 290], Acc: 0.465\n",
      "Fold: 8, Class dist.: [218 408 290], Acc: 0.446\n",
      "Fold: 9, Class dist.: [218 408 290], Acc: 0.446\n",
      "Fold: 10, Class dist.: [218 408 290], Acc: 0.446\n",
      "recent 2: train_mean 0.5876755671969731  v.s. test_mean 0.4834354419604857 , first2_mean 0.7628957409315592\n",
      "start recent:3\n",
      "h4:start format\n",
      " progress 1047finish\n",
      "Fold: 1, Class dist.: [214 401 287], Acc: 0.455\n",
      "Fold: 2, Class dist.: [214 401 287], Acc: 0.564\n",
      "Fold: 3, Class dist.: [214 401 287], Acc: 0.436\n",
      "Fold: 4, Class dist.: [214 401 287], Acc: 0.485\n",
      "Fold: 5, Class dist.: [214 401 287], Acc: 0.515\n",
      "Fold: 6, Class dist.: [214 401 287], Acc: 0.495\n",
      "Fold: 7, Class dist.: [214 402 287], Acc: 0.480\n",
      "Fold: 8, Class dist.: [214 402 287], Acc: 0.490\n",
      "Fold: 9, Class dist.: [215 402 287], Acc: 0.404\n",
      "Fold: 10, Class dist.: [215 402 288], Acc: 0.418\n",
      "recent 3: train_mean 0.6340988321119355  v.s. test_mean 0.47429028004841295 , first2_mean 0.7538252662000894\n",
      "start recent:4\n",
      "h4:start format\n",
      " progress 1047finish\n",
      "Fold: 1, Class dist.: [207 396 284], Acc: 0.436\n",
      "Fold: 2, Class dist.: [208 397 284], Acc: 0.515\n",
      "Fold: 3, Class dist.: [208 397 284], Acc: 0.485\n",
      "Fold: 4, Class dist.: [208 397 284], Acc: 0.505\n",
      "Fold: 5, Class dist.: [208 397 284], Acc: 0.505\n",
      "Fold: 6, Class dist.: [208 397 284], Acc: 0.525\n",
      "Fold: 7, Class dist.: [208 397 285], Acc: 0.490\n",
      "Fold: 8, Class dist.: [208 397 285], Acc: 0.469\n",
      "Fold: 9, Class dist.: [208 397 285], Acc: 0.480\n",
      "Fold: 10, Class dist.: [208 397 285], Acc: 0.408\n",
      "recent 4: train_mean 0.6763397924891401  v.s. test_mean 0.48179358752201756 , first2_mean 0.7550158077032193\n",
      "start recent:5\n",
      "h4:start format\n",
      " progress 1047finish\n",
      "Fold: 1, Class dist.: [206 390 279], Acc: 0.408\n",
      "Fold: 2, Class dist.: [206 390 279], Acc: 0.480\n",
      "Fold: 3, Class dist.: [206 390 279], Acc: 0.480\n",
      "Fold: 4, Class dist.: [206 390 279], Acc: 0.500\n",
      "Fold: 5, Class dist.: [206 391 279], Acc: 0.526\n",
      "Fold: 6, Class dist.: [206 391 279], Acc: 0.464\n",
      "Fold: 7, Class dist.: [206 391 279], Acc: 0.454\n",
      "Fold: 8, Class dist.: [206 391 279], Acc: 0.423\n",
      "Fold: 9, Class dist.: [206 391 279], Acc: 0.392\n",
      "Fold: 10, Class dist.: [207 391 279], Acc: 0.417\n",
      "recent 5: train_mean 0.7323323477936183  v.s. test_mean 0.45417455642050636 , first2_mean 0.7338577828038432\n",
      "start recent:6\n",
      "h4:start format\n",
      " progress 1047finish\n",
      "Fold: 1, Class dist.: [205 383 273], Acc: 0.485\n",
      "Fold: 2, Class dist.: [205 383 273], Acc: 0.474\n",
      "Fold: 3, Class dist.: [205 383 273], Acc: 0.433\n",
      "Fold: 4, Class dist.: [205 383 273], Acc: 0.474\n",
      "Fold: 5, Class dist.: [205 383 274], Acc: 0.490\n",
      "Fold: 6, Class dist.: [205 383 274], Acc: 0.396\n",
      "Fold: 7, Class dist.: [205 384 274], Acc: 0.474\n",
      "Fold: 8, Class dist.: [205 384 274], Acc: 0.495\n",
      "Fold: 9, Class dist.: [206 384 274], Acc: 0.468\n",
      "Fold: 10, Class dist.: [206 384 274], Acc: 0.404\n",
      "recent 6: train_mean 0.7783577925462005  v.s. test_mean 0.4592157526273459 , first2_mean 0.745460555177151\n",
      "start recent:7\n",
      "h4:start format\n",
      " progress 1047finish\n",
      "Fold: 1, Class dist.: [202 378 269], Acc: 0.442\n",
      "Fold: 2, Class dist.: [202 378 269], Acc: 0.389\n",
      "Fold: 3, Class dist.: [202 378 269], Acc: 0.389\n",
      "Fold: 4, Class dist.: [202 378 269], Acc: 0.442\n",
      "Fold: 5, Class dist.: [202 378 269], Acc: 0.442\n",
      "Fold: 6, Class dist.: [203 378 269], Acc: 0.426\n",
      "Fold: 7, Class dist.: [203 378 269], Acc: 0.500\n",
      "Fold: 8, Class dist.: [203 378 269], Acc: 0.404\n",
      "Fold: 9, Class dist.: [203 378 269], Acc: 0.362\n",
      "Fold: 10, Class dist.: [203 378 270], Acc: 0.376\n",
      "recent 7: train_mean 0.8143829600252653  v.s. test_mean 0.417309660561837 , first2_mean 0.7276292309359536\n",
      "start recent:8\n",
      "h4:start format\n",
      " progress 1047finish\n",
      "Fold: 1, Class dist.: [198 373 264], Acc: 0.432\n",
      "Fold: 2, Class dist.: [199 373 264], Acc: 0.372\n",
      "Fold: 3, Class dist.: [199 373 264], Acc: 0.415\n",
      "Fold: 4, Class dist.: [199 373 264], Acc: 0.447\n",
      "Fold: 5, Class dist.: [199 373 265], Acc: 0.441\n",
      "Fold: 6, Class dist.: [199 374 265], Acc: 0.424\n",
      "Fold: 7, Class dist.: [199 374 265], Acc: 0.489\n",
      "Fold: 8, Class dist.: [199 374 265], Acc: 0.424\n",
      "Fold: 9, Class dist.: [199 374 265], Acc: 0.348\n",
      "Fold: 10, Class dist.: [199 374 265], Acc: 0.348\n",
      "recent 8: train_mean 0.8604620503459721  v.s. test_mean 0.4139090411265848 , first2_mean 0.7194194574496879\n",
      "start recent:9\n",
      "h4:start format\n",
      " progress 1047finish\n",
      "Fold: 1, Class dist.: [197 365 261], Acc: 0.435\n",
      "Fold: 2, Class dist.: [197 365 261], Acc: 0.359\n",
      "Fold: 3, Class dist.: [197 365 261], Acc: 0.435\n",
      "Fold: 4, Class dist.: [197 365 261], Acc: 0.380\n",
      "Fold: 5, Class dist.: [197 365 261], Acc: 0.424\n",
      "Fold: 6, Class dist.: [197 365 261], Acc: 0.435\n",
      "Fold: 7, Class dist.: [197 366 261], Acc: 0.451\n",
      "Fold: 8, Class dist.: [197 366 261], Acc: 0.396\n",
      "Fold: 9, Class dist.: [197 366 261], Acc: 0.429\n",
      "Fold: 10, Class dist.: [198 366 261], Acc: 0.378\n",
      "recent 9: train_mean 0.8943544790351818  v.s. test_mean 0.41198943568508783 , first2_mean 0.7266048203004726\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-f92fdb058ed9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_means\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_means\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfirst2_mean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtestRecentNum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-117-9941633c0fb1>\u001b[0m in \u001b[0;36mtestRecentNum\u001b[1;34m(start, end)\u001b[0m\n\u001b[0;32m     26\u001b[0m         print(\"recent {}: train_mean {}  v.s. test_mean {} , first2_mean {}\".format(\n\u001b[0;32m     27\u001b[0m                 recent,np.mean(train_scores),np.mean(test_scores),np.mean(first2)))\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mplotCurve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_means\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_means\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecent_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_means\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_means\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfirst2_mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-ddfd518f904c>\u001b[0m in \u001b[0;36mplotCurve\u001b[1;34m(train_mean, train_std, test_mean, test_std, sizes)\u001b[0m\n\u001b[0;32m      8\u001b[0m     plt.fill_between(sizes, \n\u001b[0;32m      9\u001b[0m                   \u001b[0mtrain_mean\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtrain_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                    train_mean - train_std, alpha=0.15, color='blue')\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     plt.plot(sizes, test_mean, \n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'list'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f543fdeb0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_means,train_std,test_means,test_std,first2_mean=testRecentNum(0 ,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
