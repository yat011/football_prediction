{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "try:\n",
    "    from IPython.core.display import clear_output\n",
    "    have_ipython = True\n",
    "except ImportError:\n",
    "    have_ipython = False\n",
    "import sys\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotCurve(train_mean, train_std,test_mean,test_std,sizes):\n",
    "    plt.plot(sizes, train_mean, \n",
    "            color='blue', marker='o', \n",
    "            markersize=5, \n",
    "            label='training accuracy')\n",
    "    plt.fill_between(sizes, \n",
    "                  train_mean + train_std,\n",
    "                   train_mean - train_std, alpha=0.15, color='blue')\n",
    "\n",
    "    plt.plot(sizes, test_mean, \n",
    "              color='green', linestyle='--', \n",
    "              marker='s', markersize=5, \n",
    "             label='validation accuracy')\n",
    "    plt.fill_between(sizes, \n",
    "                      test_mean + test_std,\n",
    "                     test_mean - test_std, \n",
    "                    alpha=0.15, color='green')\n",
    "    plt.xlabel('x_range')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "def likehoodScore(proba,y):\n",
    "    return np.sum(proba * y)/proba.shape[0]\n",
    "\n",
    "def firstNScore(n, pred, y):\n",
    "    backup = np.array(pred, copy =True)\n",
    "    for r in range(pred.shape[0]):\n",
    "        row = backup[r]\n",
    "        s = np.sort(row)\n",
    "        for c in range(pred.shape[1]):\n",
    "            temp = backup[r][c]\n",
    "            backup[r][c] = False\n",
    "            for j in range(1,n+1):\n",
    "                if temp == s[-j]:\n",
    "                    backup[r][c] = True\n",
    "                    break\n",
    "    res = np.sum(np.logical_and(backup,y))/pred.shape[0]\n",
    "    return res               \n",
    "\n",
    "def oneHotDecode(self, X_sample):\n",
    "    result=None\n",
    "    fiPos = 0\n",
    "    colIndex = 0\n",
    "    while colIndex < X_sample.shape[1]:\n",
    "        if fiPos < len(self.ohe.n_values_) and colIndex == self.ohe.feature_indices_[fiPos]:                \n",
    "            start = self.ohe.feature_indices_[fiPos]\n",
    "            end_ = start+ self.ohe.n_values_[fiPos]\n",
    "            #print(\"start{} end{}\".format(start,end_))\n",
    "            classes = np.argmax(X_sample[:,start:end_],axis=1).reshape(X_sample.shape[0],1)\n",
    "            if result is None:\n",
    "                result = classes\n",
    "            else:\n",
    "                result=np.hstack([result,classes])\n",
    "            colIndex = end_\n",
    "            fiPos = fiPos +1\n",
    "        else:\n",
    "            if result is None:\n",
    "                result = X_sample[:,colIndex:colIndex+1]\n",
    "            else:\n",
    "                result=np.hstack([result, X_sample[:,colIndex:colIndex+1]])\n",
    "            colIndex = colIndex +1\n",
    "        \n",
    "    return result \n",
    "def convertToDate(dayStamps):\n",
    "    res = [] \n",
    "    for v in dayStamps:\n",
    "        res.append(datetime.datetime.fromtimestamp(float(v)*24*60*60))\n",
    "    return res\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def precisionMatrix(proba, y):\n",
    "    def _precisionClassify(df,proba, wins, c =0 ):\n",
    "        for indx, v in enumerate(proba):\n",
    "            row = 0\n",
    "            col = 0\n",
    "            if wins[indx] == c:\n",
    "                col = 0\n",
    "            else:\n",
    "                col =1\n",
    "            if v <0.2:\n",
    "                row =6 \n",
    "            elif v < 0.3 and  v >=0.2:\n",
    "                row =5 \n",
    "            elif v < 0.4 and v >= 0.3:\n",
    "                row = 4 \n",
    "            elif v < 0.5 and v >= 0.4:\n",
    "                row = 3 \n",
    "            elif v < 0.6 and v >= 0.5:\n",
    "                row = 2 \n",
    "            elif v < 0.8 and v >= 0.6:\n",
    "                row = 1\n",
    "            df.iloc[row,col] = df.iloc[row,col]+1 \n",
    "        df[df.columns[2]] = df[df.columns[0]] /(df[df.columns[1]] + df[df.columns[0]])\n",
    "        return df\n",
    "    rowHeader = ['>80','60-80','50-60','40-50','30-40','20-30','<20']\n",
    "    df = pd.DataFrame(np.zeros(shape=(7,3)),index=rowHeader, columns=['h_Correct', 'h_Wrong','h_Precent'])\n",
    "    hproba = proba[:,0]\n",
    "    wins = np.argmax(y,axis=1)\n",
    "    df = _precisionClassify(df,hproba,wins)\n",
    "    temp = pd.DataFrame(np.zeros(shape=(7,3)),index=rowHeader, columns=['d_Correct', 'd_Wrong','d_Precent'])\n",
    "    dproba = proba[:,1]\n",
    "    df = df.join(_precisionClassify(temp,dproba,wins,c=1))\n",
    "    temp = pd.DataFrame(np.zeros(shape=(7,3)),index=rowHeader, columns=['a_Correct', 'a_Wrong','a_Precent'])\n",
    "    aproba = proba[:,2]\n",
    "    df = df.join(_precisionClassify(temp,aproba,wins,c=2))\n",
    "    \n",
    "    bound = pd.DataFrame(np.array([[0.8,1.0],[0.6,0.8],[0.5,0.6],[0.4,0.5],[0.3,0.4],[0.2,0.3],[0,0.2]] )\n",
    "                                ,index=rowHeader, columns=['[lower', 'upper)'])\n",
    "            \n",
    "    return bound.join(df)\n",
    "       \n",
    "from datetime import date, timedelta\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "def futureTest(mlp, X,y,numOfWeek = 10,verbose=False):\n",
    "    decoded = oneHotDecode(c, X)\n",
    "    dates = convertToDate(X[:,c.dateColumn])\n",
    "    dates = [d - timedelta(days=2) for d in dates]    \n",
    "    weeks  = [ v.isocalendar()[1] for v in dates]\n",
    "    thisWeek = weeks[-1]\n",
    "    start = -1\n",
    "    last = X.shape[0]\n",
    "    index = -1\n",
    "    w = 0\n",
    "    sum_proba =None \n",
    "    sum_y =None\n",
    "    sum_train_proba=None\n",
    "    sum_train_y=None\n",
    "    while w < numOfWeek:\n",
    "        if thisWeek != weeks[index]:\n",
    "            start = X.shape[0] +index+1\n",
    "            X_train = X[0:start, :]\n",
    "            X_test = X[start:last,:]\n",
    "            y_train = y[0:start,:]\n",
    "            y_test = y[start:last,:]\n",
    "            mlp.fit(X_train,y_train)\n",
    "            decoded = oneHotDecode(c,X_test)\n",
    "            home = np.array([c.inverseTeamMapping(decoded[:,0])]).reshape(X_test.shape[0],1)\n",
    "            away = np.array([c.inverseTeamMapping(decoded[:,1])]).reshape(X_test.shape[0],1)\n",
    "            stack = np.hstack([home,away])\n",
    "            proba = mlp.predict_proba(X_test)\n",
    "            train_proba =mlp.predict_proba(X_train)\n",
    "            errorIndx = np.argmax(proba,axis=1) != np.argmax(y_test,axis=1)\n",
    "            if sum_proba is None:\n",
    "                sum_proba = proba\n",
    "                sum_y = y_test\n",
    "                sum_train_proba = train_proba\n",
    "                sum_train_y = y_train\n",
    "            else:\n",
    "                sum_proba = np.vstack([sum_proba,proba])\n",
    "                sum_y = np.vstack([sum_y,y_test])\n",
    "                sum_train_proba = np.vstack([sum_train_proba, train_proba])\n",
    "                sum_train_y= np.vstack([sum_train_y, y_train])\n",
    "            if verbose == True:\n",
    "                print(\"week{}\".format(w))\n",
    "                print(\"numOftest {} , score {}\".format(X_test.shape[0],mlp.score(X_test,y_test)))\n",
    "                print(np.hstack([stack[errorIndx],proba[errorIndx],y_test[errorIndx]]))\n",
    "                print(\"first2 : {}\",firstNScore(2,proba,y_test))\n",
    "            last = start\n",
    "            thisWeek = weeks[index]\n",
    "            w = w+1\n",
    "        index = index -1\n",
    "        \n",
    "    print(\"summary\")\n",
    "    print(\"score:\")\n",
    "    score = firstNScore(1,sum_proba,sum_y)\n",
    "    print(score)\n",
    "    print(\"2like\")\n",
    "    like2 = firstNScore(2,sum_proba,sum_y)\n",
    "    print(precisionMatrix(sum_proba,sum_y))\n",
    "    y_true= np.argmax(sum_y,axis=1)\n",
    "    y_pred = np.argmax(sum_proba,axis=1)\n",
    "    print(\"sum precision:{}\".format(precision_score(y_true,y_pred,average=None)))\n",
    "    return firstNScore(1,sum_train_proba,sum_train_y), score, like2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "class FootballDataHelper:\n",
    "    def __init__ (self, recentNum=5):\n",
    "        self.win_mapping = {'H':0, 'D':1,'A':2}\n",
    "        self.recentNum = recentNum\n",
    "        self.df = None\n",
    "        self.teamsData={}\n",
    "        self.session = 0\n",
    "        self.generalList =['HS','AS','HST','AST','H_poss' ,'A_poss' ,'H_atk_3rd', 'A_atk_3rd',\n",
    " 'H_atk_3rd_tot', 'A_atk_3rd_tot','H_red_goal' ,'A_red_goal' ,'H_red_on',\n",
    " 'A_red_on' ,'H_red_tot' ,'A_red_tot' ,'H_chance_goal' ,'A_chance_goal',\n",
    " 'H_chance_tot', 'A_chance_tot' ,'H_successful_tackle', 'A_successful_tackle',\n",
    " 'H_tackle_tot', 'A_tackle_tot', 'H_successful_clearance',\n",
    " 'A_successful_clearance', 'H_clearance_tot' ,'A_clearance_tot',\n",
    " 'H_interceptions' ,'A_interceptions', 'H_blocks', 'A_blocks']\n",
    "        #self.hiddensCount = 2\n",
    "       \n",
    "    def addColumns(self,df, addition):    \n",
    "        dates = df[\"Date\"].drop_duplicates().values\n",
    "        col_adds = []\n",
    "        for colAdd in addition.columns:\n",
    "             if colAdd not in df.columns:\n",
    "                    df[colAdd]=np.zeros(shape=(df.shape[0],))\n",
    "                    col_adds.append(colAdd)\n",
    "        for date in dates:\n",
    "            dateAddition= addition[addition['Date'] == date].sort(columns='HomeTeam')\n",
    "            dateDf  = df [df['Date']==date].sort(columns='HomeTeam')\n",
    "            for col in col_adds:\n",
    "                dateDf[col] = dateAddition[col].values\n",
    "            df.update(dateDf)\n",
    "        return df\n",
    "            \n",
    "    def saveDf(self,filename):\n",
    "        self.df.to_csv(filename,index=False)\n",
    "    def loadDf(self,filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])    \n",
    "        self.df = df\n",
    "        teams = self.df['HomeTeam'].drop_duplicates()\n",
    "        teamMap = {}\n",
    "        for index , v in enumerate(teams):\n",
    "            teamMap[v] = index\n",
    "        self.teamsMap = teamMap\n",
    "        referees = self.df['Referee'].drop_duplicates()\n",
    "        refereesMap = {}\n",
    "        for index , v in enumerate(referees):\n",
    "            refereesMap[v] = index+1\n",
    "\n",
    "        self.refereesMap = refereesMap\n",
    "    def readFootBallData(self,year): \n",
    "        filename = \"dataSet/E{}.csv\".format(year)\n",
    "        df = pd.read_csv(filename)\n",
    "        #df = df.drop(df.columns[range(23,df.shape[1])], axis=1)\n",
    "        #df = df.drop(\"Div\",axis=1)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df['session'] = pd.Series(np.ones(shape=(df.shape[0],))*self.session, index=df.index)\n",
    "        self.session = self.session +1\n",
    "        \n",
    "        matchDetail = pd.read_csv(\"dataSet/match{}.csv\".format(year))\n",
    "        matchDetail['Date'] =pd.to_datetime(matchDetail['Date'])\n",
    "        df = self.addColumns(df,matchDetail)\n",
    "        \n",
    "        df[\"Future\"] = np.zeros(shape=(df.shape[0],))\n",
    "        \n",
    "        if self.df is None:\n",
    "            self.df = df\n",
    "        else:\n",
    "            self.df = pd.concat([self.df,df])\n",
    "            \n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        teams = self.df['HomeTeam'].drop_duplicates()\n",
    "        teamMap = {}\n",
    "        for index , v in enumerate(teams):\n",
    "            teamMap[v] = index\n",
    "        self.teamsMap = teamMap\n",
    "        referees = self.df['Referee'].drop_duplicates()\n",
    "        refereesMap = {}\n",
    "        for index , v in enumerate(referees):\n",
    "            refereesMap[v] = index+1\n",
    "\n",
    "        self.refereesMap = refereesMap\n",
    "    def readFuture(self):\n",
    "        filename = \"dataSet/future.csv\"\n",
    "        df = pd.read_csv(filename)\n",
    "        #df = df.drop(df.columns[range(23,df.shape[1])], axis=1)\n",
    "        #df = df.drop(\"Div\",axis=1)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df[\"Future\"] = np.ones(shape=(df.shape[0],))\n",
    "        if self.df is None:\n",
    "            self.df = df\n",
    "        else:\n",
    "            self.df = pd.concat([self.df,df])\n",
    "            \n",
    "        self.df['HTR']=self.df['HTR'].fillna('D')\n",
    "        self.df = self.df.fillna(0)\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        teams = self.df['HomeTeam'].drop_duplicates()\n",
    "        teamMap = {}\n",
    "        for index , v in enumerate(teams):\n",
    "            teamMap[v] = index\n",
    "        self.teamsMap = teamMap\n",
    "        referees = self.df['Referee'].drop_duplicates()\n",
    "        refereesMap = {}\n",
    "        for index , v in enumerate(referees):\n",
    "            refereesMap[v] = index+1\n",
    "\n",
    "        self.refereesMap = refereesMap\n",
    "        \n",
    "    def getTeam(self,dataFrame, teamName):       \n",
    "        return dataFrame[(dataFrame[\"HomeTeam\"] == teamName) | (dataFrame[\"AwayTeam\"] == teamName)]\n",
    " \n",
    "        \n",
    "    def previousRecords(self,team, date , recentNum):\n",
    "        prev = team[( team[\"Date\"] < date)]\n",
    "        \n",
    "        if prev.shape[0] < recentNum :\n",
    "            #print(\"less than min Num\")\n",
    "            return None\n",
    "        else:\n",
    "            return prev.iloc[-recentNum:]\n",
    "    def readPredict (self, filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        df['Date'] = pd.to_datetime(df['Date'],dayfirst=True)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    \n",
    "  \n",
    "    def inverseTeamMapping (self, col):\n",
    "        inverseMap ={}\n",
    "        for name in self.teamsMap.keys():        \n",
    "            inverseMap[self.teamsMap[name]] = name\n",
    "        res =[]\n",
    "        for idex, v in enumerate(col):\n",
    "            res.append(inverseMap[v])\n",
    "        return res\n",
    "\n",
    "\n",
    "    def readTeamMatch(self, teamName):\n",
    "        df = pd.read_csv('teams/'+teamName+'.csv')\n",
    "        df['1'] = pd.to_datetime(df['1'],yearfirst=True)\n",
    "        #df['1']= (pd.to_numeric(df['1'])/1e9/24/60/60)\n",
    "        self.teamsData[teamName]=df.sort(['1'],ascending=[False])\n",
    "        self.teamsById[self.teamsMap[teamName]]=self.teamsData[teamName]\n",
    "    \n",
    "    def commonMapping(self, X):\n",
    "        X['HomeTeam'] = X['HomeTeam'].map(self.teamsMap)\n",
    "        X['AwayTeam'] = X['AwayTeam'].map(self.teamsMap)\n",
    "        X['Referee']=X['Referee'].map(self.refereesMap).fillna(0)\n",
    "        X['HTR'] = X['HTR'].map(self.win_mapping)\n",
    "        X['FTR'] = X['FTR'].map(self.win_mapping)\n",
    "        return X\n",
    "    def initData(self, X, target,encode):\n",
    "        X  = X.sort_values(by=\"Date\")\n",
    "        isInput = False\n",
    "        if target is None:\n",
    "            target =X      \n",
    "        else:\n",
    "            if self.ohe is None:\n",
    "                raise Exception(\"Not yet get train data\")\n",
    "            isInput = True\n",
    "            if encode == True:\n",
    "                target = self.commonMapping(target)\n",
    "        y=None\n",
    "        if encode == True:    \n",
    "            X =self.commonMapping(X)\n",
    "            y = []\n",
    "            for v in target['FTR']:\n",
    "                y.append(range(3)==v)\n",
    "        else:\n",
    "            y = target['FTR'].values\n",
    "        target_date = (pd.to_numeric(target['Date'])/1e9/24/60/60).values\n",
    "        return isInput, X,y, target, target_date\n",
    "   \n",
    "    def aggregate(self,recents,nonExpand,isInput,encode):\n",
    "        res =None\n",
    "        if encode == True:\n",
    "            if isInput==False:\n",
    "                self.ohe = OneHotEncoder(categorical_features='all')\n",
    "                self.ohe.fit(recents)\n",
    "            res = self.ohe.transform(recents).toarray()\n",
    "        else:\n",
    "            res = np.array(recents)\n",
    "        self.dateColumn = res.shape[1]\n",
    "        res = np.hstack([res,nonExpand])\n",
    "        return res\n",
    "  \n",
    "    def getH7(self,removeInsufficient=True, target=None,encode = True,future =0):\n",
    "        #Simple recent win,draw, lose \n",
    "        df = self.df\n",
    "        if removeInsufficient == True:\n",
    "            df= df[df['Sufficient'] == 1]\n",
    "        df=df[df['Future']==future]\n",
    "        \n",
    "        isInput, X, y,target, target_date = self.initData(df,target,encode)\n",
    "        resy=[]\n",
    "        resx=[]\n",
    "        print(\"start format\")\n",
    "        recents = X[['HomeTeam','AwayTeam','Referee']].values\n",
    "        haccp = X['HAccP'].values.reshape(X.shape[0],1)\n",
    "        aaccp = X['AAccP'].values.reshape(X.shape[0],1)\n",
    "        homeRecent = np.hstack([X[['HWin','HDraw','HLose']].values,\n",
    "                                (X['HScore'].values - X['HConcede'].values).reshape(X.shape[0],1)])\n",
    "        awayRecent = np.hstack([X[['AWin','ADraw','ALose']].values,\n",
    "                                (X['AScore'].values - X['AConcede'].values).reshape(X.shape[0],1)])\n",
    "        homeMoral = X['HMoral'].values.reshape(X.shape[0],1)\n",
    "        awayMoral = X['AMoral'].values.reshape(X.shape[0],1)\n",
    "        \n",
    "\n",
    "        h_atkpass_ratio = (X['H_atk_3rd_Acc'].values/X['H_atk_3rd_tot_Acc'].values).reshape(X.shape[0],1)\n",
    "        a_atkpass_ratio = (X['A_atk_3rd_Acc'].values/X['A_atk_3rd_tot_Acc'].values).reshape(X.shape[0],1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        target_date = target_date.reshape(X.shape[0],1)\n",
    "        nonExpand =np.hstack([target_date,X[['HRestDay','ARestDay','HS_Acc','AS_Acc','HST_Acc','AST_Acc',\n",
    "                                            'H_poss_Acc','A_poss_Acc','H_atk_3rd_tot_Acc','A_atk_3rd_tot_Acc',\n",
    "                                             'H_atk_3rd_Acc','A_atk_3rd_Acc','H_interceptions_Acc','A_interceptions_Acc',\n",
    "                                             'H_Enemy_Acc','A_Enemy_Acc'\n",
    "                                            ]].values,haccp-aaccp,(haccp+1)/(aaccp+1),\n",
    "                                homeRecent,awayRecent, homeMoral - awayMoral + haccp - aaccp,h_atkpass_ratio,a_atkpass_ratio\n",
    "                             ])\n",
    "        res = self.aggregate(recents,nonExpand,future,encode)\n",
    "        print(\"finish\")\n",
    "        sys.stdout.flush()\n",
    "        return res, np.array(y)\n",
    "    def _getRank(self,x, X,teamName,recentNum):\n",
    "        team = self.getTeam(X,teamName)\n",
    "        prev = team[team['Date'] < x['Date']].values      \n",
    "        for i in range(recentNum):\n",
    "            pass\n",
    "    def initRanking(self, n = 20):\n",
    "        defaultPt = 1\n",
    "        df = self.df.sort(columns=[\"Date\"],ascending=[False])\n",
    "        df[\"HPoints\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"APoints\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"HAccP\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"AAccP\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        hpoints= df[\"HPoints\"].values\n",
    "        apoints=df[\"APoints\"].values\n",
    "        ftr = df[\"FTR\"].values\n",
    "        for i in range(df.shape[0]):\n",
    "            sys.stdout.write(\"\\r progress {}\".format(i))\n",
    "            sys.stdout.flush()\n",
    "            if ftr[i] == 'H':\n",
    "                hpoints[i] = 3\n",
    "                apoints[i] = 0\n",
    "            elif ftr[i] == 'D':\n",
    "                hpoints[i] = 1\n",
    "                apoints[i] = 1\n",
    "            else :\n",
    "                hpoints[i] = 0\n",
    "                apoints[i] = 3\n",
    "        df[\"HPoints\"]=hpoints\n",
    "        df[\"APoints\"]=apoints\n",
    "        for teamName in self.teamsMap.keys():\n",
    "            team  = df[(df['HomeTeam']==teamName) | (df['AwayTeam'] == teamName)] \n",
    "            hometeam = team['HomeTeam'].values\n",
    "            hpoints = team['HPoints'].values\n",
    "            apoints = team['APoints'].values\n",
    "            psum = 0\n",
    "            haccp = team['HAccP'].values\n",
    "            aaccp = team['AAccP'].values\n",
    "        \n",
    "            for  i in range(0,n):\n",
    "                if i < hpoints.shape[0]:\n",
    "                    psum = psum + (hpoints[i] if hometeam[i] == teamName else apoints[i] ) \n",
    "                else:\n",
    "                    psum = psum + defaultPt        \n",
    "                    \n",
    "        \n",
    "            for j in range(team.shape[0]):\n",
    "\n",
    "                if j+n < hpoints.shape[0]:                     \n",
    "                    psum = psum + (hpoints[j+n] if hometeam[j+n]==teamName else apoints[j+n])\n",
    "                else:\n",
    "                    psum = psum + defaultPt \n",
    "                \n",
    "                psum = psum - (hpoints[j] if hometeam[j]==teamName else apoints[j])\n",
    "                    \n",
    "                if hometeam[j] == teamName:\n",
    "                    haccp[j]=psum\n",
    "                else:\n",
    "                    aaccp[j]=psum\n",
    "            team['HAccp']=haccp\n",
    "            team['AAccP']=aaccp\n",
    "            #print(team[['HomeTeam','AwayTeam','HAccP','AAccP']])\n",
    "            df.update(team)\n",
    "            \n",
    "            #print(df[['HomeTeam','AwayTeam','HAccP','AAccP']])\n",
    "        self.df =df\n",
    "        return df\n",
    "    def initRecentData(self, n =5):\n",
    "        df = self.df.sort(columns=[\"Date\"],ascending=[False])\n",
    "        df[\"HWin\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"AWin\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"HDraw\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"ADraw\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"HLose\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"ALose\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "                \n",
    "        df[\"HScore\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"AScore\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"HConcede\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"AConcede\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"HMoral\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"AMoral\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"HRestDay\"]= pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"ARestDay\"]= pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"H_Enemy_Acc\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        df[\"A_Enemy_Acc\"] = pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "        #general\n",
    "        generalList = self.generalList \n",
    "        generalOutput = []\n",
    "        for attr in generalList:\n",
    "            temp = attr+'_Acc'\n",
    "            df[temp]=pd.Series(np.zeros(shape=(df.shape[0],)))\n",
    "            generalOutput.append(temp)\n",
    "        #\n",
    "        df[\"Sufficient\"] = pd.Series(np.ones(shape=(df.shape[0],)))\n",
    "        \n",
    "      \n",
    "            \n",
    "        \n",
    "        hscore = df['FTHG'].values\n",
    "        ascore = df['FTAG'].values\n",
    "        hconcede = df ['FTAG'].values\n",
    "        aconcede = df['FTHG'].values\n",
    "               \n",
    "        hwin = df['HWin'].values\n",
    "        awin = df['AWin'].values\n",
    "        hlose = df['HLose'].values\n",
    "        alose = df['ALose'].values\n",
    "        hdraw = df['HDraw'].values\n",
    "        adraw = df['ADraw'].values\n",
    "        hmoral = df['HMoral'].values\n",
    "        amoral = df['AMoral'].values\n",
    "        \n",
    "        rankRatio = (df['HAccP'].values+1) / (df['AAccP'].values +1)\n",
    "        \n",
    "        \n",
    "        ftr = df[\"FTR\"].values\n",
    "        for i in range(df.shape[0]):\n",
    "            sys.stdout.write(\"\\r progress {}\".format(i))\n",
    "            sys.stdout.flush()\n",
    "            if ftr[i] == 'H':\n",
    "                hwin[i] = 1\n",
    "                hmoral[i] = 3 * 1/rankRatio[i]\n",
    "                alose[i]= 1\n",
    "                amoral[i] = -3 * 1/rankRatio[i]\n",
    "            elif ftr[i] == 'D':\n",
    "                hdraw[i] = 1\n",
    "                hmoral[i] = 1 * 1/rankRatio[i]\n",
    "                adraw[i] = 1\n",
    "                amoral[i] = 1 * rankRatio[i]\n",
    "            else :\n",
    "                hlose[i] = 1\n",
    "                hmoral[i] = -3*rankRatio[i]\n",
    "                awin [i] = 1\n",
    "                amoral[i] = 3*rankRatio[i]\n",
    "        \n",
    "        \n",
    "        df[\"HWin\"]=hwin\n",
    "        df[\"AWin\"]=awin\n",
    "        df[\"HDraw\"]=hdraw\n",
    "        df[\"ADraw\"]=adraw\n",
    "        df[\"HLose\"]=hlose\n",
    "        df[\"ALose\"]=alose\n",
    "        df[\"HScore\"]=hscore\n",
    "        df[\"AScore\"]=ascore\n",
    "        df[\"HConcede\"]=hconcede\n",
    "        df[\"AConcede\"]=aconcede\n",
    "        df[\"HMoral\"] = hmoral\n",
    "        df[\"AMoral\"] = amoral\n",
    "        \n",
    "        \n",
    "        \n",
    "        for teamName in self.teamsMap.keys():\n",
    "            print(teamName)\n",
    "            team  = df[(df['HomeTeam']==teamName) | (df['AwayTeam'] == teamName)] \n",
    "            hometeam = team['HomeTeam'].values\n",
    "            hwin = team[\"HWin\"].values\n",
    "            awin = team[\"AWin\"].values\n",
    "            hlose= team[\"HLose\"].values\n",
    "            alose = team[\"ALose\"].values\n",
    "            hdraw = team[\"HDraw\"].values\n",
    "            adraw = team[\"ADraw\"].values\n",
    "            hscore = team[\"HScore\"].values\n",
    "            ascore = team[\"AScore\"].values\n",
    "            hconcede = team[\"HConcede\"].values\n",
    "            aconcede = team[\"AConcede\"].values\n",
    "            hmoral = team[\"HMoral\"].values\n",
    "            amoral = team[\"AMoral\"].values\n",
    "            hrestday = team[\"HRestDay\"].values\n",
    "            arestday = team[\"ARestDay\"].values\n",
    "            \n",
    "            haccp = team[\"HAccP\"].values\n",
    "            aaccp = team[\"AAccP\"].values\n",
    "            h_enemy = team[\"H_Enemy_Acc\"].values\n",
    "            a_enemy = team[\"A_Enemy_Acc\"].values\n",
    "            enemy_sum = 0\n",
    "            \n",
    "            #general\n",
    "            original_list =[]\n",
    "            output_list=[]\n",
    "            for indx, o_attr in enumerate(generalList):\n",
    "                original_list.append(team[o_attr].values)\n",
    "                output_list.append(team[generalOutput[indx]].values)\n",
    "            \n",
    "            \n",
    "            matchDate =team['Date'].values\n",
    "            sufficient = team['Sufficient'].values\n",
    "            teamMatchesDate = self.teamsData[teamName].sort('1',ascending=False)['1'].values\n",
    "            \n",
    "            restday = 0\n",
    "            winsum =0 \n",
    "            losesum=0\n",
    "            drawsum=0\n",
    "            scoresum =0\n",
    "            concedesum=0\n",
    "            moralsum = 0\n",
    "            #print(team[['HomeTeam','AwayTeam','HWin']])\n",
    "            teamAttrSum_list=[0 for i in range(int(len(original_list)/2))]\n",
    "            for  i in range(0,n):\n",
    "                if i < team.shape[0]:\n",
    "                    scoresum = scoresum + (hscore[i] if hometeam[i] == teamName else ascore[i])\n",
    "                    winsum = winsum + (hwin[i] if hometeam[i] == teamName else awin[i])\n",
    "                    losesum= losesum + (hlose[i] if hometeam[i] == teamName else alose[i])\n",
    "                    drawsum= drawsum + (hdraw[i] if hometeam[i] == teamName else adraw[i])\n",
    "                    concedesum = concedesum+ (hconcede[i] if hometeam[i] == teamName else aconcede[i])\n",
    "                    moralsum= moralsum+ (hmoral[i] if hometeam[i] == teamName else amoral[i])\n",
    "                    enemy_sum += (aaccp[i] if hometeam[i] == teamName else haccp[i])\n",
    "                    for attrIndx in range(len(teamAttrSum_list)):\n",
    "                        teamAttrSum_list[attrIndx] +=(original_list[2*attrIndx][i] if hometeam[i] == teamName else original_list[2*attrIndx+1][i])\n",
    "                else:\n",
    "                    # + 0\n",
    "                    pass\n",
    "            dateIndx = 0\n",
    "            for j in range(team.shape[0]):\n",
    "                while True:\n",
    "                    if dateIndx >= teamMatchesDate.shape[0]:\n",
    "                        sufficient[j] = False\n",
    "                        break\n",
    "                    if teamMatchesDate[dateIndx] < matchDate[j] :\n",
    "                        restday = (matchDate[j] - teamMatchesDate[dateIndx])/np.timedelta64(1,'D')\n",
    "                        break\n",
    "                    else:\n",
    "                        dateIndx = dateIndx + 1\n",
    "                \n",
    "                if j+n < team.shape[0]:                     \n",
    "                    scoresum = scoresum + (hscore[j+n] if hometeam[j+n] == teamName else ascore[j+n])\n",
    "                    winsum = winsum + (hwin[j+n] if hometeam[j+n] == teamName else awin[j+n])\n",
    "                    losesum= losesum + (hlose[j+n] if hometeam[j+n] == teamName else alose[j+n])\n",
    "                    drawsum= drawsum + (hdraw[j+n] if hometeam[j+n] == teamName else adraw[j+n])\n",
    "                    concedesum = concedesum+ (hconcede[j+n] if hometeam[j+n] == teamName else aconcede[j+n])\n",
    "                    moralsum= moralsum+ (hmoral[j+n] if hometeam[j+n] == teamName else amoral[j+n])\n",
    "                    enemy_sum += (aaccp[j+n] if hometeam[j+n] == teamName else haccp[j+n])\n",
    "                    for attrIndx in range(len(teamAttrSum_list)):\n",
    "                        teamAttrSum_list[attrIndx] += (original_list[2*attrIndx][j+n] if hometeam[j+n] == teamName else original_list[2*attrIndx+1][j+n])\n",
    "                else:\n",
    "                    sufficient[j] = False\n",
    "                    \n",
    "                \n",
    "                scoresum = scoresum - (hscore[j] if hometeam[j] == teamName else ascore[j])\n",
    "                winsum = winsum - (hwin[j] if hometeam[j] == teamName else awin[j])\n",
    "                losesum= losesum - (hlose[j] if hometeam[j] == teamName else alose[j])\n",
    "                drawsum= drawsum - (hdraw[j] if hometeam[j] == teamName else adraw[j])\n",
    "                concedesum = concedesum - (hconcede[j] if hometeam[j] == teamName else aconcede[j])\n",
    "                moralsum= moralsum - (hmoral[j] if hometeam[j] == teamName else amoral[j])\n",
    "                enemy_sum -= (aaccp[j] if hometeam[j] == teamName else haccp[j])\n",
    "                for attrIndx in range(len(teamAttrSum_list)):\n",
    "                    teamAttrSum_list[attrIndx] -=  (original_list[2*attrIndx][j] if hometeam[j] == teamName else original_list[2*attrIndx+1][j])\n",
    "                    \n",
    "                if hometeam[j] == teamName:\n",
    "                    hscore[j] = scoresum\n",
    "                    hwin[j] = winsum\n",
    "                    hlose[j] = losesum\n",
    "                    hdraw[j] = drawsum\n",
    "                    hconcede[j] = concedesum\n",
    "                    hmoral[j] = moralsum\n",
    "                    hrestday[j] = restday\n",
    "                    h_enemy[j] = enemy_sum\n",
    "                    for attrIndx in range(len(teamAttrSum_list)):\n",
    "                        output_list[2*attrIndx][j] = teamAttrSum_list[attrIndx]\n",
    "                else:\n",
    "                    ascore[j] = scoresum\n",
    "                    awin[j] = winsum\n",
    "                    alose[j] = losesum\n",
    "                    adraw[j] = drawsum\n",
    "                    aconcede[j] = concedesum\n",
    "                    amoral[j] = moralsum\n",
    "                    arestday[j] = restday\n",
    "                    a_enemy[j] = enemy_sum\n",
    "                    for attrIndx in range(len(teamAttrSum_list)):\n",
    "                        output_list[2*attrIndx+1][j] = teamAttrSum_list[attrIndx]\n",
    "            team[\"HWin\"]=hwin\n",
    "            team[\"AWin\"]=awin\n",
    "            team[\"HDraw\"]=hdraw\n",
    "            team[\"ADraw\"]=adraw\n",
    "            team[\"HLose\"]=hlose\n",
    "            team[\"ALose\"]=alose\n",
    "            team[\"HScore\"]=hscore\n",
    "            team[\"AScore\"]=ascore\n",
    "            team[\"HConcede\"]=hconcede\n",
    "            team[\"AConcede\"]=aconcede\n",
    "            team[\"HMoral\"] = hmoral\n",
    "            team[\"AMoral\"] = amoral\n",
    "            team['Sufficient'] = sufficient\n",
    "            team[\"H_Enemy_Acc\"] = h_enemy\n",
    "            team[\"A_Enemy_Acc\"] = a_enemy\n",
    "            for indx in range(len(output_list)):\n",
    "                team[generalOutput[indx]]= output_list[indx]\n",
    "        \n",
    "            #print(team[['HomeTeam','AwayTeam','HWin']])\n",
    "            df.update(team)\n",
    "            #print(df[['HomeTeam','AwayTeam','HAccP','AAccP']])\n",
    "        self.df =df\n",
    "        return df\n",
    "    def initTeamData(self):\n",
    "        self.teamsData={}\n",
    "        self.teamsById={}\n",
    "        for name in self.teamsMap.keys():\n",
    "            self.readTeamMatch(name)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "c = FootballDataHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:30: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:31: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "#c.readFootBallData(\"E0_1112.csv\")\n",
    "c.readFootBallData(2012)\n",
    "c.readFootBallData(2013)\n",
    "c.readFootBallData(2014)\n",
    "c.readFootBallData(2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "c.readFuture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:147: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c.initTeamData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " progress 1451"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:233: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:284: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:285: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df = c.initRanking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " progress 1451"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:293: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:412: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:495: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:496: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:497: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:498: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:499: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:500: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:501: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:502: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:503: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:504: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:505: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:506: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:508: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "West Brom\n",
      "QPR\n",
      "Newcastle\n",
      "Arsenal\n",
      "Wigan\n",
      "Tottenham\n",
      "West Ham\n",
      "Liverpool\n",
      "Crystal Palace\n",
      "Chelsea\n",
      "Reading\n",
      "Fulham\n",
      "Burnley\n",
      "Hull\n",
      "Sunderland\n",
      "Cardiff\n",
      "Bournemouth\n",
      "Aston Villa\n",
      "Leicester\n",
      "Man City\n",
      "Watford\n",
      "Swansea\n",
      "Southampton\n",
      "Everton\n",
      "Norwich\n",
      "Man United\n",
      "Stoke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:511: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df=c.initRecentData(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.saveDf('dataSet/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c.loadDf('dataSet/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start format\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "X,y = c.getH7(removeInsufficient=True, encode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1358, 31)\n",
      "                home         away        Referee   time HRestDay ARestDay  \\\n",
      "0             Fulham     Man City       M Halsey  15612        7        3   \n",
      "1            Norwich    Liverpool        M Jones  15612        2        2   \n",
      "2            Everton  Southampton      L Probert  15612        3        3   \n",
      "3              Stoke      Swansea         J Moss  15612        7        3   \n",
      "4            Arsenal      Chelsea     M Atkinson  15612        2        3   \n",
      "5         Man United    Tottenham          C Foy  15612        2        2   \n",
      "6        Aston Villa    West Brom       A Taylor  15613        4        3   \n",
      "7                QPR     West Ham  M Clattenburg  15614        4        5   \n",
      "8              Wigan      Everton       K Friend  15619        7        7   \n",
      "9          West Brom          QPR        M Jones  15619        6        4   \n",
      "10          Man City   Sunderland      L Probert  15619        2        7   \n",
      "11           Chelsea      Norwich       A Taylor  15619        3        7   \n",
      "12          West Ham      Arsenal         P Dowd  15619        4        2   \n",
      "13           Swansea      Reading         M Dean  15619        7        7   \n",
      "14       Southampton       Fulham  M Clattenburg  15620        8        8   \n",
      "15         Tottenham  Aston Villa    N Swarbrick  15620        2        7   \n",
      "16         Liverpool        Stoke        L Mason  15620        2        8   \n",
      "17         Newcastle   Man United         H Webb  15620        2        4   \n",
      "18           Norwich      Arsenal      L Probert  15633       14       13   \n",
      "19          West Ham  Southampton    N Swarbrick  15633       13       13   \n",
      "20         West Brom     Man City  M Clattenburg  15633       14       14   \n",
      "21           Swansea        Wigan        M Jones  15633       14       14   \n",
      "22        Man United        Stoke       A Taylor  15633       13       13   \n",
      "23            Fulham  Aston Villa          C Foy  15633       13       13   \n",
      "24         Liverpool      Reading         R East  15633       13       14   \n",
      "25         Tottenham      Chelsea         M Dean  15633       13       14   \n",
      "26               QPR      Everton         J Moss  15634       15       15   \n",
      "27        Sunderland    Newcastle     M Atkinson  15634       15       14   \n",
      "28          Man City      Swansea     M Atkinson  15640        2        7   \n",
      "29           Arsenal          QPR       A Taylor  15640        2        6   \n",
      "...              ...          ...            ...    ...      ...      ...   \n",
      "1328       Liverpool     Man City     M Atkinson  16862        2        2   \n",
      "1329      Man United      Watford        M Jones  16862        3        4   \n",
      "1330           Stoke    Newcastle    N Swarbrick  16862        4       17   \n",
      "1331        West Ham    Tottenham     A Marriner  16862        4        3   \n",
      "1332         Arsenal      Swansea       R Madley  16862        3        3   \n",
      "1333        Man City  Aston Villa        L Mason  16865        2        3   \n",
      "1334       Tottenham      Arsenal       M Oliver  16865        2        2   \n",
      "1335         Watford    Leicester         J Moss  16865        2        3   \n",
      "1336         Swansea      Norwich       C Pawson  16865        2        3   \n",
      "1337         Chelsea        Stoke  M Clattenburg  16865        3        2   \n",
      "1338       Newcastle  Bournemouth      P Tierney  16865        2        3   \n",
      "1339     Southampton   Sunderland    N Swarbrick  16865        3        3   \n",
      "1340         Everton     West Ham       A Taylor  16865        3        2   \n",
      "1341       West Brom   Man United         M Dean  16866        4        3   \n",
      "1342  Crystal Palace    Liverpool     A Marriner  16866        4        3   \n",
      "1343           Stoke  Southampton        L Mason  16872        7        7   \n",
      "1344     Bournemouth      Swansea         R East  16872        7        7   \n",
      "1345         Norwich     Man City         J Moss  16872        7        7   \n",
      "1346     Aston Villa    Tottenham       A Taylor  16873        8        2   \n",
      "1347       Leicester    Newcastle       C Pawson  16874        8        9   \n",
      "1348         Chelsea     West Ham       R Madley  16879        6        5   \n",
      "1349       West Brom      Norwich       A Taylor  16879       12        7   \n",
      "1350  Crystal Palace    Leicester        M Jones  16879        7        4   \n",
      "1351         Swansea  Aston Villa         M Dean  16879        7        5   \n",
      "1352         Everton      Arsenal  M Clattenburg  16879        6        2   \n",
      "1353         Watford        Stoke       C Pawson  16879        6        7   \n",
      "1354        Man City   Man United       M Oliver  16880        4        2   \n",
      "1355       Newcastle   Sunderland     M Atkinson  16880        5       15   \n",
      "1356     Southampton    Liverpool         R East  16880        8        2   \n",
      "1357       Tottenham  Bournemouth    N Swarbrick  16880        2        8   \n",
      "\n",
      "     HS_Acc AS_Acc HST_Acc AST_Acc ... HLose H goal Diff AWin ADraw ALose  \\\n",
      "0        74     79      56      53 ...     2           5    2     3     0   \n",
      "1        55     79      27      40 ...     2          -6    0     2     3   \n",
      "2        94     59      52      31 ...     1           4    1     0     4   \n",
      "3        46     64      24      41 ...     1          -1    2     1     2   \n",
      "4        71     69      33      38 ...     0           7    4     1     0   \n",
      "5        75     85      41      50 ...     1           6    2     2     1   \n",
      "6        55     58      33      35 ...     3          -4    3     1     1   \n",
      "7        54     61      32      37 ...     3          -8    2     2     1   \n",
      "8        55     95      29      54 ...     3          -4    3     1     1   \n",
      "9        57     47      32      30 ...     1           0    0     2     3   \n",
      "10       80     28      50      17 ...     0           3    1     4     0   \n",
      "11       74     61      40      32 ...     0           6    0     3     2   \n",
      "12       70     71      43      34 ...     1           1    2     2     1   \n",
      "13       60     42      33      18 ...     3          -4    0     2     3   \n",
      "14       58     70      27      50 ...     4          -7    2     0     3   \n",
      "15       83     64      50      35 ...     0           4    1     2     2   \n",
      "16       75     50      39      26 ...     2           0    1     3     1   \n",
      "17       62     78      29      42 ...     1          -1    4     0     1   \n",
      "18       55     75      32      42 ...     3          -7    3     1     1   \n",
      "19       70     57      40      24 ...     1           2    1     1     3   \n",
      "20       60     95      35      61 ...     1           1    3     2     0   \n",
      "21       75     53      42      27 ...     3          -7    0     2     3   \n",
      "22       70     48      40      25 ...     1           8    1     3     1   \n",
      "23       70     65      44      37 ...     2           0    1     2     2   \n",
      "24       76     41      36      21 ...     2           0    0     2     3   \n",
      "25       88     71      50      42 ...     0           6    4     1     0   \n",
      "26       54     92      32      54 ...     4          -5    2     2     1   \n",
      "27       33     64      21      27 ...     1          -2    1     3     1   \n",
      "28       97     79      62      43 ...     0           5    1     1     3   \n",
      "29       77     59      42      33 ...     2           5    0     2     3   \n",
      "...     ...    ...     ...     ... ...   ...         ...  ...   ...   ...   \n",
      "1328     73     80      27      17 ...     2           4    2     1     2   \n",
      "1329     59     52      24      12 ...     2           2    2     2     1   \n",
      "1330     46     70      14      26 ...     3          -6    2     0     3   \n",
      "1331     73    107      20      43 ...     1           2    5     0     0   \n",
      "1332     77     67      28      18 ...     2           1    1     2     2   \n",
      "1333     67     41      15      12 ...     3          -5    1     0     4   \n",
      "1334     92     86      34      31 ...     1           5    2     1     2   \n",
      "1335     52     69      10      24 ...     2          -1    3     1     1   \n",
      "1336     71     57      15      12 ...     2          -1    0     1     4   \n",
      "1337     69     52      20      14 ...     0           6    3     0     2   \n",
      "1338     52     56      19      17 ...     4          -8    2     1     2   \n",
      "1339     48     69      13      19 ...     2          -1    1     2     2   \n",
      "1340     96     77      28      20 ...     2           6    3     1     1   \n",
      "1341     51     65      16      26 ...     1           1    3     1     1   \n",
      "1342     68     65      19      30 ...     3          -3    3     1     1   \n",
      "1343     58     50      19      15 ...     1           1    2     1     2   \n",
      "1344     64     63      18      14 ...     2           0    2     1     2   \n",
      "1345     55     73      13      21 ...     4          -5    2     0     3   \n",
      "1346     37    101      11      39 ...     4         -11    3     1     1   \n",
      "1347     70     55      25      20 ...     1           3    1     0     4   \n",
      "1348     77     69      23      19 ...     0           6    3     1     1   \n",
      "1349     43     48      11       9 ...     1           2    0     2     3   \n",
      "1350     68     66      20      19 ...     3          -3    3     1     1   \n",
      "1351     56     38      15      10 ...     3          -1    0     0     5   \n",
      "1352     91     75      34      24 ...     2           6    2     1     2   \n",
      "1353     51     60      11      18 ...     3          -2    3     1     1   \n",
      "1354     82     57      22      22 ...     3          -2    2     1     2   \n",
      "1355     61     69      19      20 ...     4          -7    1     3     1   \n",
      "1356     53     71      17      28 ...     2          -1    3     1     1   \n",
      "1357     94     59      38      18 ...     1           3    3     1     1   \n",
      "\n",
      "     A goal diff moraldiff + h-a H_atkPass_ratio A_atkPass_ratio  y  \n",
      "0              3         -5.4577        0.765472        0.749086  A  \n",
      "1             -6         4.26691        0.592814        0.743329  A  \n",
      "2             -6         20.4973         0.72035         0.69037  H  \n",
      "3              3        -0.98787         0.55364        0.738382  H  \n",
      "4              7         -7.3312        0.774038        0.737245  A  \n",
      "5              2         7.24231        0.810465          0.7456  A  \n",
      "6              3        -16.1433        0.540134        0.600753  D  \n",
      "7              1        -16.4869        0.633779        0.615502  A  \n",
      "8              5        -18.8485        0.704545         0.74359  D  \n",
      "9             -4         17.7318        0.614545        0.582593  H  \n",
      "10             1         5.22302        0.751147        0.652278  H  \n",
      "11            -4         26.8163        0.750591         0.57933  H  \n",
      "12             6         1.33957        0.612676        0.771863  A  \n",
      "13            -5         3.22343        0.746457         0.56869  D  \n",
      "14            -1        -9.28572        0.668563        0.726944  D  \n",
      "15            -3         17.1502        0.748227        0.559406  H  \n",
      "16             1        -5.98228        0.731103        0.566219  D  \n",
      "17             6         -7.8114        0.577358        0.792669  A  \n",
      "18             8        -21.3046        0.576862        0.780193  H  \n",
      "19            -5         12.8002        0.611521        0.647808  H  \n",
      "20             6        -6.20904        0.629032        0.766917  A  \n",
      "21            -6        0.178857        0.735632         0.67438  H  \n",
      "22             1         9.43603        0.745257        0.560694  H  \n",
      "23            -3         5.66887        0.715702        0.573718  H  \n",
      "24            -5         7.88105        0.737089        0.554817  H  \n",
      "25             7        -2.72658        0.770723        0.755801  A  \n",
      "26             3        -23.5168        0.634146        0.739694  D  \n",
      "27            -2       -0.225469         0.64977        0.593525  D  \n",
      "28            -6         24.2804        0.759479        0.701909  H  \n",
      "29            -3         12.0548        0.800668        0.658423  H  \n",
      "...          ...             ...             ...             ... ..  \n",
      "1328           2        -2.28404        0.672078        0.745536  H  \n",
      "1329           1        -4.32401        0.758197        0.588136  H  \n",
      "1330          -6         3.14025        0.700709         0.67035  H  \n",
      "1331           8        -19.9385        0.710692        0.690998  H  \n",
      "1332          -1         13.1779        0.756959        0.629085  A  \n",
      "1333          -9         13.3512        0.726363         0.66881  H  \n",
      "1334           1         13.5843        0.671338        0.762918  D  \n",
      "1335           4        -19.0615        0.566547        0.594801  A  \n",
      "1336          -7         19.0105        0.641571        0.623288  H  \n",
      "1337          -2         9.61243        0.768306        0.710598  D  \n",
      "1338          -1        -12.8138        0.642593        0.700565  A  \n",
      "1339          -1         1.78991         0.59612        0.538462  D  \n",
      "1340           3        -10.8407        0.739773        0.704545  A  \n",
      "1341           4        -4.45653        0.580827        0.770777  H  \n",
      "1342           8        -24.5246        0.607908        0.683871  A  \n",
      "1343          -1         8.06201        0.694521        0.626016  A  \n",
      "1344           0         1.36626         0.68169        0.642623  H  \n",
      "1345          -1        -21.0893        0.623698        0.764023  D  \n",
      "1346           2        -30.6047        0.684641         0.67402  A  \n",
      "1347          -9         31.6266        0.607251        0.666667  H  \n",
      "1348           2         1.42972        0.764513        0.685315  D  \n",
      "1349          -3         20.5266        0.564639        0.619891  A  \n",
      "1350           2        -33.3654        0.600349         0.64058  A  \n",
      "1351         -15         16.7183        0.626072        0.668874  H  \n",
      "1352           1        -2.52855        0.724868        0.736451  A  \n",
      "1353           3        -10.9102        0.557836        0.660714  A  \n",
      "1354           0        -4.08739        0.779705        0.754821  A  \n",
      "1355           0        -15.3967        0.651952         0.52214  D  \n",
      "1356           8           -9.09        0.629687        0.710744  H  \n",
      "1357           3         3.93801         0.67624        0.656672  H  \n",
      "\n",
      "[1358 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "df = pd.DataFrame(np.hstack([X,y.reshape(y.shape[0],1)]))\n",
    "\n",
    "df.columns = ['home','away','Referee','time','HRestDay','ARestDay','HS_Acc','AS_Acc','HST_Acc','AST_Acc',\n",
    "                                            'H_Poss_Acc','A_Poss_Acc','H_atk_3rd_tot_Acc','A_atk_3rd_tot_Acc',\n",
    "                                             'H_atk_3rd_Acc','A_atk_3rd_Acc','H_interceptions_Acc','A_interceptions_Acc',\n",
    "              'H_Enemy_Acc','A_Enemy_Acc'\n",
    "              ,'HAccP - AAccP','H/A','HWin','HDraw','HLose','H goal Diff',\n",
    "'AWin','ADraw','ALose','A goal diff','moraldiff + h-a','H_atkPass_ratio','A_atkPass_ratio',\n",
    "              'y']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv('dataSet/V9_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start format\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "X,y = c.getH7(removeInsufficient = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "def splitData(X,y):\n",
    "    X_train, X_test1, y_train, y_test1 = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_test, X_val, y_test,y_val = train_test_split(X_test1, y_test1, test_size=0.5, random_state=42)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "def createModel(hidSize, inputDim ,dropout =0.7):\n",
    "    activation ='sigmoid'\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidSize[0], input_dim=inputDim, init='glorot_normal'))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    #model.add(Dense(hidSize[1], init='glorot_normal'))\n",
    "    #model.add(Activation(activation))\n",
    "    #model.add(Dropout(dropout))\n",
    " \n",
    "    model.add(Dense(3, init='glorot_normal'))\n",
    "    model.add(Activation('softmax'))\n",
    "    sgd = SGD(lr=1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "    return model\n",
    "earlyCallback = EarlyStopping(patience=20,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "def crossValidate2(node_sizes, X,y,dropout=0.7, fold = 10, earlyStopping =True):\n",
    "    y_label = np.argmax(y,axis=1)\n",
    "\n",
    "    kfold = StratifiedKFold(y=y_label, \n",
    "                             n_folds=fold,\n",
    "                            random_state=1)\n",
    "\n",
    "    scores = []\n",
    "    train_scores=[]\n",
    "    proba_test = []\n",
    "    proba_y=[]\n",
    "    for k, (train, test) in enumerate(kfold):\n",
    "        earlyCallback = EarlyStopping(patience=20,verbose=1)\n",
    "        model = createModel(node_sizes,X.shape[1],dropout=dropout)\n",
    "        if earlyStopping==True:\n",
    "             model.fit(X[train],y[train],verbose=0,nb_epoch=500, validation_split=0.1,show_accuracy=True, callbacks=[earlyCallback])\n",
    "        else:\n",
    "            model.fit(X[train],y[train],verbose=0,nb_epoch=500, validation_split=0.1,show_accuracy=True )\n",
    "      #  firstNScores.append(firstNScore(2, model.predict_proba(X[test]), y[test]))\n",
    "        score = model.evaluate(X[test],y[test])\n",
    "        proba_test.append(model.predict_proba(X[test]))\n",
    "        proba_y.append(y[test])\n",
    "        train_scores.append(model.evaluate(X[train],y[train]))\n",
    "        scores.append(score)\n",
    "        print('Fold: %s, Class dist.: %s, val_loss: %.3f' % (k+1, \n",
    "                    np.bincount(y_label[train]), score))    \n",
    "        \n",
    "        \n",
    "    return train_scores,scores, proba_test,proba_y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00038: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [479 265 341], val_loss: 1.001\n",
      "Epoch 00063: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 2, Class dist.: [479 265 341], val_loss: 0.969\n",
      "Epoch 00045: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 3, Class dist.: [479 266 342], val_loss: 0.990\n",
      "Epoch 00047: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 4, Class dist.: [479 266 342], val_loss: 1.002\n",
      "Epoch 00051: early stopping\n",
      "270/270 [==============================] - 0s     \n",
      "270/270 [==============================] - 0s     \n",
      "1088/1088 [==============================] - 0s     \n",
      "Fold: 5, Class dist.: [480 266 342], val_loss: 1.059\n"
     ]
    }
   ],
   "source": [
    "train_scores,scores,  proba_test,proba_y= crossValidate2([55,55],X_scaled,y,fold=5,dropout=0.7,earlyStopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learningRate(X,y,sizes,test_size=0.2, num =5,dropout=0.7):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    train_loss=[] \n",
    "    score_loss=[]\n",
    "    lasts = [ int(X_train.shape[0]/num * (r+1)) for r in range(num)]\n",
    "    for i in range(num):\n",
    "        earlyCallback = EarlyStopping(patience=20,verbose=1)\n",
    "        model = createModel(sizes,X.shape[1],dropout=dropout)\n",
    "        if i == num - 1:\n",
    "            model.fit(X_train,y_train,verbose=0,nb_epoch=500, validation_split=0.1,show_accuracy=True, callbacks=[earlyCallback])\n",
    "            train_score = model.evaluate(X_train,y_train)\n",
    "            test_score = model.evaluate(X_test,y_test)\n",
    "            print(\"train:{}, test{}\".format(train_score,test_score))\n",
    "            train_loss.append(train_score)\n",
    "            score_loss.append(test_score)\n",
    "        else:\n",
    "            model.fit(X_train[0:lasts[i],:],y_train[0:lasts[i]],verbose=0,nb_epoch=500, validation_split=0.1,show_accuracy=True, callbacks=[earlyCallback])\n",
    "            train_score = model.evaluate(X_train[0:lasts[i],:],y_train[0:lasts[i]])\n",
    "            test_score = model.evaluate(X_test,y_test)\n",
    "            print(\"train:{}, test{}\".format(train_score,test_score))\n",
    "            train_loss.append(train_score)\n",
    "            score_loss.append(test_score)\n",
    "    return train_loss, score_loss, lasts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00136: early stopping\n",
      "108/108 [==============================] - 0s\n",
      "272/272 [==============================] - 0s     \n",
      "train:0.40966343879699707, test1.1810810916564043\n",
      "Epoch 00033: early stopping\n",
      "217/217 [==============================] - 0s     \n",
      "272/272 [==============================] - 0s     "
     ]
    }
   ],
   "source": [
    "learningRate(X_scaled,y,[55,55],num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testNodeNum(X,y, sizes,dropout =0.5):\n",
    "    train_loss=[] \n",
    "    score_loss=[]\n",
    "    for s in sizes:\n",
    "        train_scores,scores,  proba_test,proba_y= crossValidate2([s,s],X,y,fold=5)\n",
    "        print(\"size:{} , val_loss_mean:{}\".format(s,np.mean(scores)))\n",
    "        train_loss.append(train_scores)\n",
    "        score_loss.append(scores)\n",
    "    return train_loss,score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00046: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [479 265 341], val_loss: 1.001\n",
      "Epoch 00074: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 2, Class dist.: [479 265 341], val_loss: 0.973\n",
      "Epoch 00066: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 3, Class dist.: [479 266 342], val_loss: 0.990\n",
      "Epoch 00044: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 4, Class dist.: [479 266 342], val_loss: 1.004\n",
      "Epoch 00040: early stopping\n",
      "270/270 [==============================] - 0s     \n",
      "270/270 [==============================] - 0s     \n",
      "1088/1088 [==============================] - 0s     \n",
      "Fold: 5, Class dist.: [480 266 342], val_loss: 1.035\n",
      "size:15 , val_loss_mean:1.0006081914049496\n",
      "Epoch 00055: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [479 265 341], val_loss: 0.995\n",
      "Epoch 00053: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 2, Class dist.: [479 265 341], val_loss: 0.975\n",
      "Epoch 00043: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 3, Class dist.: [479 266 342], val_loss: 0.986\n",
      "Epoch 00073: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 4, Class dist.: [479 266 342], val_loss: 1.000\n",
      "Epoch 00041: early stopping\n",
      "270/270 [==============================] - 0s     \n",
      "270/270 [==============================] - 0s     \n",
      "1088/1088 [==============================] - 0s     \n",
      "Fold: 5, Class dist.: [480 266 342], val_loss: 1.048\n",
      "size:20 , val_loss_mean:1.0008517997300672\n",
      "Epoch 00029: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [479 265 341], val_loss: 0.997\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-2960c4fa732e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msizes\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscore_loss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtestNodeNum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msizes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-73-2b2ef5b4ad37>\u001b[0m in \u001b[0;36mtestNodeNum\u001b[1;34m(X, y, sizes, dropout)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mscore_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msizes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtrain_scores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mproba_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mproba_y\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcrossValidate2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"size:{} , val_loss_mean:{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-6a524d492a1f>\u001b[0m in \u001b[0;36mcrossValidate2\u001b[1;34m(node_sizes, X, y, dropout, fold, earlyStopping)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_sizes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mearlyStopping\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m              \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearlyCallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, show_accuracy, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m                          \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m                          shuffle=shuffle, metrics=metrics)\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, metrics)\u001b[0m\n\u001b[0;32m    278\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/y/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sizes= range(15,X.shape[1],5)\n",
    "train_loss,score_loss= testNodeNum(X_scaled,y,sizes,dropout=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sizes)\n",
    "loss = (np.mean(score_loss,axis=1))\n",
    "loss_std = (np.std(score_loss,axis=1))\n",
    "plt.plot(sizes,loss)\n",
    "plt.fill_between(sizes,loss-loss_std,loss+loss_std,alpha=0.3)\n",
    "plt.show()\n",
    "print(\"max: {}\".format(sizes[np.argmin(loss,axis=0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testDropoutRate(X,y, sizes,dropout):\n",
    "    train_scores,scores,  proba_test,proba_y= crossValidate2(sizes,X,y,fold=5,dropout=dropout,earlyStopping=True)\n",
    "    print(\"dropout:{} , val_loss_mean:{}\".format(dropout,np.mean(scores)))\n",
    "    return train_scores,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00036: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [479 265 341], val_loss: 1.024\n",
      "Epoch 00031: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 2, Class dist.: [479 265 341], val_loss: 0.975\n",
      "Epoch 00031: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 3, Class dist.: [479 266 342], val_loss: 1.016\n",
      "Epoch 00028: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 4, Class dist.: [479 266 342], val_loss: 1.013\n",
      "Epoch 00025: early stopping\n",
      "270/270 [==============================] - 0s     \n",
      "270/270 [==============================] - 0s     \n",
      "1088/1088 [==============================] - 0s     \n",
      "Fold: 5, Class dist.: [480 266 342], val_loss: 1.072\n",
      "dropout:0.1 , val_loss_mean:1.0199852315362063\n",
      "Epoch 00037: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [479 265 341], val_loss: 1.011\n",
      "Epoch 00040: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 2, Class dist.: [479 265 341], val_loss: 0.969\n",
      "Epoch 00031: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 3, Class dist.: [479 266 342], val_loss: 0.998\n",
      "Epoch 00029: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 4, Class dist.: [479 266 342], val_loss: 1.012\n",
      "Epoch 00025: early stopping\n",
      "270/270 [==============================] - 0s     \n",
      "270/270 [==============================] - 0s     \n",
      "1088/1088 [==============================] - 0s     \n",
      "Fold: 5, Class dist.: [480 266 342], val_loss: 1.057\n",
      "dropout:0.2 , val_loss_mean:1.009208562537362\n",
      "Epoch 00037: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [479 265 341], val_loss: 0.996\n",
      "Epoch 00045: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 2, Class dist.: [479 265 341], val_loss: 0.970\n",
      "Epoch 00038: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 3, Class dist.: [479 266 342], val_loss: 0.995\n",
      "Epoch 00034: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 4, Class dist.: [479 266 342], val_loss: 1.000\n",
      "Epoch 00022: early stopping\n",
      "270/270 [==============================] - 0s     \n",
      "270/270 [==============================] - 0s     \n",
      "1088/1088 [==============================] - 0s     \n",
      "Fold: 5, Class dist.: [480 266 342], val_loss: 1.051\n",
      "dropout:0.30000000000000004 , val_loss_mean:1.0024974948664844\n",
      "Epoch 00038: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [479 265 341], val_loss: 0.993\n",
      "Epoch 00062: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 2, Class dist.: [479 265 341], val_loss: 0.965\n",
      "Epoch 00059: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 3, Class dist.: [479 266 342], val_loss: 0.998\n",
      "Epoch 00035: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 4, Class dist.: [479 266 342], val_loss: 1.001\n",
      "Epoch 00026: early stopping\n",
      "270/270 [==============================] - 0s     \n",
      "270/270 [==============================] - 0s     \n",
      "1088/1088 [==============================] - 0s     \n",
      "Fold: 5, Class dist.: [480 266 342], val_loss: 1.043\n",
      "dropout:0.4 , val_loss_mean:0.9999555602924577\n",
      "Epoch 00057: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [479 265 341], val_loss: 0.981\n",
      "Epoch 00075: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 2, Class dist.: [479 265 341], val_loss: 0.962\n",
      "Epoch 00048: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 3, Class dist.: [479 266 342], val_loss: 0.983\n",
      "Epoch 00036: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 4, Class dist.: [479 266 342], val_loss: 1.000\n",
      "Epoch 00035: early stopping\n",
      "270/270 [==============================] - 0s     \n",
      "270/270 [==============================] - 0s     \n",
      "1088/1088 [==============================] - 0s     \n",
      "Fold: 5, Class dist.: [480 266 342], val_loss: 1.037\n",
      "dropout:0.5 , val_loss_mean:0.992682413817185\n",
      "Epoch 00049: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [479 265 341], val_loss: 0.984\n",
      "Epoch 00089: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 2, Class dist.: [479 265 341], val_loss: 0.963\n",
      "Epoch 00086: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 3, Class dist.: [479 266 342], val_loss: 0.984\n",
      "Epoch 00046: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 4, Class dist.: [479 266 342], val_loss: 1.001\n",
      "Epoch 00034: early stopping\n",
      "270/270 [==============================] - 0s     \n",
      "270/270 [==============================] - 0s     \n",
      "1088/1088 [==============================] - 0s     \n",
      "Fold: 5, Class dist.: [480 266 342], val_loss: 1.030\n",
      "dropout:0.6 , val_loss_mean:0.9923445295144047\n",
      "Epoch 00124: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [479 265 341], val_loss: 0.990\n",
      "Epoch 00173: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 2, Class dist.: [479 265 341], val_loss: 0.959\n",
      "Epoch 00082: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 3, Class dist.: [479 266 342], val_loss: 0.981\n",
      "Epoch 00094: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 4, Class dist.: [479 266 342], val_loss: 0.998\n",
      "Epoch 00034: early stopping\n",
      "270/270 [==============================] - 0s     \n",
      "270/270 [==============================] - 0s     \n",
      "1088/1088 [==============================] - 0s     \n",
      "Fold: 5, Class dist.: [480 266 342], val_loss: 1.029\n",
      "dropout:0.7000000000000001 , val_loss_mean:0.9914079155943771\n",
      "Epoch 00156: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [479 265 341], val_loss: 0.988\n",
      "Epoch 00205: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 2, Class dist.: [479 265 341], val_loss: 0.986\n",
      "Epoch 00311: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 3, Class dist.: [479 266 342], val_loss: 0.995\n",
      "Epoch 00113: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 4, Class dist.: [479 266 342], val_loss: 1.002\n",
      "Epoch 00092: early stopping\n",
      "270/270 [==============================] - 0s     \n",
      "270/270 [==============================] - 0s     \n",
      "1088/1088 [==============================] - 0s     \n",
      "Fold: 5, Class dist.: [480 266 342], val_loss: 1.033\n",
      "dropout:0.8 , val_loss_mean:1.0009911133097205\n",
      "Epoch 00029: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [479 265 341], val_loss: 1.067\n",
      "Epoch 00029: early stopping\n",
      "273/273 [==============================] - 0s     \n",
      "273/273 [==============================] - 0s     \n",
      "1085/1085 [==============================] - 0s     \n",
      "Fold: 2, Class dist.: [479 265 341], val_loss: 1.068\n",
      "Epoch 00039: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 3, Class dist.: [479 266 342], val_loss: 1.065\n",
      "Epoch 00024: early stopping\n",
      "271/271 [==============================] - 0s     \n",
      "271/271 [==============================] - 0s     \n",
      "1087/1087 [==============================] - 0s     \n",
      "Fold: 4, Class dist.: [479 266 342], val_loss: 1.066\n",
      "Epoch 00039: early stopping\n",
      "270/270 [==============================] - 0s     \n",
      "270/270 [==============================] - 0s     \n",
      "1088/1088 [==============================] - 0s     \n",
      "Fold: 5, Class dist.: [480 266 342], val_loss: 1.068\n",
      "dropout:0.9 , val_loss_mean:1.0668552110417688\n"
     ]
    }
   ],
   "source": [
    "g_dropout_range =np.arange(0.1,1, 0.1)\n",
    "g_train_loss=[]\n",
    "g_score_loss =[]\n",
    "for d in g_dropout_range:\n",
    "    train_loss, score_loss = testDropoutRate(X_scaled,y,[55,55],float(d))\n",
    "    g_train_loss.append(train_loss)\n",
    "    g_score_loss.append(score_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a166907f0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+SulVAr6/wHfWXVruC46rAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a15ccc2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a166907f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "g_train_mean = np.mean(g_score_loss,axis=1)\n",
    "g_test_mean = np.mean(g_score_loss,axis=1)\n",
    "g_test_std = np.std(g_score_loss,axis = 1)\n",
    "plt.plot(g_dropout_range,g_test_mean)\n",
    "plt.plot(g_dropout_range,g_train_mean,color='red')\n",
    "plt.fill_between(g_dropout_range, g_test_mean - g_test_std, g_test_mean+g_test_std,alpha=0.3)\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def futureTest2(node_sizes, X,y,ori_dates, numOfWeek = 10,verbose=False):\n",
    "    decoded = oneHotDecode(c, X)\n",
    "    dates = convertToDate(ori_dates)\n",
    "    dates = [d - timedelta(days=2) for d in dates]    \n",
    "    weeks  = [ v.isocalendar()[1] for v in dates]\n",
    "    thisWeek = weeks[-1]\n",
    "    start = -1\n",
    "    last = X.shape[0]\n",
    "    index = -1\n",
    "    w = 0\n",
    "    sum_proba =None \n",
    "    sum_y =None\n",
    "    sum_train_proba=None\n",
    "    sum_train_y=None\n",
    "    model = createModel(node_sizes,X.shape[1])\n",
    "    results = None\n",
    "    while w < numOfWeek:\n",
    "        if thisWeek != weeks[index]:\n",
    "            print(\"week{}\".format(w))\n",
    "            start = X.shape[0] +index+1\n",
    "            X_train = X[0:start, :]\n",
    "            X_test = X[start:last,:]\n",
    "            y_train = y[0:start,:]\n",
    "            y_test = y[start:last,:]\n",
    "            earlyCallback = EarlyStopping(patience=20,verbose=1)\n",
    "            history = model.fit(X_train,y_train,verbose=0,nb_epoch=500, validation_split=0.1, callbacks=[earlyCallback])\n",
    "            decoded = oneHotDecode(c,X_test)\n",
    "            home = np.array([c.inverseTeamMapping(decoded[:,0])]).reshape(X_test.shape[0],1)\n",
    "            away = np.array([c.inverseTeamMapping(decoded[:,1])]).reshape(X_test.shape[0],1)\n",
    "            stack = np.hstack([home,away])\n",
    "            proba = model.predict_proba(X_test)\n",
    "            train_proba =model.predict_proba(X_train)\n",
    "            errorIndx = np.argmax(proba,axis=1) != np.argmax(y_test,axis=1)\n",
    "            tresult = np.hstack([np.array([w for i in range(proba.shape[0])]).reshape(proba.shape[0],1),\n",
    "                                 ori_dates[start:last].reshape(proba.shape[0],1),stack,proba,y_test])\n",
    "            if sum_proba is None:\n",
    "                sum_proba = proba\n",
    "                sum_y = y_test\n",
    "                sum_train_proba = train_proba\n",
    "                sum_train_y = y_train\n",
    "                results =    tresult\n",
    "            else:\n",
    "                sum_proba = np.vstack([sum_proba,proba])\n",
    "                sum_y = np.vstack([sum_y,y_test])\n",
    "                sum_train_proba = np.vstack([sum_train_proba, train_proba])\n",
    "                sum_train_y= np.vstack([sum_train_y, y_train])\n",
    "                results =  np.vstack([results, tresult])\n",
    "            if verbose == True:\n",
    "                print(\"numOftest {} , loss {}\".format(X_test.shape[0],model.evaluate(X_test,y_test)))               \n",
    "                print (tresult)\n",
    "                print(\"first2 : {}\",firstNScore(2,proba,y_test))\n",
    "            last = start\n",
    "            thisWeek = weeks[index]\n",
    "            w = w+1\n",
    "        index = index -1\n",
    "    start = X.shape[0] +index+1\n",
    "    print(\"start compute precision_mat\")\n",
    "    print(X[0:start,:].shape)\n",
    "    print(y[0:start,:].shape)\n",
    "    _,_, proba_test,proba_y = crossValidate2(node_sizes,X[0:start,:],y[0:start,:],fold=10)\n",
    "    p_matrix = precisionMatrix(np.vstack(proba_test),np.vstack(proba_y))\n",
    "    print(\"summary\")\n",
    "    print(\"score:\")\n",
    "    score = firstNScore(1,sum_proba,sum_y)\n",
    "    print(score)\n",
    "    print(\"2like\")\n",
    "    like2 = firstNScore(2,sum_proba,sum_y)\n",
    "    print(precisionMatrix(sum_proba,sum_y))\n",
    "    y_true= np.argmax(sum_y,axis=1)\n",
    "    y_pred = np.argmax(sum_proba,axis=1)\n",
    "    print(\"sum precision:{}\".format(precision_score(y_true,y_pred,average=None)))\n",
    "    resultdf= pd.DataFrame(results, columns=['week','DayStamp','HomeTeam','AwayTeam','H_prob','D_prob','A_prob','H','D','A'])\n",
    "    return sum_proba, sum_y,resultdf,p_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week0\n",
      "Epoch 00088: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1348/1348 [==============================] - 0s     \n",
      "week1\n",
      "Epoch 00039: early stopping\n",
      "5/5 [==============================] - 0s\n",
      "1343/1343 [==============================] - 0s     \n",
      "week2\n",
      "Epoch 00024: early stopping\n",
      "15/15 [==============================] - 0s\n",
      "1328/1328 [==============================] - 0s     \n",
      "week3\n",
      "Epoch 00027: early stopping\n",
      "13/13 [==============================] - 0s\n",
      "1315/1315 [==============================] - 0s     \n",
      "week4\n",
      "Epoch 00024: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1305/1305 [==============================] - 0s     \n",
      "week5\n",
      "Epoch 00025: early stopping\n",
      "12/12 [==============================] - 0s\n",
      "1293/1293 [==============================] - 0s     \n",
      "week6\n",
      "Epoch 00023: early stopping\n",
      "8/8 [==============================] - 0s\n",
      "1285/1285 [==============================] - 0s     \n",
      "week7\n",
      "Epoch 00024: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1275/1275 [==============================] - 0s     \n",
      "week8\n",
      "Epoch 00021: early stopping\n",
      "17/17 [==============================] - 0s\n",
      "1258/1258 [==============================] - 0s     \n",
      "week9\n",
      "Epoch 00022: early stopping\n",
      "3/3 [==============================] - 0s\n",
      "1255/1255 [==============================] - 0s     \n",
      "week10\n",
      "Epoch 00021: early stopping\n",
      "11/11 [==============================] - 0s\n",
      "1244/1244 [==============================] - 0s     \n",
      "week11\n",
      "Epoch 00021: early stopping\n",
      "19/19 [==============================] - 0s\n",
      "1225/1225 [==============================] - 0s     \n",
      "week12\n",
      "Epoch 00027: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1215/1215 [==============================] - 0s     \n",
      "week13\n",
      "Epoch 00021: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1205/1205 [==============================] - 0s     \n",
      "week14\n",
      "Epoch 00021: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1195/1195 [==============================] - 0s     \n",
      "week15\n",
      "Epoch 00022: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1185/1185 [==============================] - 0s     \n",
      "week16\n",
      "Epoch 00021: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1175/1175 [==============================] - 0s     \n",
      "week17\n",
      "Epoch 00022: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1165/1165 [==============================] - 0s     \n",
      "week18\n",
      "Epoch 00023: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1155/1155 [==============================] - 0s     \n",
      "week19\n",
      "Epoch 00024: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1145/1145 [==============================] - 0s     \n",
      "week20\n",
      "Epoch 00023: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1135/1135 [==============================] - 0s     \n",
      "week21\n",
      "Epoch 00021: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1125/1125 [==============================] - 0s     \n",
      "week22\n",
      "Epoch 00024: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1115/1115 [==============================] - 0s     \n",
      "week23\n",
      "Epoch 00022: early stopping\n",
      "10/10 [==============================] - 0s\n",
      "1105/1105 [==============================] - 0s     \n",
      "week24\n",
      "Epoch 00022: early stopping\n",
      "8/8 [==============================] - 0s\n",
      "1097/1097 [==============================] - 0s     \n",
      "start compute precision_mat\n",
      "(1096, 106)\n",
      "(1096, 3)\n",
      "Epoch 00033: early stopping\n",
      "111/111 [==============================] - 0s\n",
      "111/111 [==============================] - 0s\n",
      "985/985 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [440 237 308], val_loss: 1.011\n",
      "Epoch 00026: early stopping\n",
      "111/111 [==============================] - 0s\n",
      "111/111 [==============================] - 0s\n",
      "985/985 [==============================] - 0s     \n",
      "Fold: 2, Class dist.: [440 237 308], val_loss: 0.969\n",
      "Epoch 00034: early stopping\n",
      "111/111 [==============================] - 0s\n",
      "111/111 [==============================] - 0s\n",
      "985/985 [==============================] - 0s     \n",
      "Fold: 3, Class dist.: [440 237 308], val_loss: 0.930\n",
      "Epoch 00032: early stopping\n",
      "110/110 [==============================] - 0s\n",
      "110/110 [==============================] - 0s\n",
      "986/986 [==============================] - 0s     \n",
      "Fold: 4, Class dist.: [440 237 309], val_loss: 1.004\n",
      "Epoch 00029: early stopping\n",
      "109/109 [==============================] - 0s\n",
      "109/109 [==============================] - 0s\n",
      "987/987 [==============================] - 0s     \n",
      "Fold: 5, Class dist.: [440 238 309], val_loss: 0.939\n",
      "Epoch 00036: early stopping\n",
      "109/109 [==============================] - 0s\n",
      "109/109 [==============================] - 0s\n",
      "987/987 [==============================] - 3s     \n",
      "Fold: 6, Class dist.: [440 238 309], val_loss: 0.991\n",
      "Epoch 00036: early stopping\n",
      "109/109 [==============================] - 0s\n",
      "109/109 [==============================] - 0s\n",
      "987/987 [==============================] - 0s     \n",
      "Fold: 7, Class dist.: [440 238 309], val_loss: 0.965\n",
      "Epoch 00029: early stopping\n",
      "109/109 [==============================] - 0s\n",
      "109/109 [==============================] - 0s\n",
      "987/987 [==============================] - 0s     \n",
      "Fold: 8, Class dist.: [440 238 309], val_loss: 0.990\n",
      "Epoch 00028: early stopping\n",
      "109/109 [==============================] - 0s\n",
      "109/109 [==============================] - 0s\n",
      "987/987 [==============================] - 0s     \n",
      "Fold: 9, Class dist.: [440 238 309], val_loss: 0.980\n",
      "Epoch 00045: early stopping\n",
      "108/108 [==============================] - 0s\n",
      "108/108 [==============================] - 0s\n",
      "988/988 [==============================] - 0s     \n",
      "Fold: 10, Class dist.: [441 238 309], val_loss: 1.057\n",
      "summary\n",
      "score:\n",
      "0.467432950192\n",
      "2like\n",
      "       [lower  upper)  h_Correct  h_Wrong  h_Precent  d_Correct  d_Wrong  \\\n",
      ">80       0.8     1.0         21        4   0.840000          1        1   \n",
      "60-80     0.6     0.8         13       13   0.500000          3        2   \n",
      "50-60     0.5     0.6         12       16   0.428571          6        2   \n",
      "40-50     0.4     0.5         10       18   0.357143          1        9   \n",
      "30-40     0.3     0.4         30       41   0.422535         14       50   \n",
      "20-30     0.2     0.3         15       16   0.483871         21       50   \n",
      "<20       0.0     0.2          8       44   0.153846         22       79   \n",
      "\n",
      "       d_Precent  a_Correct  a_Wrong  a_Precent  \n",
      ">80     0.500000         12        8   0.600000  \n",
      "60-80   0.600000         11        9   0.550000  \n",
      "50-60   0.750000          5        8   0.384615  \n",
      "40-50   0.100000         10       15   0.400000  \n",
      "30-40   0.218750         22       42   0.343750  \n",
      "20-30   0.295775         14       32   0.304348  \n",
      "<20     0.217822         10       63   0.136986  \n",
      "sum precision:[ 0.504       0.35135135  0.46464646]\n"
     ]
    }
   ],
   "source": [
    "sum_proba, sum_y,resultdf,p_matrix= futureTest2([55,55],X_scaled,y,X[:,c.dateColumn],numOfWeek=25,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[lower</th>\n",
       "      <th>upper)</th>\n",
       "      <th>h_Correct</th>\n",
       "      <th>h_Wrong</th>\n",
       "      <th>h_Precent</th>\n",
       "      <th>d_Correct</th>\n",
       "      <th>d_Wrong</th>\n",
       "      <th>d_Precent</th>\n",
       "      <th>a_Correct</th>\n",
       "      <th>a_Wrong</th>\n",
       "      <th>a_Precent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&gt;80</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60-80</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>203</td>\n",
       "      <td>80</td>\n",
       "      <td>0.717314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50-60</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>59</td>\n",
       "      <td>0.611842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40-50</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>70</td>\n",
       "      <td>92</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>0.462025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30-40</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>76</td>\n",
       "      <td>118</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>54</td>\n",
       "      <td>147</td>\n",
       "      <td>0.268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20-30</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>41</td>\n",
       "      <td>131</td>\n",
       "      <td>0.238372</td>\n",
       "      <td>215</td>\n",
       "      <td>615</td>\n",
       "      <td>0.259036</td>\n",
       "      <td>56</td>\n",
       "      <td>171</td>\n",
       "      <td>0.246696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>21</td>\n",
       "      <td>107</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>32</td>\n",
       "      <td>185</td>\n",
       "      <td>0.147465</td>\n",
       "      <td>52</td>\n",
       "      <td>282</td>\n",
       "      <td>0.155689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       [lower  upper)  h_Correct  h_Wrong  h_Precent  d_Correct  d_Wrong  \\\n",
       ">80       0.8     1.0          1        2   0.333333          0        0   \n",
       "60-80     0.6     0.8        203       80   0.717314          0        0   \n",
       "50-60     0.5     0.6         77       77   0.500000          0        0   \n",
       "40-50     0.4     0.5         70       92   0.432099          0        0   \n",
       "30-40     0.3     0.4         76      118   0.391753         17       32   \n",
       "20-30     0.2     0.3         41      131   0.238372        215      615   \n",
       "<20       0.0     0.2         21      107   0.164062         32      185   \n",
       "\n",
       "       d_Precent  a_Correct  a_Wrong  a_Precent  \n",
       ">80          NaN          0        0        NaN  \n",
       "60-80        NaN         15        9   0.625000  \n",
       "50-60        NaN         93       59   0.611842  \n",
       "40-50        NaN         73       85   0.462025  \n",
       "30-40   0.346939         54      147   0.268657  \n",
       "20-30   0.259036         56      171   0.246696  \n",
       "<20     0.147465         52      282   0.155689  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findRecordsBy(self,df):\n",
    "    #print((df['DayStamp']).values)\n",
    "    #date = convertToDate((df['DayStamp']).values)\n",
    "    #df[\"Date\"] = date\n",
    "    \n",
    "    home = df['HomeTeam'].values\n",
    "    away = df['AwayTeam'].values\n",
    "    origin = self.df[[\"Date\",\"HomeTeam\",\"AwayTeam\",\"JocH\",\"JocD\",\"JocA\"]]\n",
    "    origin[\"DayStamp\"]=(pd.to_numeric(origin['Date'])/1e9/24/60/60).values\n",
    "    origin[\"DayStamp\"] = origin[\"DayStamp\"].apply(lambda x: \"%.f\"%(float(x)))\n",
    "    df['DayStamp']=df['DayStamp'].apply(lambda x: \"%.f\"%(float(x)))\n",
    "    return origin.merge(df,left_on=['DayStamp',\"HomeTeam\",\"AwayTeam\"],right_on=[\"DayStamp\",\"HomeTeam\",\"AwayTeam\"],how='inner')\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "withodds = findRecordsBy(c,resultdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def formatMatrixs(oddDf , precisionDf):\n",
    "    proba_mat = oddDf[['H_prob','D_prob','A_prob']].values\n",
    "    def locatePrecision(proba_mat, precisionDf):\n",
    "        precisionMat = precisionDf.values\n",
    "        pre_cols=[4,7,10]\n",
    "        def convert(proba, pre_col = 4):\n",
    "            if proba < 0.2:\n",
    "                return proba\n",
    "            for i in range(precisionMat.shape[0]):\n",
    "                if precisionMat[i,0] <= proba and proba < precisionMat[i,1] :\n",
    "                    if math.isnan(precisionMat[i,pre_col]):\n",
    "                        return proba\n",
    "                    else:\n",
    "                        return precisionMat[i,pre_col]\n",
    "        h_fproba = np.array([ convert(float(proba)) for proba in proba_mat[:,0] ] )\n",
    "        d_fproba = np.array([ convert(float(proba),pre_col=7) for proba in proba_mat[:,1] ] )\n",
    "        a_fproba = np.array([ convert(float(proba),pre_col=10) for proba in proba_mat[:,2] ] )\n",
    "        return h_fproba, d_fproba,a_fproba\n",
    "    h_fproba, d_fproba,a_fproba =locatePrecision(proba_mat,precisionDf)\n",
    "    fproba_mat = np.hstack([h_fproba,d_fproba,a_fproba]).reshape(3,h_fproba.shape[0]).T\n",
    "    odd_mat = oddDf[['JocH','JocD','JocA']].values\n",
    "    win_mat = None\n",
    "    if 'H' in oddDf.columns:\n",
    "        win_mat = oddDf[['H','D','A']].values\n",
    "    return fproba_mat,odd_mat,win_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fproba_mat,odd_mat,win_mat= formatMatrixs(withodds,p_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strategy1(fproba_mat,odd_mat,win_mat):\n",
    "    exp = odd_mat * fproba_mat\n",
    "    print(exp)\n",
    "    maxi = np.argmax(exp,axis=1)\n",
    "    print(maxi)\n",
    "    y_true = np.argmax(win_mat,axis=1)\n",
    "    spent = 0\n",
    "    expectation = 0\n",
    "    income = 0\n",
    "    for i in range(maxi.shape[0]):\n",
    "        if exp[i,maxi[i]] > 1:\n",
    "            expectation = expectation+ exp[i,maxi[i]]\n",
    "            spent = spent+1\n",
    "            if maxi[i] == y_true[i]:\n",
    "                income = income + odd_mat[i,maxi[i]]\n",
    "            \n",
    "            \n",
    "        \n",
    "    print(\"Spent:{}, Income:{}, expectation:{}\".format(spent,income,expectation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.03339552e+00   1.04675237e+00   8.94297838e-01]\n",
      " [  8.21849315e-01   9.04600812e-01   6.44336531e-01]\n",
      " [  8.96994536e-01   9.36690647e-01   8.16753927e-01]\n",
      " [  1.00178082e+00   8.27063599e-01   8.51716738e-01]\n",
      " [  6.71511628e-01   1.08776978e+00   1.44656652e+00]\n",
      " [  6.96132597e-01   8.14140731e-01   1.36569106e+00]\n",
      " [  1.71044776e+00   6.39047328e-01   6.70557940e-01]\n",
      " [  7.53767123e-01   9.56292287e-01   8.99754539e-01]\n",
      " [  7.98142077e-01   9.06474820e-01   9.73821990e-01]\n",
      " [  8.80813953e-01   7.88294993e-01   9.32832618e-01]\n",
      " [  9.55161290e-01   3.13147581e-01   4.83380637e-01]\n",
      " [  1.91640922e-01   5.21662380e-01   1.16852630e+00]\n",
      " [  1.21575342e+00   7.62449256e-01   5.33796820e-01]\n",
      " [  1.36740331e+00   1.23884892e+00   6.78901734e-01]\n",
      " [  8.65616438e-01   8.27063599e-01   1.12210300e+00]\n",
      " [  9.94475138e-01   9.51798561e-01   8.56820809e-01]\n",
      " [  8.57734807e-01   8.27063599e-01   9.13005780e-01]\n",
      " [  1.37505661e-01   1.86258842e-01   2.04885686e+00]\n",
      " [  7.98208955e-01   7.75562357e-01   2.19266117e+00]\n",
      " [  9.33606557e-01   1.59804258e+00   4.86921009e-01]\n",
      " [  1.58216418e+00   8.39986468e-01   5.26554066e-01]\n",
      " [  7.73219178e-01   9.69215156e-01   1.24377682e+00]\n",
      " [  5.49180328e-01   1.11798561e+00   1.51416309e+00]\n",
      " [  8.75342466e-01   8.27063599e-01   6.65827831e-01]\n",
      " [  9.69253731e-01   1.05967524e+00   1.22541906e+00]\n",
      " [  8.99657534e-01   8.39986468e-01   6.53730836e-01]\n",
      " [  3.80386740e-01   9.17523681e-01   3.36910569e+00]\n",
      " [  1.05523256e+00   9.66906475e-01   6.94892704e-01]\n",
      " [  6.22465753e-01   1.18890392e+00   1.66541582e+00]\n",
      " [  2.72512452e-01   4.53988700e-01   1.17727273e+00]\n",
      " [  5.89226519e-01   8.01217862e-01   1.26416185e+00]\n",
      " [  1.97704918e+00   9.82138024e-01   4.71204188e-01]\n",
      " [  7.01252885e-01   1.05755396e+00   9.92682927e-01]\n",
      " [  1.07615672e+00   5.64165755e-01   1.51416309e+00]\n",
      " [  9.88524590e-01   9.06474820e-01   7.63350785e-01]\n",
      " [  1.41027397e+00   3.57897199e-01   7.13089005e-01]\n",
      " [  9.34838710e-01   2.44513988e-01   6.28706343e-01]\n",
      " [  2.85179987e-01   2.87325945e-01   1.87727273e+00]\n",
      " [  9.70218579e-01   7.88294993e-01   7.69633508e-01]\n",
      " [  1.09753731e+00   6.86168744e-01   1.48712446e+00]\n",
      " [  9.48387097e-01   1.63693526e-01   2.56565912e-01]\n",
      " [  9.51912568e-01   7.54695535e-01   8.10471204e-01]\n",
      " [  8.36438356e-01   8.78755074e-01   1.13562232e+00]\n",
      " [  1.35410448e+00   3.63497608e-01   9.05793991e-01]\n",
      " [  5.20114092e-01   4.51777467e-01   1.04363636e+00]\n",
      " [  1.12604478e+00   9.82138024e-01   3.13354857e-01]\n",
      " [  3.94726338e-01   6.40660628e-01   1.01818182e+00]\n",
      " [  8.23770492e-01   1.39031401e+00   7.57081545e-01]\n",
      " [  6.85684932e-01   1.04675237e+00   1.25185250e+00]\n",
      " [  3.11647685e-01   4.88010579e-01   2.06818182e+00]\n",
      " [  6.46780822e-01   1.13721245e+00   2.00085837e+00]\n",
      " [  7.02950820e-01   9.66906475e-01   9.59871245e-01]\n",
      " [  7.45856354e-01   9.06474820e-01   7.00523560e-01]\n",
      " [  5.47616327e-01   2.29622126e-01   1.17727273e+00]\n",
      " [  8.37209302e-01   9.36690647e-01   6.95598212e-01]\n",
      " [  7.43224044e-01   9.21582734e-01   1.06806283e+00]\n",
      " [  9.76380597e-01   6.34155348e-01   1.21117437e+00]\n",
      " [  8.96994536e-01   9.66906475e-01   6.89484979e-01]\n",
      " [  6.93313953e-01   8.91677943e-01   1.39248927e+00]\n",
      " [  5.75581395e-01   1.32949640e+00   2.09549356e+00]\n",
      " [  1.03339552e+00   2.56110741e-01   1.51416309e+00]\n",
      " [  9.81104651e-01   7.88294993e-01   7.89527897e-01]\n",
      " [  9.02616279e-01   5.80904518e-01   1.02094241e+00]\n",
      " [  4.20103878e-01   6.18247151e-01   1.14545455e+00]\n",
      " [  1.10466418e+00   1.00798376e+00   7.59614448e-01]\n",
      " [  6.14088398e-01   3.70572278e-01   1.62272727e+00]\n",
      " [  2.45354256e-01   1.08552097e+00   8.90909091e-01]\n",
      " [  7.58132958e-02   5.00004508e-01   1.44688863e+00]\n",
      " [  7.36918605e-01   6.32403348e-01   1.41361257e+00]\n",
      " [  7.87808219e-01   9.04600812e-01   9.16679677e-01]\n",
      " [  1.08328358e+00   6.37020170e-01   8.60793816e-01]\n",
      " [  8.53060109e-01   7.88294993e-01   8.79581152e-01]\n",
      " [  1.12063953e+00   7.36603518e-01   8.41884817e-01]\n",
      " [  7.06395349e-01   9.17523681e-01   1.25729614e+00]\n",
      " [  9.09383562e-01   5.05342014e-01   1.13089005e+00]\n",
      " [  1.21823204e+00   3.89631589e-01   9.73636364e-01]\n",
      " [  8.85174419e-01   7.62449256e-01   1.11518325e+00]\n",
      " [  1.61287121e-01   1.27670658e-01   3.06937829e+00]\n",
      " [  7.60405710e-01   8.52909337e-01   1.08292683e+00]\n",
      " [  8.31575342e-01   8.27063599e-01   1.24377682e+00]\n",
      " [  6.73661202e-01   1.57670450e+00   1.02746781e+00]\n",
      " [  8.45303867e-01   5.70589891e-01   1.19121951e+00]\n",
      " [  7.08563536e-01   1.41272921e+00   6.08369099e-01]\n",
      " [  3.34407225e-01   1.70552871e+00   8.11158798e-01]\n",
      " [  1.99383562e+00   8.78755074e-01   4.70472103e-01]\n",
      " [  9.15697674e-01   8.14140731e-01   8.38197425e-01]\n",
      " [  5.45058140e-01   1.25351827e+00   2.50107296e+00]\n",
      " [  8.71366120e-01   8.27063599e-01   8.23036649e-01]\n",
      " [  5.71147541e-01   1.04244604e+00   1.48712446e+00]\n",
      " [  7.92671233e-01   9.43369418e-01   7.90387785e-01]\n",
      " [  7.76162791e-01   1.01223022e+00   1.06802575e+00]\n",
      " [  9.19365672e-01   2.29741203e-01   1.43122288e+00]\n",
      " [  5.00604312e-01   4.36724567e-01   1.27272727e+00]\n",
      " [  8.75342466e-01   9.82014388e-01   3.37894499e-01]\n",
      " [  9.28064516e-01   9.09550488e-02   2.22816122e-01]\n",
      " [  4.64917127e-01   1.39262190e+00   1.01394850e+00]\n",
      " [  1.93850746e+00   9.82014388e-01   2.00374419e-01]\n",
      " [  5.96775956e-01   1.57006081e+00   8.67056707e-01]\n",
      " [  7.82945205e-01   5.57346869e-01   1.21673820e+00]\n",
      " [  5.71220930e-01   1.11136671e+00   2.27124464e+00]\n",
      " [  4.70169378e-01   4.34346958e-01   1.05000000e+00]\n",
      " [  8.19767442e-01   8.39986468e-01   9.86909871e-01]\n",
      " [  7.45856354e-01   5.67389138e-01   1.32357724e+00]\n",
      " [  1.07703488e+00   1.67862546e+00   2.65069789e-02]\n",
      " [  1.33633880e+00   2.32479954e-01   1.14308943e+00]\n",
      " [  8.16448087e-01   9.21582734e-01   9.26701571e-01]\n",
      " [  5.22346156e-01   3.30033470e-01   1.25917685e+00]\n",
      " [  9.51912568e-01   8.76258993e-01   8.16753927e-01]\n",
      " [  1.63517442e+00   8.27063599e-01   5.87434555e-01]\n",
      " [  6.85684932e-01   4.13146099e-01   1.85214592e+00]\n",
      " [  8.33843284e-01   1.13053545e+00   1.96443340e+00]\n",
      " [  1.21935484e+00   2.90106805e-01   1.78560455e-01]\n",
      " [  1.09836066e+00   8.01217862e-01   6.84816754e-01]\n",
      " [  8.38882059e-01   1.08776978e+00   7.25722543e-01]\n",
      " [  1.01991143e-01   1.24971159e-01   1.59812311e+00]\n",
      " [  1.09011628e+00   5.68221164e-01   8.10471204e-01]\n",
      " [  9.76380597e-01   1.11136671e+00   3.60905512e-01]\n",
      " [  8.60753425e-01   8.52909337e-01   6.56655521e-01]\n",
      " [  8.72093023e-01   5.43427213e-01   1.09947644e+00]\n",
      " [  1.38006874e-02   1.03258871e-02   1.92609039e+00]\n",
      " [  8.85174419e-01   9.21582734e-01   9.19313305e-01]\n",
      " [  1.46075581e+00   7.88294993e-01   5.54291845e-01]\n",
      " [  7.02950820e-01   9.36690647e-01   1.00042918e+00]\n",
      " [  2.64921875e-01   3.27873094e+00   3.53095103e-01]\n",
      " [  1.24720149e+00   1.08776978e+00   9.91997821e-02]\n",
      " [  5.31850800e-01   9.95511957e-02   1.32363636e+00]\n",
      " [  9.81104651e-01   9.51798561e-01   7.65193133e-01]\n",
      " [  4.88372093e-01   1.70581867e+00   3.78540773e+00]\n",
      " [  8.78688525e-01   7.62449256e-01   8.73298429e-01]\n",
      " [  1.24480874e+00   8.52909337e-01   6.06282723e-01]\n",
      " [  8.08011050e-01   7.88294993e-01   1.26341463e+00]\n",
      " [  8.55890411e-01   9.51798561e-01   6.33354516e-01]\n",
      " [  9.55000000e-01   6.93945902e-01   1.33838864e+00]\n",
      " [  9.59302326e-01   8.52909337e-01   8.79581152e-01]\n",
      " [  8.15406977e-01   8.27063599e-01   1.17801047e+00]\n",
      " [  3.36839276e-01   6.08010713e-01   1.15818182e+00]\n",
      " [  5.71823204e-01   9.06474820e-01   9.04712042e-01]\n",
      " [  2.62886292e-01   3.29362514e-01   1.65454545e+00]\n",
      " [  8.19767442e-01   8.39986468e-01   1.14659686e+00]\n",
      " [  9.14516129e-01   4.12867550e-02   1.98349910e-01]\n",
      " [  1.36835821e+00   8.91677943e-01   1.43820427e-01]\n",
      " [  5.88424658e-01   2.09989834e+00   4.77747994e-01]\n",
      " [  8.67704918e-01   9.21582734e-01   8.57591623e-01]\n",
      " [  1.07273224e+00   2.40450630e-01   1.29349593e+00]\n",
      " [  5.62500000e-01   1.13721245e+00   2.40643777e+00]\n",
      " [  9.19365672e-01   7.58491150e-01   1.12789330e+00]\n",
      " [  3.72440835e-02   9.47863490e-03   1.44707633e+00]\n",
      " [  1.74608209e+00   9.21582734e-01   1.20295787e-01]\n",
      " [  1.83761191e-02   2.64767806e+00   3.12102716e-01]\n",
      " [  6.76243094e-01   1.39656712e+00   7.06806283e-01]\n",
      " [  5.88424658e-01   9.80976135e-01   2.70386266e+00]\n",
      " [  1.07703488e+00   5.20977542e-01   1.22670520e+00]\n",
      " [  1.15327869e+00   5.82327513e-01   9.73872832e-01]\n",
      " [  9.14246575e-01   6.15072458e-01   9.46351931e-01]\n",
      " [  9.01644878e-02   1.67874487e-01   1.39238843e+00]\n",
      " [  3.21011487e-01   6.61458778e-01   1.08181818e+00]\n",
      " [  8.50290698e-01   8.39986468e-01   9.19313305e-01]\n",
      " [  4.17907541e-01   2.69245367e+00   1.85551586e-02]\n",
      " [  2.37645349e+00   6.88521758e-01   6.92947977e-01]\n",
      " [  5.14534884e-01   1.69208633e+00   2.11249776e+00]\n",
      " [  8.94193548e-01   9.10416106e-02   1.02643023e+00]\n",
      " [  9.19365672e-01   1.42014388e+00   3.90208983e-01]\n",
      " [  5.19890710e-01   1.19352518e+00   1.99476440e+00]\n",
      " [  8.28488372e-01   8.39986468e-01   9.73390558e-01]\n",
      " [  8.67704918e-01   8.39986468e-01   8.16753927e-01]\n",
      " [  1.46094763e-01   2.29402950e-01   1.35498400e+00]\n",
      " [  6.56506849e-01   7.75505200e-01   1.96030043e+00]\n",
      " [  3.12508962e-01   1.93470579e+00   6.21888412e-01]\n",
      " [  9.95806452e-01   2.20081717e-01   2.70304743e-01]\n",
      " [  1.96451613e+00   2.18196591e-01   2.31163478e-01]\n",
      " [  2.43119490e-01   7.07718101e-01   2.86363636e+00]\n",
      " [  6.33977901e-01   1.71763033e+00   4.54450054e-01]\n",
      " [  1.61620302e-01   7.62449256e-01   1.64181818e+00]\n",
      " [  5.34535519e-01   4.99109919e-01   2.76242775e+00]\n",
      " [  1.01914179e+00   3.03913258e-01   1.62231760e+00]\n",
      " [  8.68865753e-02   2.13363158e-01   1.31686422e+00]\n",
      " [  2.67957864e-01   2.10250926e-01   1.93464269e+00]\n",
      " [  9.22529302e-02   2.10837483e-01   1.61495983e+00]\n",
      " [  1.24645161e+00   1.98217381e-01   1.22647891e-01]\n",
      " [  1.11179104e+00   2.80117504e-01   1.52356021e+00]\n",
      " [  6.36627907e-01   9.69215156e-01   1.94764398e+00]\n",
      " [  1.00258065e+00   2.92420697e-01   5.71834257e-01]\n",
      " [  8.87419355e-01   2.15686502e-01   4.45616917e-02]\n",
      " [  1.24692010e+00   3.63485859e-01   8.52727273e-01]\n",
      " [  7.48904110e-01   6.67449895e-01   1.29785408e+00]\n",
      " [  5.71147541e-01   9.56292287e-01   1.57068063e+00]\n",
      " [  4.50327869e-01   1.22767253e+00   5.15028902e+00]\n",
      " [  1.16712329e+00   1.45483962e+00   4.79532979e-02]\n",
      " [  1.20580110e+00   1.69298437e+00   4.29914163e-01]\n",
      " [  1.33633880e+00   8.39986468e-01   8.80231214e-01]\n",
      " [  1.21156716e+00   3.32882882e-01   5.79300523e-01]\n",
      " [  9.02616279e-01   9.97122302e-01   8.24678112e-01]\n",
      " [  1.01598837e+00   9.66906475e-01   7.30042918e-01]\n",
      " [  4.83278689e-01   1.12428958e+00   2.51308901e+00]\n",
      " [  6.32267442e-01   1.19352518e+00   1.59527897e+00]\n",
      " [  9.34838710e-01   4.73811065e-01   1.60080189e-01]\n",
      " [  9.07458564e-01   1.40130129e+00   5.90575916e-01]\n",
      " [  1.55806452e+00   2.49231873e-04   8.58008229e-04]\n",
      " [  1.60478805e-02   3.16636171e-02   1.55143930e+00]\n",
      " [  5.16695956e-02   3.84867281e-02   2.18171324e+00]\n",
      " [  8.48097015e-01   5.69696929e-01   2.83905579e+00]\n",
      " [  6.95628415e-01   9.82014388e-01   9.73390558e-01]\n",
      " [  1.04068493e+00   9.66906475e-01   2.53780581e-01]\n",
      " [  1.32559701e+00   9.97122302e-01   1.78083093e-01]\n",
      " [  1.30813953e+00   8.39986468e-01   5.73218884e-01]\n",
      " [  8.96994536e-01   9.51798561e-01   6.97596567e-01]\n",
      " [  4.06700091e-01   4.02966645e-01   1.60363636e+00]\n",
      " [  6.83701657e-01   5.09227797e-01   1.52727273e+00]\n",
      " [  6.77322404e-01   9.82014388e-01   1.02746781e+00]\n",
      " [  4.89779006e-01   9.36690647e-01   1.11518325e+00]\n",
      " [  1.35464481e+00   5.12579687e-01   8.42774566e-01]\n",
      " [  1.43962687e+00   1.48283965e-01   8.38197425e-01]\n",
      " [  9.55000000e-01   3.23276963e-01   9.60548416e-01]\n",
      " [  4.62430939e-01   2.23629055e+00   2.62862159e-01]\n",
      " [  1.59193548e+00   4.22450248e-02   2.69058820e-01]\n",
      " [  5.78794826e-03   1.19922328e-02   1.45414041e+00]\n",
      " [  1.58216418e+00   2.27860844e-01   7.62489270e-01]\n",
      " [  1.11774194e+00   7.08793098e-01   7.46402484e-03]\n",
      " [  8.46774194e-01   4.15042508e-03   9.52196633e-02]\n",
      " [  1.28633721e+00   5.80225754e-01   6.81675393e-01]\n",
      " [  8.89931507e-01   1.98124890e-01   1.14659686e+00]\n",
      " [  8.69477612e-01   1.34397835e+00   1.05636127e+00]\n",
      " [  6.88306011e-01   8.01217862e-01   1.20942408e+00]\n",
      " [  3.38475084e-02   2.72890878e-01   2.22618645e+00]\n",
      " [  9.07978142e-01   9.82014388e-01   7.79057592e-01]\n",
      " [  6.51693989e-01   1.02733813e+00   1.22513089e+00]\n",
      " [  7.85806452e-01   5.16097235e-03   8.99702269e-02]\n",
      " [  6.07759563e-01   8.78755074e-01   2.15375723e+00]\n",
      " [  7.23837209e-01   1.45023282e+00   4.35141271e-01]\n",
      " [  4.84806630e-01   1.74854800e+00   5.79523471e-01]\n",
      " [  5.64364641e-01   1.55447647e+00   7.84120172e-01]\n",
      " [  1.28633721e+00   1.58360463e+00   2.37734147e-01]\n",
      " [  1.51089552e+00   4.20896562e-01   4.22614129e-01]\n",
      " [  7.40883978e-01   9.36690647e-01   6.91099476e-01]\n",
      " [  3.29293566e-01   4.52305037e-01   1.84545455e+00]\n",
      " [  1.51939891e+00   7.96070185e-02   1.05636364e+00]\n",
      " [  7.50546448e-01   9.97122302e-01   9.73821990e-01]\n",
      " [  1.77500000e+00   1.46931089e-01   5.68586387e-01]\n",
      " [  1.05523256e+00   9.51798561e-01   4.56004996e-01]\n",
      " [  7.65483871e-01   1.72685177e-01   1.96131371e+00]\n",
      " [  2.22383721e+00   1.82276691e-01   9.14471545e-01]\n",
      " [  5.05245902e-01   1.23884892e+00   2.16753927e+00]\n",
      " [  1.31847015e+00   8.39986468e-01   2.17787395e-01]\n",
      " [  1.09041045e+00   9.56292287e-01   4.14368177e-01]\n",
      " [  1.09836066e+00   9.21582734e-01   6.00257511e-01]\n",
      " [  7.71802326e-01   8.91677943e-01   1.05450644e+00]\n",
      " [  1.62492537e+00   9.97122302e-01   6.86004929e-02]\n",
      " [  7.61530055e-01   9.21582734e-01   1.03664921e+00]\n",
      " [  5.78469945e-01   1.08776978e+00   1.53926702e+00]\n",
      " [  1.80405645e-03   1.83662510e+00   1.47485549e+00]\n",
      " [  8.26716418e-01   8.23329985e-01   3.24463519e+00]\n",
      " [  2.48495970e-02   6.60106134e-04   2.78893182e+00]\n",
      " [  1.65343284e+00   6.15739717e-01   3.40222833e-02]\n",
      " [  1.46100746e+00   2.93872774e-01   9.89528796e-01]\n",
      " [  3.65085643e-01   1.43844364e-01   1.51902822e+00]\n",
      " [  1.16516129e+00   2.90539179e-03   7.48058494e-02]\n",
      " [  4.96400194e-03   5.28669753e-01   1.83152432e+00]\n",
      " [  7.99354839e-01   2.04358448e-04   5.42034303e-03]\n",
      " [  1.40956284e+00   8.65832206e-01   8.42774566e-01]\n",
      " [  1.39110927e-01   1.62740107e+00   8.90406504e-01]\n",
      " [  1.28283582e+00   4.51823559e-01   1.08154506e+00]]\n",
      "[1 1 1 0 2 2 0 1 2 2 0 2 0 0 2 0 2 2 2 1 0 2 2 0 2 0 2 0 2 2 2 0 1 2 0 0 0\n",
      " 2 0 2 0 0 2 0 2 0 2 1 2 2 2 1 1 2 1 2 2 1 2 2 2 0 2 2 0 2 1 2 2 2 0 2 0 2\n",
      " 2 0 2 2 2 2 1 2 1 1 0 0 2 0 2 1 2 2 2 1 0 1 0 1 2 2 2 2 2 1 0 2 2 0 0 2 2\n",
      " 0 0 1 2 0 1 0 2 2 1 0 2 1 0 2 0 2 0 0 2 1 2 0 2 2 1 2 2 0 0 1 1 2 2 2 2 0\n",
      " 1 1 2 2 0 2 2 2 2 1 0 2 2 1 2 2 0 2 2 1 0 0 2 1 2 2 2 2 2 2 0 2 2 0 0 0 2\n",
      " 2 2 1 1 0 0 1 0 2 2 0 1 0 2 2 2 1 0 0 0 1 2 2 2 2 0 0 2 1 0 2 0 0 0 0 2 1\n",
      " 2 2 1 2 0 2 1 1 1 1 0 1 2 0 1 0 0 2 0 2 0 0 0 2 0 2 2 1 2 2 0 0 2 0 2 0 0\n",
      " 1 0]\n",
      "Spent:205, Income:258.19, expectation:322.188139700667\n"
     ]
    }
   ],
   "source": [
    "strategy1(fproba_mat,odd_mat,win_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strategy4(fproba_mat,odd_mat,win_mat,info, z = 0.2 ,e =1.8 ):\n",
    "    exp = odd_mat * fproba_mat\n",
    "    y_true=None\n",
    "    if win_mat is None:\n",
    "        y_true = np.zeros(shape=(fproba_mat.shape[0],))\n",
    "    else:\n",
    "        y_true = np.argmax(win_mat,axis=1)\n",
    "    spent = 0\n",
    "    expectation = 0\n",
    "    income = 0\n",
    "    total = fproba_mat.shape[0]\n",
    "    withdraw = 0\n",
    "    buy = 0\n",
    "    homeTeam = info[\"HomeTeam\"].values\n",
    "    awayTeam = info[\"AwayTeam\"].values\n",
    "    receipt = []\n",
    "    def chooseFrom(match, chosable):\n",
    "        max_prob = -1\n",
    "        c = 0\n",
    "        for choice in chosable:\n",
    "            if fproba_mat[match,choice] > max_prob:\n",
    "                c = choice\n",
    "                max_prob = fproba_mat[match,choice]\n",
    "        return c\n",
    "    for match in range(exp.shape[0]):\n",
    "        chosable = []\n",
    "        for choose in range(3):\n",
    "            if exp[match,choose]> e and fproba_mat[match,choose] >= z:\n",
    "                chosable.append(choose)\n",
    "                \n",
    "        if len(chosable) == 0:\n",
    "            withdraw= withdraw+1\n",
    "            continue\n",
    "        choice = chooseFrom(match,chosable)\n",
    "        expectation = expectation+ exp[match,choice]\n",
    "        spent = spent+1\n",
    "        buy =buy +1 \n",
    "        receipt.append(np.hstack([homeTeam[match],awayTeam[match], odd_mat[match,choice],choice,y_true[match],fproba_mat[match,:]]))\n",
    "        if choice == y_true[match]:\n",
    "            income = income + odd_mat[match,choice]\n",
    "    #print(buy)\n",
    "    #print(\"Spent:{}, Income:{}, expectation:{}, withdraw:{}(total:{})\".\n",
    "    #      format(spent,income,expectation,withdraw,total))\n",
    "    receiptDf = pd.DataFrame(receipt,columns=[\"home\",\"away\",\"odd of choice\",\"choice\",\"result\",\"Hp\",\"Dp\",\"Ap\"])\n",
    "    return spent,income,expectation,withdraw,total,receiptDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spent,income,expectation,withdraw,total,receipt = strategy4(fproba_mat,odd_mat,win_mat,withodds,z=0.2,e=1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_z_range = np.arange(0,1,0.05)\n",
    "g_e_range = np.arange(1,2,0.05)\n",
    "g_incomes = []\n",
    "g_spents =[]\n",
    "g_withdraws=[]\n",
    "g_exps=[]\n",
    "g_total = 0\n",
    "for e in g_e_range:\n",
    "    for z in g_z_range:\n",
    "        spent,income,expectation,withdraw,total,receipt = strategy4(fproba_mat,odd_mat,win_mat,withodds,z=z,e=e)\n",
    "        g_spents.append(spent)\n",
    "        g_incomes.append(income)\n",
    "        g_withdraws.append(withdraw)\n",
    "        g_exps.append(expectation)\n",
    "        g_total= total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f1cc5a860>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEKCAYAAADDzOROAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f1c4efa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEKCAYAAABT352BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrJl/npQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f1c56b2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEKCAYAAADDzOROAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f1c836c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWMAAAEKCAYAAADHOTRzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxmZmDeAwNjNrAIexmVkD/H/7Eok92TkKSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f1ca6b4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f1cc5a860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "g_n_incomes = np.array(g_incomes).reshape(len(g_e_range),len(g_z_range))\n",
    "g_n_spent = np.array(g_spents).reshape(len(g_e_range),len(g_z_range))\n",
    "g_n_withdraws = np.array(g_withdraws).reshape(len(g_e_range),len(g_z_range))\n",
    "g_n_exps = np.array(g_exps).reshape(len(g_e_range),len(g_z_range))\n",
    "Z, E =np.meshgrid(g_z_range,g_e_range)\n",
    "CS = plt.contour = plt.contourf(Z,E,g_n_incomes)\n",
    "plt.title(\"Income\")\n",
    "cbar = plt.colorbar(CS)\n",
    "plt.figure()\n",
    "CS = plt.contour = plt.contourf(Z,E,g_n_incomes-g_n_spent)\n",
    "plt.title(\"Net Income\")\n",
    "cbar = plt.colorbar(CS)\n",
    "plt.figure()\n",
    "CS = plt.contour = plt.contourf(Z,E,g_n_withdraws)\n",
    "plt.title(\"Withdraws\")\n",
    "cbar = plt.colorbar(CS)\n",
    "plt.figure()\n",
    "CS = plt.contour = plt.contourf(Z,E,g_n_exps - g_n_incomes)\n",
    "plt.title(\"Exps - income\")\n",
    "cbar = plt.colorbar(CS)\n",
    "plt.figure()\n",
    "CS = plt.contour = plt.contourf(Z,E, (g_n_incomes-g_n_spent)/g_n_spent)\n",
    "plt.title(\"net_income/spents\")\n",
    "cbar = plt.colorbar(CS)\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_node_sizes=[55,55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPrecisionMaxtrix(node_sizes,c):\n",
    "    X, y = c.getH7(removeInsufficient=True)\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    _,_, proba_test,proba_y = crossValidate2(node_sizes,X_scaled,y,fold=10)\n",
    "    p_matrix = precisionMatrix(np.vstack(proba_test),np.vstack(proba_y)) \n",
    "    return p_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start format\n",
      "finish\n",
      "Epoch 00035: early stopping\n",
      "137/137 [==============================] - 0s     \n",
      "137/137 [==============================] - 0s     \n",
      "1221/1221 [==============================] - 0s     \n",
      "Fold: 1, Class dist.: [539 298 384], val_loss: 1.001\n",
      "Epoch 00058: early stopping\n",
      "137/137 [==============================] - 0s     \n",
      "137/137 [==============================] - 0s     \n",
      "1221/1221 [==============================] - 0s     \n",
      "Fold: 2, Class dist.: [539 298 384], val_loss: 1.006\n",
      "Epoch 00061: early stopping\n",
      "136/136 [==============================] - 0s     \n",
      "136/136 [==============================] - 0s     \n",
      "1222/1222 [==============================] - 0s     \n",
      "Fold: 3, Class dist.: [539 299 384], val_loss: 0.944\n",
      "Epoch 00098: early stopping\n",
      "136/136 [==============================] - 0s     \n",
      "136/136 [==============================] - 0s     \n",
      "1222/1222 [==============================] - 0s     \n",
      "Fold: 4, Class dist.: [539 299 384], val_loss: 0.958\n",
      "Epoch 00091: early stopping\n",
      "136/136 [==============================] - 0s     \n",
      "136/136 [==============================] - 0s     \n",
      "1222/1222 [==============================] - 0s     \n",
      "Fold: 5, Class dist.: [539 299 384], val_loss: 1.027\n",
      "Epoch 00037: early stopping\n",
      "136/136 [==============================] - 0s     \n",
      "136/136 [==============================] - 0s     \n",
      "1222/1222 [==============================] - 0s     \n",
      "Fold: 6, Class dist.: [539 299 384], val_loss: 0.990\n",
      "Epoch 00066: early stopping\n",
      "136/136 [==============================] - 0s     \n",
      "136/136 [==============================] - 0s     \n",
      "1222/1222 [==============================] - 0s     \n",
      "Fold: 7, Class dist.: [539 299 384], val_loss: 0.997\n",
      "Epoch 00030: early stopping\n",
      "135/135 [==============================] - 0s     \n",
      "135/135 [==============================] - 0s     \n",
      "1223/1223 [==============================] - 0s     \n",
      "Fold: 8, Class dist.: [539 299 385], val_loss: 1.041\n",
      "Epoch 00044: early stopping\n",
      "135/135 [==============================] - 0s     \n",
      "135/135 [==============================] - 0s     \n",
      "1223/1223 [==============================] - 0s     \n",
      "Fold: 9, Class dist.: [539 299 385], val_loss: 1.041\n",
      "Epoch 00030: early stopping\n",
      "134/134 [==============================] - 0s     \n",
      "134/134 [==============================] - 0s     \n",
      "1224/1224 [==============================] - 0s     \n",
      "Fold: 10, Class dist.: [540 299 385], val_loss: 1.026\n"
     ]
    }
   ],
   "source": [
    "g_p_matrix= getPrecisionMaxtrix(g_node_sizes,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainedModel(node_sizes,c):\n",
    "    X, y = c.getH7(removeInsufficient=True)\n",
    "    X_scaled = StandardScaler().fit_transform(X) \n",
    "    model = createModel(node_sizes,X_scaled.shape[1])\n",
    "    earlyCallback = EarlyStopping(patience=20,verbose=1)\n",
    "    history = model.fit(X_scaled,y,verbose=0,nb_epoch=500, validation_split=0.1, callbacks=[earlyCallback])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start format\n",
      "finish\n",
      "Epoch 00083: early stopping\n"
     ]
    }
   ],
   "source": [
    "g_model = getTrainedModel(g_node_sizes,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def predictFuture(node_sizes,c,p_matrix,model):\n",
    "    X_test,y_test = c.getH7(removeInsufficient = True,future=True)\n",
    "    X_test_scaled = StandardScaler().fit_transform(X_test)\n",
    "    proba_y = model.predict_proba(X_test_scaled)\n",
    "   \n",
    "    def getTestDf (X_test,proba_y,c):\n",
    "        decoded = oneHotDecode(c, X_test)\n",
    "        homeNames = c.inverseTeamMapping(decoded[:,0])\n",
    "        awayNames = c.inverseTeamMapping(decoded[:,1])\n",
    "        names = np.array([homeNames,awayNames]).T\n",
    "        return pd.DataFrame(np.hstack([names,proba_y]),columns=['HomeTeam','AwayTeam','H_prob','D_prob','A_prob'])\n",
    "   \n",
    "    test_df = getTestDf(X_test,proba_y,c)\n",
    "    test_df = test_df.sort(columns=\"HomeTeam\")\n",
    "    originDf = c.df[c.df[\"Future\"]==1].sort(columns=\"HomeTeam\")\n",
    "    test_df['JocH']=originDf['JocH'].values\n",
    "    test_df['JocD']=originDf['JocD'].values\n",
    "    test_df['JocA']=originDf['JocA'].values\n",
    "    fproba_mat,odd_mat,_= formatMatrixs(test_df,p_matrix)\n",
    "    return fproba_mat,odd_mat,test_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start format\n",
      "finish\n",
      "9/9 [==============================] - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "fproba_mat,odd_mat,test_df=predictFuture(g_node_sizes,c,g_p_matrix,g_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spent,income,expectation,withdraw,total,receipt = strategy4(fproba_mat,odd_mat,None,test_df,z=0.2,e=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "      <th>odd of choice</th>\n",
       "      <th>choice</th>\n",
       "      <th>result</th>\n",
       "      <th>Hp</th>\n",
       "      <th>Dp</th>\n",
       "      <th>Ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Man City</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2930232558139535</td>\n",
       "      <td>0.2519954389965792</td>\n",
       "      <td>0.6341463414634146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leicester</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6721311475409836</td>\n",
       "      <td>0.17790399491786957</td>\n",
       "      <td>0.10948322713375092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>2.82</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2930232558139535</td>\n",
       "      <td>0.2519954389965792</td>\n",
       "      <td>0.6341463414634146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          home         away odd of choice choice result                  Hp  \\\n",
       "0  Bournemouth     Man City           1.9      2    0.0  0.2930232558139535   \n",
       "1    Leicester  Southampton          1.95      0    0.0  0.6721311475409836   \n",
       "2    Liverpool    Tottenham          2.82      2    0.0  0.2930232558139535   \n",
       "\n",
       "                    Dp                   Ap  \n",
       "0   0.2519954389965792   0.6341463414634146  \n",
       "1  0.17790399491786957  0.10948322713375092  \n",
       "2   0.2519954389965792   0.6341463414634146  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receipt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/y/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Everton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Tottenham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>Swansea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Watford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>Newcastle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>West Brom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Man City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>Crystal Palace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>2016-03-20</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>Bournemouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>2016-03-20</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>2016-03-20</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>Sunderland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2016-03-20</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Man United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>West Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>Norwich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Watford</td>\n",
       "      <td>Stoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>Aston Villa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Leicester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>2016-03-14</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Newcastle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>2016-03-13</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Tottenham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Swansea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>Man City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>2016-03-06</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>Man United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>2016-03-06</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>2016-03-05</td>\n",
       "      <td>Everton</td>\n",
       "      <td>West Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>2016-03-05</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>Bournemouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>2016-03-05</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Stoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>2016-03-05</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Sunderland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2012-09-15</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>Man City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2012-09-02</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Man United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2012-09-02</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>Aston Villa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2012-09-02</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2012-09-01</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>Everton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2012-09-01</td>\n",
       "      <td>Wigan</td>\n",
       "      <td>Stoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2012-09-01</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>Fulham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2012-09-01</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>Sunderland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2012-09-01</td>\n",
       "      <td>Man City</td>\n",
       "      <td>QPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2012-09-01</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>Norwich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2012-08-26</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Man City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2012-08-26</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2012-08-25</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>West Brom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2012-08-25</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>West Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2012-08-25</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Wigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2012-08-25</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>QPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2012-08-25</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Fulham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012-08-25</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Newcastle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012-08-25</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Everton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012-08-22</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012-08-20</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Man United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-08-19</td>\n",
       "      <td>Wigan</td>\n",
       "      <td>Chelsea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012-08-19</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-08-18</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>Tottenham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-08-18</td>\n",
       "      <td>Reading</td>\n",
       "      <td>Stoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-08-18</td>\n",
       "      <td>QPR</td>\n",
       "      <td>Swansea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-08-18</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Norwich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-08-18</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012-08-18</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>Aston Villa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-08-18</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Sunderland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1452 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        HomeTeam        AwayTeam\n",
       "1451 2016-04-03       Leicester     Southampton\n",
       "1450 2016-04-03      Man United         Everton\n",
       "1449 2016-04-03       Liverpool       Tottenham\n",
       "1446 2016-04-02           Stoke         Swansea\n",
       "1443 2016-04-02         Arsenal         Watford\n",
       "1445 2016-04-02         Norwich       Newcastle\n",
       "1447 2016-04-02      Sunderland       West Brom\n",
       "1444 2016-04-02     Bournemouth        Man City\n",
       "1448 2016-04-02        West Ham  Crystal Palace\n",
       "1442 2016-03-20       Tottenham     Bournemouth\n",
       "1441 2016-03-20     Southampton       Liverpool\n",
       "1440 2016-03-20       Newcastle      Sunderland\n",
       "1439 2016-03-20        Man City      Man United\n",
       "1433 2016-03-19         Chelsea        West Ham\n",
       "1438 2016-03-19       West Brom         Norwich\n",
       "1437 2016-03-19         Watford           Stoke\n",
       "1436 2016-03-19         Swansea     Aston Villa\n",
       "1435 2016-03-19         Everton         Arsenal\n",
       "1434 2016-03-19  Crystal Palace       Leicester\n",
       "1432 2016-03-14       Leicester       Newcastle\n",
       "1431 2016-03-13     Aston Villa       Tottenham\n",
       "1428 2016-03-12     Bournemouth         Swansea\n",
       "1430 2016-03-12           Stoke     Southampton\n",
       "1429 2016-03-12         Norwich        Man City\n",
       "1427 2016-03-06       West Brom      Man United\n",
       "1426 2016-03-06  Crystal Palace       Liverpool\n",
       "1419 2016-03-05         Everton        West Ham\n",
       "1421 2016-03-05       Newcastle     Bournemouth\n",
       "1418 2016-03-05         Chelsea           Stoke\n",
       "1422 2016-03-05     Southampton      Sunderland\n",
       "...         ...             ...             ...\n",
       "35   2012-09-15           Stoke        Man City\n",
       "28   2012-09-02     Southampton      Man United\n",
       "27   2012-09-02       Newcastle     Aston Villa\n",
       "26   2012-09-02       Liverpool         Arsenal\n",
       "23   2012-09-01       West Brom         Everton\n",
       "25   2012-09-01           Wigan           Stoke\n",
       "24   2012-09-01        West Ham          Fulham\n",
       "21   2012-09-01         Swansea      Sunderland\n",
       "20   2012-09-01        Man City             QPR\n",
       "22   2012-09-01       Tottenham         Norwich\n",
       "18   2012-08-26       Liverpool        Man City\n",
       "19   2012-08-26           Stoke         Arsenal\n",
       "17   2012-08-25       Tottenham       West Brom\n",
       "16   2012-08-25         Swansea        West Ham\n",
       "15   2012-08-25     Southampton           Wigan\n",
       "14   2012-08-25         Norwich             QPR\n",
       "13   2012-08-25      Man United          Fulham\n",
       "12   2012-08-25         Chelsea       Newcastle\n",
       "11   2012-08-25     Aston Villa         Everton\n",
       "10   2012-08-22         Chelsea         Reading\n",
       "9    2012-08-20         Everton      Man United\n",
       "8    2012-08-19           Wigan         Chelsea\n",
       "7    2012-08-19        Man City     Southampton\n",
       "2    2012-08-18       Newcastle       Tottenham\n",
       "4    2012-08-18         Reading           Stoke\n",
       "3    2012-08-18             QPR         Swansea\n",
       "1    2012-08-18          Fulham         Norwich\n",
       "5    2012-08-18       West Brom       Liverpool\n",
       "6    2012-08-18        West Ham     Aston Villa\n",
       "0    2012-08-18         Arsenal      Sunderland\n",
       "\n",
       "[1452 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.df[[\"Date\",\"HomeTeam\",\"AwayTeam\"]].sort(columns =\"Date\",ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
