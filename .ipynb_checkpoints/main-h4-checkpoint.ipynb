{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "try:\n",
    "    from IPython.core.display import clear_output\n",
    "    have_ipython = True\n",
    "except ImportError:\n",
    "    have_ipython = False\n",
    "import sys\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotCurve(train_mean, train_std,test_mean,test_std,sizes):\n",
    "    plt.plot(sizes, train_mean, \n",
    "            color='blue', marker='o', \n",
    "            markersize=5, \n",
    "            label='training accuracy')\n",
    "    plt.fill_between(sizes, \n",
    "                  train_mean + train_std,\n",
    "                   train_mean - train_std, alpha=0.15, color='blue')\n",
    "\n",
    "    plt.plot(sizes, test_mean, \n",
    "              color='green', linestyle='--', \n",
    "              marker='s', markersize=5, \n",
    "             label='validation accuracy')\n",
    "    plt.fill_between(sizes, \n",
    "                      test_mean + test_std,\n",
    "                     test_mean - test_std, \n",
    "                    alpha=0.15, color='green')\n",
    "    plt.xlabel('x_range')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "def likehoodScore(proba,y):\n",
    "    return np.sum(proba * y)/proba.shape[0]\n",
    "\n",
    "def firstNScore(n, pred, y):\n",
    "    for r in range(pred.shape[0]):\n",
    "        row = pred[r]\n",
    "        s = np.sort(row)\n",
    "        for c in range(pred.shape[1]):\n",
    "            temp = pred[r][c]\n",
    "            pred[r][c] = False\n",
    "            for j in range(1,n+1):\n",
    "                if temp == s[-j]:\n",
    "                    pred[r][c] = True\n",
    "                    break\n",
    "    res = np.sum(np.logical_and(pred,y))/pred.shape[0]\n",
    "    return res               \n",
    "\n",
    "def oneHotDecode(self, X_sample):\n",
    "    result=None\n",
    "    fiPos = 0\n",
    "    colIndex = 0\n",
    "    while colIndex < X_sample.shape[1]:\n",
    "        if fiPos < len(self.ohe.categorical_features) and colIndex == self.ohe.feature_indices_[fiPos]:                \n",
    "            start = self.ohe.feature_indices_[fiPos]\n",
    "            end_ = start+ self.ohe.n_values_[fiPos]\n",
    "            classes = np.argmax(X_sample[:,start:end_],axis=1).reshape(X_sample.shape[0],1)\n",
    "            if result is None:\n",
    "                result = classes\n",
    "            else:\n",
    "                result=np.hstack([result,classes])\n",
    "            colIndex = end_\n",
    "            fiPos = fiPos +1\n",
    "        else:\n",
    "            if result is None:\n",
    "                result = X_sample[:,colIndex:colIndex+1]\n",
    "            else:\n",
    "                result=np.hstack([result, X_sample[:,colIndex:colIndex+1]])\n",
    "            colIndex = colIndex +1\n",
    "        \n",
    "    return result \n",
    "def convertToDate(dayStamps):\n",
    "    res = [] \n",
    "    for v in dayStamps:\n",
    "        res.append(datetime.datetime.fromtimestamp(v*24*60*60))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "class FootballDataHelper:\n",
    "    def __init__ (self, recentNum=5):\n",
    "        self.win_mapping = {'H':0, 'D':1,'A':2}\n",
    "        self.recentNum = recentNum\n",
    "        self.df = None\n",
    "        #self.hiddensCount = 2\n",
    "       \n",
    "        \n",
    "    def readFootBallData(self,filename): \n",
    "        df = pd.read_csv(filename)\n",
    "        df = df.drop(df.columns[range(23,df.shape[1])], axis=1)\n",
    "        df = df.drop(\"Div\",axis=1)\n",
    "        df['Date'] = pd.to_datetime(df['Date'],dayfirst=True)\n",
    "        df['HTR'] = df['HTR'].map(self.win_mapping)\n",
    "        df['FTR'] = df['FTR'].map(self.win_mapping)\n",
    "        df= df.drop('Referee', 1)\n",
    "        print(df.shape)\n",
    "          #self.team = df['HomeTeam'].drop_duplicates()\n",
    "        if self.df is None:\n",
    "            self.df = df\n",
    "        else:\n",
    "            self.df = pd.concat([self.df,df])\n",
    "            \n",
    "        teams = self.df['HomeTeam'].drop_duplicates()\n",
    "        teamMap = {}\n",
    "        for index , v in enumerate(teams):\n",
    "            teamMap[v] = index\n",
    "        self.teamsMap = teamMap\n",
    " \n",
    "    def getTeam(self,dataFrame, teamName):       \n",
    "        return dataFrame[(dataFrame[\"HomeTeam\"] == teamName) | (dataFrame[\"AwayTeam\"] == teamName)]\n",
    " \n",
    "        \n",
    "    def previousRecords(self,team, date , recentNum):\n",
    "        prev = team[( team[\"Date\"] < date)]\n",
    "        \n",
    "        if prev.shape[0] < recentNum :\n",
    "            #print(\"less than min Num\")\n",
    "            return None\n",
    "        else:\n",
    "            return prev.iloc[-recentNum:]\n",
    "    def readPredict (self, filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        df['Date'] = pd.to_datetime(df['Date'],dayfirst=True)\n",
    "        df['FTR'] = df['FTR'].map(self.win_mapping)\n",
    "        return df\n",
    "    \n",
    "    \n",
    "  \n",
    "    def inverseTeamMapping (self, col):\n",
    "        inverseMap ={}\n",
    "        for name in self.teamsMap.keys():        \n",
    "            inverseMap[self.teamsMap[name]] = name\n",
    "        res =[]\n",
    "        for idex, v in enumerate(col):\n",
    "            res.append(inverseMap[v])\n",
    "        return res\n",
    "\n",
    "    def getH1(self):\n",
    "        #recent matches (only win/loss/draw)\n",
    "       \n",
    "        \n",
    "       # print (self.df)      \n",
    "        X  = self.df.sort_values(by=\"Date\")\n",
    "        y = []\n",
    "        for v in X['FTR']:\n",
    "            y.append(range(3)==v)\n",
    "       # print(y)\n",
    "        resy=[]\n",
    "        resx=[]\n",
    "        print(\"h1:start format\")\n",
    "        for i in range(X.shape[0]):\n",
    "            \n",
    "            sys.stdout.write(\"\\r progress {}\".format(i))\n",
    "            sys.stdout.flush()\n",
    "            x = X.iloc[i]\n",
    "            homeName = x['HomeTeam']\n",
    "            awayName = x['AwayTeam']\n",
    "            homeTeam = self.getTeam(X,homeName)\n",
    "            awayTeam = self.getTeam(X,awayName)\n",
    "            prevHome = self.previousRecords(homeTeam,x['Date'])\n",
    "            prevAway = self.previousRecords(awayTeam,x['Date'])\n",
    "            if prevHome is None or prevAway is None:\n",
    "               # print(\"{} skip\".format(i))\n",
    "                continue\n",
    "            prevHomeWin = []\n",
    "            prevAwayWin = []\n",
    "            for v in prevHome['FTR']:\n",
    "                prevHomeWin.append(range(3) == v)\n",
    "            #print(prevHomeWin)\n",
    "            for v in prevAway['FTR']:\n",
    "                prevAwayWin.append(range(3) == v)\n",
    "            pHHT=(prevHome['HomeTeam']==homeName).values\n",
    "            pAHT=(prevAway['HomeTeam']==awayName).values\n",
    "            tempX=[]\n",
    "            for j in range(pHHT.shape[0]):\n",
    "                tempX.append(np.append(prevHomeWin[j],pHHT[j]))\n",
    "                \n",
    "            for j in range(pAHT.shape[0]):\n",
    "                tempX.append(np.append(prevAwayWin[j],pAHT[j]))\n",
    "            resx.append(np.ravel(tempX))\n",
    "            \n",
    "            resy.append(y[i])\n",
    "        print(\"finish\")\n",
    "        sys.stdout.flush()\n",
    "        return np.array(resx), np.array(resy)\n",
    "    def getH2(self):         \n",
    "       #team based      \n",
    "        X  = self.df.sort_values(by=\"Date\")\n",
    "        y = []\n",
    "        for v in X['FTR']:\n",
    "            y.append(range(3)==v)\n",
    "       # print(y)\n",
    "        resy=[]\n",
    "        resx=[]\n",
    "        print(\"h1:start format\")\n",
    "        X['HomeTeam'] = X['HomeTeam'].map(self.teamsMap)\n",
    "        X['AwayTeam'] = X['AwayTeam'].map(self.teamsMap)\n",
    "        nativeX = X[['HomeTeam','AwayTeam']].values\n",
    "        #print(X)\n",
    "        ohe = OneHotEncoder(categorical_features=[0,1])\n",
    "        res = ohe.fit_transform(nativeX).toarray()\n",
    "        #print(res)\n",
    "        return res, np.array(y)\n",
    "    def _getH3RecentMatches(self,x, X,teamName,recentNum):\n",
    "        team = self.getTeam(X,teamName)\n",
    "        prev = self.previousRecords(team,x['Date'],recentNum)\n",
    "        if prev is None:\n",
    "               return None\n",
    "        prevHt=  prev['HomeTeam'].values\n",
    "        prevAt=  prev['AwayTeam'].values   \n",
    "        prevIsHome = []\n",
    "        prevOther = []\n",
    "        for i in range(recentNum):\n",
    "            if prevHt[i] == teamName:\n",
    "                prevIsHome.append(1)\n",
    "                prevOther.append(prevAt[i])\n",
    "            else:\n",
    "                prevIsHome.append(0)\n",
    "                prevOther.append(prevHt[i])\n",
    "        wins = prev['FTR'].values       \n",
    "        temp = np.array([prevIsHome,prevOther,wins]).T\n",
    "\n",
    "        return np.ravel(temp)\n",
    "        \n",
    "    def getH3(self, recentNum):\n",
    "        X  = self.df.sort_values(by=\"Date\")\n",
    "        X['HomeTeam'] = X['HomeTeam'].map(self.teamsMap)\n",
    "        X['AwayTeam'] = X['AwayTeam'].map(self.teamsMap)\n",
    "        y = []\n",
    "        for v in X['FTR']:\n",
    "            y.append(range(3)==v)\n",
    "       # print(y)\n",
    "        resy=[]\n",
    "        resx=[]\n",
    "        print(\"h3:start format\")\n",
    "        recents = []\n",
    "        for i in range(X.shape[0]):\n",
    "            \n",
    "            sys.stdout.write(\"\\r progress {}\".format(i))\n",
    "            sys.stdout.flush()\n",
    "            x = X.iloc[i]\n",
    "            homeName = x['HomeTeam']\n",
    "            awayName = x['AwayTeam']\n",
    "            homeRecent = self._getH3RecentMatches(x,X,homeName, recentNum)\n",
    "            awayRecent =self._getH3RecentMatches(x,X,awayName, recentNum)\n",
    "            if homeRecent is None or awayRecent is None:\n",
    "                   continue \n",
    "        #    print(homeName)\n",
    "         #   print(homeRecent)\n",
    "        #    print(awayName)\n",
    "         #   print(awayRecent)\n",
    "         #   return\n",
    "            recents.append(np.hstack([homeName,awayName, homeRecent,awayRecent]))        \n",
    "            resy.append(y[i])\n",
    "        cols =np.hstack([[0,1],list(range(3,len(recents[0]),3))])\n",
    "        print(cols)\n",
    "        ohe = OneHotEncoder(categorical_features=cols)\n",
    "        res = ohe.fit_transform(recents).toarray()\n",
    "        print(\"finish\")\n",
    "        sys.stdout.flush()\n",
    "        return res, np.array(resy)\n",
    "   \n",
    "\n",
    "    def getH4(self, recentNum, target=None):\n",
    "        \n",
    "        X  = self.df.sort_values(by=\"Date\")\n",
    "        isInput = False\n",
    "        if target is None:\n",
    "            target =X      \n",
    "        else:\n",
    "            if self.ohe is None:\n",
    "                raise Exception(\"Not yet get train data\")\n",
    "            isInput = True\n",
    "            target['HomeTeam']=target['HomeTeam'].map(self.teamsMap)\n",
    "            target['AwayTeam']=target['AwayTeam'].map(self.teamsMap)\n",
    "            pass\n",
    "            \n",
    "        X['HomeTeam'] = X['HomeTeam'].map(self.teamsMap)\n",
    "        X['AwayTeam'] = X['AwayTeam'].map(self.teamsMap)\n",
    "        target_date = (pd.to_numeric(target['Date'])/1e9/24/60/60).values\n",
    "        y = []\n",
    "        for v in target['FTR']:\n",
    "            y.append(range(3)==v)\n",
    "       # print(y)\n",
    "        resy=[]\n",
    "        resx=[]\n",
    "        print(\"h4:start format\")\n",
    "        recents = []\n",
    "        for i in range(target.shape[0]):\n",
    "            \n",
    "            sys.stdout.write(\"\\r progress {}\".format(i))\n",
    "            sys.stdout.flush()\n",
    "            x = target.iloc[i]\n",
    "            homeName = x['HomeTeam']\n",
    "            awayName = x['AwayTeam']\n",
    "            homeRecent = self._getH3RecentMatches(x,X,homeName, recentNum)\n",
    "            awayRecent =self._getH3RecentMatches(x,X,awayName, recentNum)\n",
    "            if homeRecent is None or awayRecent is None:\n",
    "                   continue \n",
    "           # print(homeName)\n",
    "           # print(homeRecent)\n",
    "          #  print(awayName)\n",
    "            #print(awayRecent)\n",
    "            if recentNum == 0:\n",
    "                recents.append(np.hstack([homeName,awayName,target_date[i]]))\n",
    "            else:\n",
    "                recents.append(np.hstack([homeName,awayName,target_date[i], homeRecent,awayRecent]))            \n",
    "            resy.append(y[i])\n",
    "#        print(recents)\n",
    "        if isInput==False:\n",
    "            cols = None\n",
    "            if recentNum == 0 :\n",
    "                cols = np.array([0,1])\n",
    "            else:\n",
    "                cols =np.hstack([[0,1],list(range(4,len(recents[0]),3))])\n",
    "            self.ohe = OneHotEncoder(categorical_features=cols)\n",
    "            self.ohe.fit(recents)\n",
    "        res = self.ohe.transform(recents).toarray()\n",
    "        print(\"finish\")\n",
    "        sys.stdout.flush()\n",
    "        return res, np.array(resy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 21)\n",
      "(380, 21)\n",
      "(293, 21)\n",
      "{'Norwich': 2, 'Chelsea': 7, 'QPR': 21, 'Man City': 9, 'Swansea': 4, 'Crystal Palace': 8, 'Southampton': 15, 'Tottenham': 18, 'West Brom': 5, 'Bournemouth': 23, 'Newcastle': 14, 'Sunderland': 3, 'Arsenal': 0, 'Leicester': 20, 'Stoke': 16, 'Burnley': 22, 'Man United': 19, 'West Ham': 6, 'Liverpool': 1, 'Aston Villa': 10, 'Cardiff': 17, 'Watford': 24, 'Hull': 13, 'Everton': 11, 'Fulham': 12}\n"
     ]
    }
   ],
   "source": [
    "c = FootballDataHelper(recentNum=4)\n",
    "c.readFootBallData(\"E0_1314.csv\")\n",
    "c.readFootBallData(\"E0_1415.csv\")\n",
    "c.readFootBallData(\"E0 (1).csv\")\n",
    "print(c.teamsMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h4:start format\n",
      " progress 1052finish\n"
     ]
    }
   ],
   "source": [
    "X,y = c.getH4(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "def plotErrorDate(X_test, X_err, dateCol = 10):\n",
    "    X_test_date =np.sort(X_test[:,10])\n",
    "    X_date=[]\n",
    "    y_date=[]\n",
    "    for v in X_test_date:\n",
    "        date = datetime.datetime.fromtimestamp(v*24*60*60)\n",
    "        if len(X_date) ==0  or X_date[-1] != date:\n",
    "            X_date.append(date)\n",
    "            y_date.append(1)\n",
    "        else:\n",
    "            y_date[-1] = y_date[-1] +1\n",
    "    plt.plot_date(X_date,y_date,xdate=True)\n",
    "    X_err_d = np.sort(X_err[:,10])\n",
    "    X_err_date=[]\n",
    "    y_err_date = []\n",
    "    for v in X_err_d:\n",
    "        date = datetime.datetime.fromtimestamp(v*24*60*60)\n",
    "        if len(X_err_date) ==0  or X_err_date[-1] != date:\n",
    "            X_err_date.append(date)\n",
    "            y_err_date.append(1)\n",
    "        else:\n",
    "            y_err_date[-1] = y_err_date[-1] +1\n",
    "    plt.plot_date(X_err_date,y_err_date,xdate=True,color='red')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inData = c.readPredict(\"predict.csv\")\n",
    "print(inData)\n",
    "X_in, y_in = c.getH4(4,target=inData)\n",
    "print(y_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from custom import SoftMaxMLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "hiddenNodes = int(12)\n",
    "print(hiddenNodes)\n",
    "clf = SoftMaxMLPClassifier(hidden_layer_sizes=[hiddenNodes], activation='logistic', algorithm='l-bfgs', alpha=50, \n",
    "              learning_rate_init=0.01,learning_rate='adaptive' ,max_iter=1000,early_stopping = True,verbose = 3)\n",
    "mlp = Pipeline([('scl', StandardScaler()),('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SoftMaxMLPClassifier(activation='logistic', algorithm='l-bfgs', alpha=50,\n",
       "           batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "           early_stopping=True, epsilon=1e-08, hidden_layer_sizes=[12],\n",
       "           learn...e=None, shuffle=True, tol=0.0001,\n",
       "           validation_fraction=0.1, verbose=3, warm_start=False))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X,y)\n",
    "#res = mlp.predict(X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(X_in.shape)\n",
    "res = mlp.predict(X_in)\n",
    "print(res)\n",
    "proba= mlp.predict_proba(X_in)\n",
    "print(y_in)\n",
    "print(mlp.score(X_in,y_in))\n",
    "print(proba)\n",
    "print(firstNScore(2,proba,y_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#future\n",
    "inData = c.readPredict(\"future.csv\")\n",
    "print(inData)\n",
    "X_in, y_in = c.getH4(4,target=inData)\n",
    "res = mlp.predict(X_in)\n",
    "proba= mlp.predict_proba(X_in)\n",
    "print (\"{}\\n{}\".format(res,proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"start learning\")\n",
    "sys.stdout.flush()\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=mlp, \n",
    "                       X=X, \n",
    "                      y=y, \n",
    "                      train_sizes=np.linspace(0.1, 1.0, 4), \n",
    "                      cv=4,\n",
    "                     n_jobs=1,verbose=3)\n",
    "print(\"finishing\")   \n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotCurve(train_mean,train_std,test_mean,test_std,train_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "def crossValidate(mlp, X,y, fold = 10):\n",
    "    y_label = np.argmax(y,axis=1)\n",
    "\n",
    "    kfold = StratifiedKFold(y=y_label, \n",
    "                             n_folds=fold,\n",
    "                            random_state=1)\n",
    "\n",
    "    scores = []\n",
    "    train_scores=[]\n",
    "    firstNScores = []\n",
    "    for k, (train, test) in enumerate(kfold):\n",
    "\n",
    "        mlp.fit(X[train], y[train])\n",
    "        score = mlp.score(X[test], y[test])\n",
    "        firstNScores.append(firstNScore(2, mlp.predict_proba(X[test]), y[test]))\n",
    "        train_scores.append(mlp.score(X[train],y[train]))\n",
    "        scores.append(score)\n",
    "        print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1, \n",
    "                    np.bincount(y_label[train]), score))    \n",
    "        \n",
    "        \n",
    "    return train_scores,scores, firstNScores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def lamda_test(mlp, X, y, lamdas):\n",
    "    \n",
    "    train_scores=[]\n",
    "    test_scores=[]\n",
    "    for lamda in lamdas:\n",
    "        clf.set_params(alpha= lamda)\n",
    "        train_s, test_s, firstNScores = crossValidate(mlp,X,y,fold=5)\n",
    "        train_scores.append(train_s)\n",
    "        test_scores.append(test_s)\n",
    "        print(\"lamda: {}, train: {}, test: {}\".format(lamda, \n",
    "                    np.mean(train_s), np.mean(test_s)) )\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    plotCurve(train_mean,train_std,test_mean,test_std,lamdas)\n",
    "    return np.array(train_scores),np.array(test_scores)\n",
    "\n",
    "l_range = np.array(range(10,14,2))\n",
    "train_scores,test_scores = lamda_test(mlp,X,y,l_range)\n",
    "#50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\n",
    "#plotCurve(train_mean,train_std,test_mean,test_std,l_range)\n",
    "plt.plot(l_range, train_mean, \n",
    "        color='blue', marker='o', \n",
    "        markersize=5, \n",
    "        label='training accuracy')\n",
    "plt.fill_between(l_range, \n",
    "              train_mean + train_std,\n",
    "               train_mean - train_std, alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(l_range, test_mean, \n",
    "          color='green', linestyle='--', \n",
    "          marker='s', markersize=5, \n",
    "         label='validation accuracy')\n",
    "plt.fill_between(l_range, \n",
    "                  test_mean + test_std,\n",
    "                 test_mean - test_std, \n",
    "                alpha=0.15, color='green')\n",
    "plt.xlabel('lamda')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y,test_size =0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SoftMaxMLPClassifier(activation='logistic', algorithm='l-bfgs', alpha=50,\n",
       "           batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "           early_stopping=True, epsilon=1e-08, hidden_layer_sizes=[12],\n",
       "           learn...e=None, shuffle=True, tol=0.0001,\n",
       "           validation_fraction=0.1, verbose=3, warm_start=False))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(alpha=50)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = mlp.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.610738255034\n",
      "0.815436241611\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCoAAAJrCAYAAAAmgXI5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZmZmZmZFcMDFWZmZmZmZmZWjP8Ab/8b1011xxYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4208d71400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "predicted = mlp.predict(X_test)\n",
    "print(mlp.score(X_test, y_test))\n",
    "proba = mlp.predict_proba(X_test)\n",
    "print(firstNScore(2,proba,y_test))\n",
    "error = X_test[np.argmax(predicted,axis=1) != np.argmax(y_test,axis=1)]\n",
    "plotErrorDate(oneHotDecode(c,X_train),oneHotDecode(c,error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likehoodScore(res,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "home_teams_test = np.argmax(X_test[:,0:len(c.teamsMap)],axis=1)\n",
    "away_teams_test = np.argmax(X_test[:,len(c.teamsMap):len(c.teamsMap)*2],axis=1)\n",
    "inverseMap ={}\n",
    "for name in c.teamsMap.keys():        \n",
    "    inverseMap[c.teamsMap[name]] = name\n",
    "\n",
    "home_name =[]\n",
    "away_name =[]\n",
    "for i in range(home_teams_test.shape[0]):         \n",
    "    home_name.append(inverseMap[home_teams_test[i]])\n",
    "    away_name.append(inverseMap[away_teams_test[i]])\n",
    "pre_y = np.argmax(predicted,axis=1)\n",
    "real_y = np.argmax(y_test,axis=1)\n",
    "for i in range(predicted.shape[0]):\n",
    "    if pre_y[i] != real_y[i]:\n",
    "        print('-------------')\n",
    "        print(\"{} vs {}\".format(home_name[i],away_name[i]))\n",
    "        print(\"{} vs {}\".format(res[i],y_test[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#c.df[(c.df['HomeTeam'] == 'West Brom') | (c.df['AwayTeam']=='West Brom')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from custom import SoftMaxMLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def testNodeSize(start ,end):\n",
    "    node_range = range(start,end,25)\n",
    "    train_means = []\n",
    "    train_std = []\n",
    "    test_means =[]\n",
    "    test_std=[]\n",
    "    for node in node_range:   \n",
    "        print(\"start node:{}\".format(node))\n",
    "        clf = SoftMaxMLPClassifier(hidden_layer_sizes=[node], activation='logistic', algorithm='l-bfgs', alpha=30, \n",
    "                  learning_rate_init=0.01,learning_rate='adaptive' ,max_iter=500,early_stopping = True,verbose = 3)\n",
    "        mlp = Pipeline([('scl', StandardScaler()),('clf', clf)])\n",
    "        train_scores,test_scores = crossValidate(mlp,X,y,fold=5)\n",
    "        train_means.append(np.mean(train_scores))\n",
    "        train_std.append(np.std(train_scores))\n",
    "        test_means.append(np.mean(test_scores))\n",
    "        test_std.append(np.std(test_scores))\n",
    "        print(\"Node {}: train_mean {}  v.s. test_mean {}\".format(node,np.mean(train_scores),np.mean(test_scores)))\n",
    "    plotCurve(train_means,train_std,test_means,test_std,node_range)\n",
    "    return train_means,train_std,test_means,test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_means,train_std,test_means,test_std=testNodeSize(10 , X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from custom import SoftMaxMLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def testRecentNum(start, end):\n",
    "    recent_range = range(start,end)\n",
    "    train_means = []\n",
    "    train_std = []\n",
    "    test_means =[]\n",
    "    test_std=[]\n",
    "    first2_mean=[]\n",
    "    for recent in recent_range:\n",
    "        print(\"start recent:{}\".format(recent))\n",
    "        X,y = c.getH4(recent)\n",
    "        clf = SoftMaxMLPClassifier(hidden_layer_sizes=[12], activation='logistic', algorithm='l-bfgs', alpha=30, \n",
    "                  learning_rate_init=0.01,learning_rate='adaptive' ,max_iter=500,early_stopping = True,verbose = 3)\n",
    "        mlp = Pipeline([('scl', StandardScaler()),('clf', clf)])\n",
    "        train_scores,test_scores, first2 = crossValidate(mlp,X,y,fold=10)\n",
    "        train_means.append(np.mean(train_scores))\n",
    "        train_std.append(np.std(train_scores))\n",
    "        test_means.append(np.mean(test_scores))\n",
    "        test_std.append(np.std(test_scores))\n",
    "        first2_mean.append(np.mean(first2))\n",
    "        print(\"recent {}: train_mean {}  v.s. test_mean {} , first2_mean {}\".format(\n",
    "                recent,np.mean(train_scores),np.mean(test_scores),np.mean(first2)))\n",
    "    plotCurve(train_means,train_std,test_means,test_std,recent_range)\n",
    "    return train_means,train_std,test_means,test_std,first2_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_means,train_std,test_means,test_std,first2_mean=testRecentNum(0 ,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week0\n",
      "numOftest 5 , score 0.8\n",
      "[['Norwich' 'Man City' '0.1813496188598995' '0.17910355518254364'\n",
      "  '0.6395468259575569' 'False' 'True' 'False']]\n",
      "first2 : {} 0.8\n",
      "week1\n",
      "numOftest 10 , score 0.5\n",
      "[['Chelsea' 'Stoke' '0.8188013592983958' '0.09707085168138402'\n",
      "  '0.08412778902022014' 'False' 'True' 'False']\n",
      " ['Everton' 'West Ham' '0.5984502354977616' '0.1894183129687371'\n",
      "  '0.2121314515335014' 'False' 'False' 'True']\n",
      " ['Southampton' 'Sunderland' '0.6988086836028544' '0.13471668073872464'\n",
      "  '0.16647463565842105' 'False' 'True' 'False']\n",
      " ['Tottenham' 'Arsenal' '0.4100207542405329' '0.24092803534560595'\n",
      "  '0.34905121041386117' 'False' 'True' 'False']\n",
      " ['Watford' 'Leicester' '0.5923561736669753' '0.17059662839770037'\n",
      "  '0.23704719793532422' 'False' 'False' 'True']]\n",
      "first2 : {} 0.8\n",
      "week2\n",
      "numOftest 18 , score 0.5\n",
      "[['Southampton' 'Chelsea' '0.4500628498005311' '0.2126042833160902'\n",
      "  '0.3373328668833789' 'False' 'False' 'True']\n",
      " ['Watford' 'Bournemouth' '0.7617144309579698' '0.13464973686209616'\n",
      "  '0.1036358321799341' 'False' 'True' 'False']\n",
      " ['Man United' 'Arsenal' '0.4009348378224459' '0.18648058246606544'\n",
      "  '0.4125845797114887' 'True' 'False' 'False']\n",
      " ['Tottenham' 'Swansea' '0.3811560530069009' '0.20079426737266837'\n",
      "  '0.41804967962043066' 'True' 'False' 'False']\n",
      " ['Aston Villa' 'Everton' '0.4405325854068202' '0.19770471368042092'\n",
      "  '0.36176270091275875' 'False' 'False' 'True']\n",
      " ['Bournemouth' 'Southampton' '0.27528675156124094' '0.23281010354119994'\n",
      "  '0.49190314489755915' 'True' 'False' 'False']\n",
      " ['Leicester' 'West Brom' '0.45743463729686185' '0.21617785200549036'\n",
      "  '0.32638751069764776' 'False' 'True' 'False']\n",
      " ['Sunderland' 'Crystal Palace' '0.2837244022119373' '0.2551340547113703'\n",
      "  '0.4611415430766925' 'False' 'True' 'False']\n",
      " ['Arsenal' 'Swansea' '0.7416612684600251' '0.1363860795267762'\n",
      "  '0.12195265201319871' 'False' 'False' 'True']]\n",
      "first2 : {} 0.833333333333\n",
      "week3\n",
      "numOftest 10 , score 0.5\n",
      "[['Swansea' 'Southampton' '0.5807989788580159' '0.20920344064006624'\n",
      "  '0.20999758050191797' 'False' 'False' 'True']\n",
      " ['Everton' 'West Brom' '0.761196057098111' '0.12721634056980632'\n",
      "  '0.11158760233208274' 'False' 'False' 'True']\n",
      " ['Norwich' 'West Ham' '0.4274340541224738' '0.25212034734114425'\n",
      "  '0.32044559853638205' 'False' 'True' 'False']\n",
      " ['Man City' 'Tottenham' '0.5004055524402096' '0.2343561662460511'\n",
      "  '0.2652382813137394' 'False' 'False' 'True']\n",
      " ['Aston Villa' 'Liverpool' '0.4303242193658472' '0.1540206513852972'\n",
      "  '0.41565512924885556' 'False' 'False' 'True']]\n",
      "first2 : {} 0.8\n",
      "week4\n",
      "numOftest 10 , score 0.4\n",
      "[['Swansea' 'Crystal Palace' '0.4088716054145535' '0.27833537667597247'\n",
      "  '0.312793017909474' 'False' 'True' 'False']\n",
      " ['Man City' 'Leicester' '0.8074436039290908' '0.11075446607705064'\n",
      "  '0.08180192999385874' 'False' 'False' 'True']\n",
      " ['Newcastle' 'West Brom' '0.38470967231674297' '0.20974039530545463'\n",
      "  '0.4055499323778023' 'True' 'False' 'False']\n",
      " ['Liverpool' 'Sunderland' '0.5308220398655524' '0.2489937262686397'\n",
      "  '0.22018423386580788' 'False' 'True' 'False']\n",
      " ['Bournemouth' 'Arsenal' '0.42565061836730667' '0.21146980680244434'\n",
      "  '0.3628795748302491' 'False' 'False' 'True']\n",
      " ['Chelsea' 'Man United' '0.5562334163554697' '0.22382649054236717'\n",
      "  '0.21994009310216303' 'False' 'True' 'False']]\n",
      "first2 : {} 0.8\n",
      "week5\n",
      "numOftest 10 , score 0.4\n",
      "[['Sunderland' 'Man City' '0.47642122653396507' '0.16572484269537452'\n",
      "  '0.35785393077066047' 'False' 'False' 'True']\n",
      " ['Arsenal' 'Southampton' '0.766752439656714' '0.12550791910014483'\n",
      "  '0.10773964124314114' 'False' 'True' 'False']\n",
      " ['Crystal Palace' 'Bournemouth' '0.5092239606783607' '0.17743058769496273'\n",
      "  '0.3133454516266766' 'False' 'False' 'True']\n",
      " ['Leicester' 'Liverpool' '0.34294522818714684' '0.29666273547917765'\n",
      "  '0.3603920363336755' 'True' 'False' 'False']\n",
      " ['West Brom' 'Swansea' '0.47738140937687273' '0.19285979461066483'\n",
      "  '0.32975879601246244' 'False' 'True' 'False']\n",
      " ['Watford' 'Chelsea' '0.4113783056852257' '0.19556339068353545'\n",
      "  '0.3930583036312389' 'False' 'True' 'False']]\n",
      "first2 : {} 0.8\n",
      "week6\n",
      "numOftest 10 , score 0.4\n",
      "[['West Brom' 'Aston Villa' '0.6812193447762606' '0.14135481065040884'\n",
      "  '0.17742584457333052' 'False' 'True' 'False']\n",
      " ['Sunderland' 'Bournemouth' '0.48873022254782567' '0.206604986779528'\n",
      "  '0.30466479067264624' 'False' 'True' 'False']\n",
      " ['West Ham' 'Man City' '0.27736625145692984' '0.18393912899668155'\n",
      "  '0.5386946195463885' 'False' 'True' 'False']\n",
      " ['Man United' 'Southampton' '0.7479819118447358' '0.1174527551777037'\n",
      "  '0.1345653329775605' 'False' 'False' 'True']\n",
      " ['Crystal Palace' 'Tottenham' '0.5978035773711277' '0.15714437329387085'\n",
      "  '0.24505204933500152' 'False' 'False' 'True']\n",
      " ['Arsenal' 'Chelsea' '0.49701345144610615' '0.23576438156481996'\n",
      "  '0.26722216698907386' 'False' 'False' 'True']]\n",
      "first2 : {} 0.7\n",
      "week7\n",
      "numOftest 10 , score 0.5\n",
      "[['Aston Villa' 'Leicester' '0.40047997067662056' '0.22475902104538356'\n",
      "  '0.3747610082779959' 'False' 'True' 'False']\n",
      " ['Chelsea' 'Everton' '0.6798107424147989' '0.16749619708043867'\n",
      "  '0.15269306050476253' 'False' 'True' 'False']\n",
      " ['Liverpool' 'Man United' '0.5118378522828796' '0.190457993010381'\n",
      "  '0.2977041547067394' 'False' 'False' 'True']\n",
      " ['Stoke' 'Arsenal' '0.611788719405614' '0.1552394492570329'\n",
      "  '0.23297183133735314' 'False' 'True' 'False']\n",
      " ['Swansea' 'Watford' '0.391425564032956' '0.1928842874052971'\n",
      "  '0.41569014856174685' 'True' 'False' 'False']]\n",
      "first2 : {} 0.8\n",
      "week8\n",
      "numOftest 10 , score 0.4\n",
      "[['Bournemouth' 'West Ham' '0.4899643545966156' '0.2285685260586517'\n",
      "  '0.2814671193447328' 'False' 'False' 'True']\n",
      " ['Newcastle' 'Man United' '0.30464200708836625' '0.20304426854688887'\n",
      "  '0.4923137243647448' 'False' 'True' 'False']\n",
      " ['Swansea' 'Sunderland' '0.674346541808188' '0.1606782842181947'\n",
      "  '0.1649751739736174' 'False' 'False' 'True']\n",
      " ['Liverpool' 'Arsenal' '0.444549953986371' '0.22590698075958945'\n",
      "  '0.3295430652540396' 'False' 'True' 'False']\n",
      " ['Chelsea' 'West Brom' '0.5437148878453759' '0.22299199586011315'\n",
      "  '0.23329311629451094' 'False' 'True' 'False']\n",
      " ['Man City' 'Everton' '0.5132626915505012' '0.2022458802163016'\n",
      "  '0.28449142823319723' 'False' 'True' 'False']]\n",
      "first2 : {} 0.6\n",
      "week9\n",
      "numOftest 10 , score 0.7\n",
      "[['Watford' 'Man City' '0.4777012415144999' '0.1757892396617923'\n",
      "  '0.3465095188237079' 'False' 'False' 'True']\n",
      " ['Leicester' 'Bournemouth' '0.7052927842830853' '0.14350569412870579'\n",
      "  '0.15120152158820896' 'False' 'True' 'False']\n",
      " ['Everton' 'Tottenham' '0.48667747754894874' '0.22509702512929175'\n",
      "  '0.28822549732175956' 'False' 'True' 'False']]\n",
      "first2 : {} 0.8\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "def futureTest(mlp, X,y,numOfWeek = 10):\n",
    "    decoded = oneHotDecode(c, X)\n",
    "    dates = convertToDate(decoded[:,10])\n",
    "    dates = [d - timedelta(days=2) for d in dates]    \n",
    "    weeks  = [ v.isocalendar()[1] for v in dates]\n",
    "\n",
    "    thisWeek = weeks[-1]\n",
    "    start = -1\n",
    "    last = X.shape[0]\n",
    "    index = -1\n",
    "    w = 0\n",
    "    while w < numOfWeek:\n",
    "        if thisWeek != weeks[index]:\n",
    "            start = X.shape[0] +index+1\n",
    "            X_train = X[0:start, :]\n",
    "            X_test = X[start:last,:]\n",
    "            y_train = y[0:start,:]\n",
    "            y_test = y[start:last,:]\n",
    "            mlp.fit(X_train,y_train)\n",
    "            print(\"week{}\".format(w))\n",
    "            decoded = oneHotDecode(c,X_test)\n",
    "            home = np.array([c.inverseTeamMapping(decoded[:,0])]).reshape(X_test.shape[0],1)\n",
    "            away = np.array([c.inverseTeamMapping(decoded[:,1])]).reshape(X_test.shape[0],1)\n",
    "            stack = np.hstack([home,away])\n",
    "            print(\"numOftest {} , score {}\".format(X_test.shape[0],mlp.score(X_test,y_test)))\n",
    "            proba = mlp.predict_proba(X_test)\n",
    "            errorIndx = np.argmax(proba,axis=1) != np.argmax(y_test,axis=1)\n",
    "            print(np.hstack([stack[errorIndx],proba[errorIndx],y_test[errorIndx]]))\n",
    "    \n",
    "            print(\"first2 : {}\",firstNScore(2,proba,y_test))\n",
    "            last = start\n",
    "            thisWeek = weeks[index]\n",
    "            w = w+1\n",
    "        index = index -1\n",
    "\n",
    "clf.set_params(alpha=50)\n",
    "futureTest(mlp,X,y)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO confusion matrix ,e.g. 100 - 90 % precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
